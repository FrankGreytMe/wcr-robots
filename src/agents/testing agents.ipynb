{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac784d3-a3d8-48b2-83ab-3ded4cf9abfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e5680f9-75d4-4f1c-b987-dd53e5d1c1cd",
   "metadata": {},
   "source": [
    "# interrupt_agent.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb249b8-1f4c-4025-bae5-b59f9b34fdde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c082cef-b202-4de6-9143-e12be0515f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Make sure the .env from the repo root is loaded into the current process\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(\".env\", usecwd=True))  # searches upward from CWD\n",
    "\n",
    "import os\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found after loading .env\"\n",
    "\n",
    "# 2) Ensure the project 'src' is on sys.path\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # now 'src' is on path\n",
    "\n",
    "# --- Option A: import via the package (may import other agents too)\n",
    "from agents.interrupt_agent import interrupt_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15cc68a0-d11b-47a6-8fb0-cb2593c43562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALwAAAGwCAIAAACcnpgzAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdcE/f/B/DPZZOQsPeSpbJBhvPnrtpaF1oL4mytYl2tUkdblTq+VnG11tVq3Yqj7tHWWXcVBUEoFGQIyJBN9vz9cX75IobxaRNy0ffzDx7J3eVz7zteubtc7vIhNBoNAgAHzdAFAOMDoQHYIDQAG4QGYIPQAGwQGoCNYegC/rnqckV9lUJcrxLVKZVyIzhxQBCIziR4AgaXTxdYMc1tmIau6B8ijO48TVmB9GmqKC9daGHLUio0XAGdy2cwWYSh62odQSC5TCOuV4rrVHQmUVMu9wgw9QgwtXNlG7o0PMYUmqpS+Z1zFSamDAtbpru/qYWtsb5TSdVl8twnoppyhVSs6jHM2ogWx2hCc/d8Ve4TYc/3rTr48Qxdi47lPRHdOVfhGcjv9p6loWtpE+MIzZH1haEDLbyCTA1diB5lJwuTr1eP/dzF0IW0juqfnjQatDUup/+Htm92YhBC3iGmfUfbblvwFFH+XUz1Lc2W+Tmx33rRjWZ3/2/JJeqdS3M/TfAydCEtoXRoEtc9GxhtZ+1kZB8u/qXyQtn14+VU3k9RNzS3z1bau3E8A9+0w962yEkRvSiWdh9qZehCtKPoMU1FsawwS/R2JgYh5BXMy0sXVZbIDV2IdhQNze1zlT2GWRu6CkPqOcz6zrkKQ1ehHRVDU5InFVgwXDtxDV2IIbn5cLl8Rmm+1NCFaEHF0OQ8Flras9p5pgMHDiwuLsZ91ZEjR5YtW6afipClPSsnVainxv8NKoYm74nQvX1P+xYVFdXU1PyDF6anp+uhnJfc/Xj56SL9tf+PUe5b7qpSubUjW2CllzMzGo3m0KFD58+ff/bsmbu7e9euXWfMmPHgwYNZs2YhhEaMGNG/f/+1a9c+ffr0+PHj9+/fLy0tdXd3Hz169KhRoxBCWVlZMTExmzZtWrFihY2NDZvNfvz4MULo/PnziYmJXl46PrlibsM0t2FVlyks7Ch2nkpDMU/ThOd2PddT44cOHRo4cOC5c+cqKiqOHz/ev3//vXv3ajSamzdvhoaGFhUVkZNNnz591KhR9+/ff/DgwdGjR0NDQ+/evavRaHJzc0NDQ6Oiog4cOJCenq7RaCZNmrR06VI9VavRaM78WJyXLtJf+/8M5bY04jolT6Cvqh49euTn5zd06FCE0OjRoyMiIqRSLUeaa9asEYvFDg4OCKGwsLBTp07duXOnW7dudDodIdSnT5+YmBg9VdgET8AQ1SnbZ15tR7nQiGpVPAFdT40HBQVt3rx5+fLlXbp06dOnj4uL9rOuarX64MGDd+7cefbsGTnE3d29YayPj4+eynsdzwxC0wYEgWgMfV1RFR0dzeVyb9y4ER8fz2AwBg8ePHv2bGvrV04IqVSq2bNnazSaOXPmhIeH83i8yZMnN56AzW6/rzVodAJR75Q95UJjYkqvKtPXmVA6nR4ZGRkZGfn06dP79+/v2LFDJBKtW7eu8TQZGRmZmZnbtm0LDw8nh9TX1+upnlYJaxQ21PvqjXIfubl624trNJpz587l5uYihDw9PaOjo6OiorKysppMRn72trGxIZ/m5OQUFBToo562ENep9HeE949RLjQCKyaDoZeqCII4d+7cggULbt68WVdXd+vWrevXrwcFBSGEOnTogBC6fPlyenq6p6cnQRAHDx4UCoV5eXnr1q2LiIgoKSnR2qaLi0tGRkZSUlJ1dbU+amYwCYFVe5/nbJ2hP75p8XN8rrBGoY+WS0pK5s+fHxoaGhoaOnjw4O3btwuFQnJUfHw8edpGo9H8+uuvY8aMCQ0NHTVq1JMnTy5duhQaGhodHV1QUNDw8Zv06NGj0aNHh4eHP3jwQOfV1lUp9izP03mz/x4VL424fvyFtSPLv4eZoQsxsNRbtdXl8j6RNoYupCnK7Z4QQh4BppWlFL0qoD1Vlco9A6h4kSvlDrIQQq6dTO7/VlmSL3XowNE6QVFR0fjx47WOotPpKpVK66gxY8aQXxfoQ1xcXFJSktZRlpaWVVVVWkd98803ffr00Trq+VNJVanMeQzlNjPUvXLvea707oWK0bOctY5VKpXl5eVaR9XX1/P5fK2jeDyemZm+dnkVFRVyufato1Qq5XC0p9/S0rK5Uce/K+o1wtq+mbeNYVFxS4MQcvTgWDuwi/4WO3fUclUNg8FwdHQ0RF3NanKG8F96lim2deFQMzEUPaYh9Rltc+lwubCGcifR9a2uSnntWHnvSOpeuEjd0CCExi1wPbT2maGraG+H1xaMW+Bm6CpaQtFjmgYqhWZXfF7MAjeemb6+xaQOYY3y4JqCqSs86Hr79k0nqB4ahJBUrD68tmDQeAcnL4ru43Wi8G/JlcSycQtcWRxKb/6NIzSk68df1JTLewyztnWh3Bd4/1LZM9mdsxUWdqy+lPyA/TqjCQ1CqChbcudchYO7ibUjy93flMOl+juyZVKROi9dWPFcXpIv6fm+tZOXiaEraitjCg0pP0Oc87g+L13UwZeHNIgnYHAFdBbbOAIkl6lFdUpxnQohVPCXyN3f1DPItIOPkd2sY3yhaVCaL62tVIhqlaI6lUKm1m3j2dnZNBrN09NTh20SNILJIrgCOk/AMLNi2Xcw1v0sRU/utYV9Bz2e/vp7+wmCwej/YXc9tW/UjGOrDigFQgOwQWgANggNwAahAdggNAAbhAZgg9AAbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsEBqADUIDsEFoADYIDcAGoQHYIDQAG4QGYIPQaEej0RgMI74pTK8gNNqp1Wql8q37PaU2gtAAbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsEBqADUIDsEFoADYIDcAGoQHYIDQAmxH/Yrk+9OvXr66uTq1WEwRBEC9XjpmZ2bVr1wxdGoXAluYVXbt21Wg0dDqdRqMRBEGj0RBCvXr1MnRd1AKhecWkSZOa9I7p4OAQExNjuIqoCELzCh8fn8DAwMZDunTp0rlzZ8NVREUQmqbGjx/v4OBAPra3t4fNzOsgNE35+vo2bGyCg4NhM/M6CI0W48aNs7Ozs7e3nzBhgqFroSKD3dpT/UJRVSIT1SgVCgp+5ncM9fyAIAhhke3DompDF9MUk0XjmTGsHFjmNkyDFGCY8zS3z1RWlSkQ0lg7cuRSHXcK98ZjcmiVz6UIEVYOzB7vW7V/AQYIza3TlSoV6jLAAEv7hnl4qZLFJnoMs2zn+bb3Mc2jazVyqQYSoxOh71iJhaqUP2raeb7tGhqNGqXfqwvq297vjDdYcD+r9Lt17by3aNfQCGuVKoWa+j3cGxG2CU0mVYnr2vW283b9/4nrlDwz+CkGHTM1Y4pqVe05x/bdPSGkbteleyuo1RpEtOscYU8BsEFoADYIDcAGoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwEb10CyLXzA/boauWhsxasC+/Tt11Zo+TJw8evOWdYauohVUDw2gIAgNwGYEV7fQaLSkh38mJu5Nz0j18uo0Z/YCb69OCCGhUHjs+IH79+/kF+RaWlr36tl3yuRYDoeDEFKpVEeO7t+3/yeCIPx8A6dMjvXzC2zSbErKwy8Wzvxs7qKh742srKxYszY+PSPV1dV91IixeflP7z+4s+unRITQsOF9p0yOvX7jclpayvmzN7hc7u3bf+zd92N+Qa6FhaWnZ8fP5y62sbFFCA0a0v2jKTOiPpxItr96zbLCwoKtP+xBCA0f0e/jj2dWVVXs27+Tx+NFhPeYNTPO0tIKIZSfn/vtmmXPCvODg8MmjJ9qiBWMzQi2NPkFuWfOHI+J+eg/qzbJZbIlS+eTF8Mf/+XQocN7oqIm/WfVptjpc69c/fXAwV3kS3b8+P3Zs7+sWL7+q8UrraxtFi6eXVT0rHGbBQV5Xy+dFzkqauh7IxFCaxO+KSwsWL9u+/L4hFu3rz98+CdBvLxEhclinTiZ6O3deV3CVjabnfTwz6XxXwwePOzYkYtff7mqpKT4+81rW10EFpt9OHEPm805c/ranp+PP059tG//TwghhUKxcPFsGxu73buOTf1o5qFDu6urKvWzFnXJCLY01dVVc2YvsLa2QQhNmjjtqyXz0tNT/f2Doj6c2K/vO25u7uRkjx8/evDg7tSPZ9bUVB87fvCzuYvCw7ohhLp16yUWiSorK5ydXckpKysr4hZ8GhAQEjt9Lvn0/oO7n81d1LmTL0Jo/ryvYiaMsLd/+TMAdDrd2sZ29sw48unPu7f16T1gdGQUQiggIDh2+meLFs/Jzc3x8PBqYREIgnBxdhsXPRkhxDflh4Z2/Ts7EyF04+bV8vKy7zbutLOzRwjNmhkXNe59Pa9OHTCC0Hh6eJOJQQiRe5mSkmJ//yAmk3n/wZ3V3y59mptN9s1ETpabl4MQ8vHxJ1/CYDBWLH/5eYQgCJlMumDRLCtL62VLviU3J3n5TxFCAf7B5DRmZubBwWGlpc8bCujo7dPwODc3u3+/QQ1PyZz9lfmk5dAghDp2/F8jfL5AKKxHCBUXF3I4HHv7l7eO29nZW1lZ/+sVpndGsHvi8UwbHnO5PIRQXX0dQmjr9o37D+x6//3IQwfOXLuS1HAwQf4/uCbc15vSaDRHjx3Izc1hsdlsNpscKBIJEUIcE5OGyQR8s8avYrFY/21ZKJPJ2GxOk3qkEkmrS9Gwv2usrq628dIhhDgck9cnoxojCI1E+r9/CfkPNjMzV6vVFy6cGjVy7PtDR5HHoWRWGkJW/9+nTXh7d96wfntWVsaBgz+TQ9gsNkJI1agfueqaKq2vJY+ypY3qEYtFCCFLbZsHtar1y6EFAjO5TNZ4CNkgxRlBaJ49y5NKpeTjzMx0hJCTk4tcLpdKpVZWL3dbMpns7r2b5GNv7850Ov3x44fkU7VavWDhrEuXLpBPu3XtFRIcNn3a3L37fiQPLBwdnRt2UuRmLCUlSWslDAajU0ef9PTUhiHkYw93L4QQm82WSMSNys5vddHs7RzqhfUFBXnk078y06urteeVUqgeGrVazeGYrNuwsl5YX1VVeShxj5Ojs09nPw6H4+Tk8utvZ4ufF9XW1qxZGx8YEFJXVyuVSgV8waB3hp4+fezir2eSU5K+37w2OSXJxzegcbORoz7sEhIeH79AIpG4unZwcXHbs3fH85LiemH9pk2ryRhpNXz4mD9uXDlxIrFeWP8o+cHW7RsjwruTB+N+fkE3b10TiUQIob37fmpuc9VYjx59WCzWug0rpVLpixflq79dyucLdLTm9IjqoZEr5IEBIc5OLmM+GPxh9FCE0PJvXh7VLl2ymslkTp4yZvyEkV0jen788UwWizViVP/Kyoq5cxYGB4et37Bq3vzYjIy0FcvXOzu5NGl58aLlYol4/cZVCKGFXyxTq9XjJ4yMi5vh5xvo09mfydD+gwzvDhn+8UefJh7dN3xEv4SE5SHBYV99tYocNXvWF+ZmFu8P7zP43R4qlbJvn3davU/e1NR01cqNUonk/eF9pnz8wdgPxjs7u1L/pzPb9QcASgukf/xS8d7Hzb6PDaW2tkYqlZKfexFCCxbO4vFMly391tB1tcn5nYX9x9raurDbbY5U39K0jyXL4ubNn37r1vXq6qq9+35KTkl6//1IQxdFXUZwnqYdLI9PSFi/YvuP31VWvnBzdV8enxDaJcLQRVEXhAYhhMzNLVat2GDoKowG7J4ANggNwAahAdggNAAbhAZgg9AAbBAagA1CA7BBaAA2CA3A1q6hYZvQaZBSXaPRCbZJu67Wdp2ZhS2z4rlMRcVuV4yVQqauLpWZWbdrdyzt/cYP6GmenVzXzjN9g+Wk1Pv3NG/nmbZ3aHqNsCrNE+emar/qG2DJSakvfybuOay9eycxTH9P53aWmPAZTBbN3I6tUkB/T3gYTFpVqUypUEtFyqEfObR/AQbrzD0/Q1xRLBMLVTIJFUPzvPg5QSMaekClFI4JzYRPt3Fiu/louberHRgsNBS3fft2BoMxdapx3JHfzuATMMAGoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdggNAAbhAZgg9AAbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsEBqADUIDsEFotGMwGExmu95Vb0TgF8u1UzbqMww0AVsagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsEBqADUIDsEFoADYIDcAGoQHYIDQAG4QGYIMfn35F//79a2trNRoNQRDkX7VabWFhcfXqVUOXRiGwpXlF165d1Wo1jUYjCKLhb69evQxdF7VAaF4xfvx4JyenxkMcHByioqIMVxEVQWhe4efnFxgY2HhIUFCQr6+v4SqiIghNU9HR0Q2drzg4OMTExBi6IsqB0DQVEBAQEBBAPg4MDITNzOsgNFpER0fb2NjY29tPmDDB0LVQUeu3sFSWKiqLpaK6t+qWDudQz9F0Ol1SYpdcUm3oYtoPz4xh7cixtG/lhq+WztNo1OjszueiWpW5HZtjQtdDkYBaJCJlXaWcJ2C8P9WBIJqdrNnQqFWaE1uK/bpbOnc0TJ93wFAKs0QZf9ZEznRqrhP1ZkNzcmuxX3dLBw8T/RYIKKk4R5yVVDNiuqPWsdqzVJInpdFpkJi3lpMXV6NGpQUyrWO1h6biuYzLh9u832pcPqOyBCc0knoV1wxC81bjmTHEtQqto7SHRqNBGhV8+/1WU6uRBmn/BAUn9wA2CA3ABqEB2CA0ABuEBmCD0ABsEBqADUIDsEFoADYIDcAGoQHY9BWa9RtWTZ0WrafG2+jv7Mx+A8LS01P10fiIUQP27d/5b2b6wYfv7ty1pS3zosLKbMzAW5r4bxZeuHhaT41bWVpPnDDV2tpWT+3/g5nqdXn12nhjBg5NZla6/hq3srKeMjnWzs5ef7PAnalel1evjTems4tmxGLxqtVfJyc/cHf3GjlibONRFRUvtm7bkJ6RKpPJIiJ6TJo4zcnRWalUvjO4G0IoYd2KHT9+f/rkFYTQhYunz547kZ//1MPDu3+/waMjX94PO2x43ymTY6/fuJyWlnL+7I3V3y5lMpldI3qu37iKwWB07uS3bNmaEycO79u/08LC8t0hwz+ZOovcU0yPHf/D9z/7+QUuWRrHZDL79x+8du03EqnEzy9w+rS5Pp39yL4zftr5w70/b1VUlAcGdhk5YmzXiB5tWWSCIE6cPHLx4umS0uLwsO6fzV1kZmbeZKYsFsvGxu7I0f3fLFu77JsFTZaXwWCeOJG4bccmNpsdEBCyeNFyAV/Q8sq8e/fm1Wu/PU59JBTW+3T2nzB+anBwKNbK/Pd0tqVZt35FUdGzDet3rPhmXU5O1oOku+RwpVI5Ly427UlK3Pwlu3cd5fMFM2ZMKCl9zmAwfr1wGyH0RdwSciEvXbqQsG5F506+hw+enTI59uix/Vu3bSQbYbJYJ04ment3Xpewlc1ms1is1LTkvzKfHDtyccvmPalpyXM/m0qj0c+fvbFwQfyhw3uSU5KalMdisZ6kP7569bcdOw5ePH+LQWesTfiGHLVx0+oTJxNHR0YfPnSuV8++S5bOv3X7elsW+cKFU7W11Z9+Ou/LRSvuP7izZduGJhMwmcysrIy8/Kf/WbkxKKhLk+VFCF27/rtEKlm75oe4+UseP364Z++OllemWCxe+Z+vlErl4kXLV63c6OTk8tWSz2tqqrFW5r+nm9BUVLy4dv1SdNSkzp18LS2tYqfPZTJZ5KjHqY8KCwsWL1oeHtbNwsJy5ox5pqb8X345/HojZ8+fCAwMmTtnobm5RVho10kTp504mVhbW4MQotPp1ja2s2fGhXaJoNPpNBpNpVLN/HS+mZm5u7unm5s7k8GcNPETLpfbNaIHl8vNyclqupw0mlQiiZu/xMHekcFg9Os3KD8/VyqVSqXS3y+dHxc9efiw0QK+YOh7I/v1G7Rv309tWWoTLnfypOkhwWE9evR+f2jk9euXmnT4Q6fTKypfLI9P6N79/8zMzF9vwdSUHzNuSkhwWN8+A3t0752WmtzyyuRyuTt/Svxs7qKQ4LCQ4LBpn8wRi8VPnjxu48oUCoVtWa5W6SY0JSXFCCE3Nw/yKUEQnTr6kI/T0lKYTGaXkPCX86PRAoO6pKUlN2lBqVRmZKSFh3VvGBISEq5SqdLSUsinHb19Gk/v4uLW0IkXl8vr4O7ZMIrL5QmF9a8X6eLagct9eTsOny9ACIlEwszMdKVS2Xi+wUGh2TlZIpGo1aUOC+1G/PfuIB8ff4VCUV1d1WQaN1d3NpvdXAsB/sENjwVm5jK5rOWViRASi0Tfb147ZuyQfgPCho3oixCqqW16O19zK7OgILfVhWoL3RzT1NbVIIRMeaYNQzicl3cyCIX1CoWi34CwxtNbWVk3aUEqlapUql0/b93189bGw6trXv4bWCxW4+G0V+/JoTV3i05r0whF9Qih2XM/bjK8qqqCx+O13CCX+78JTEy4CKH6+rom07CaTwzZf13D44b8tbAyS0tL5n4+NTys+9KvV/v6BqhUqiHv9Xy92eZW5uvl/TO6CY2ZwBwhJJP97+J1sfjlO9XKytrExGTVyld2qAx60/mamppyOJwhg4f17j2g8XAnRxedVNgcS0trhND8eV85Ob0yo7Z8UJdKJQ2PyeU1MzOvrKr4lyW1sDKvXvtNoVAsXBDP4XAQQuS++3XNrUwPd69/WRtJN6Gxt3dECKVnpHp5dSST/ij5gbW1DULIw8NbIpHY2zs62L+886r4eZGlhdXrjXh4eEukkpDgl9skuVxeVlZia2unkwqb4+LixmKx6HR6w3yrqioJgjAxaf2er8ZHTllZGVwu18LC8t+HpoWVWVtbw+cLyMQghK7/cbm5RrSuTK3HVf+Abo5pbGxs/f2Ddv28tai4UCaTrfzPVw37gq4RPSIieiQkLC8rK62pqT5x8khs7Pjffj+HEGKz2TY2to8e3U9OSVIqldM/mXPjxpULF0+rVKrU1ORvViya/8UMuVyukwqbwzflT540fc/eHWlpKVKp9Pofl+fFxX6/eW2rL9So1bl5OceOH1SpVFl//3X5ysU+vQe2vJdssrzNTdbCyvTy7FhZWXH+wimlUnnvz9tPnqSY8kzLy0vbuDJ11TGnzj5yL160vHMn30+mRQ8d1tvSwmrwoPcbbvhdvWpT794Dlq9cPGr0O6fPHHv33REjR3xAjooZ91HSwz+XLJ0vl8sDA0N2bDuQmpo8KnLggkWzJGLxyhUbmhzK6EN01KS4+UsOJe4ZNqLv5h8SXF06xM1f0uqr5Ar5h2MnpDx+OHBQ1/lxsUGBXWJjP2v1VY2Xt4XJmluZAwe+GzNuyu49298Z3O3kqSOzZ33xzqCh+w/s2rxlXVtWZuNDqH9D+73cf16sUihQUB9LncwDGKOU61VsDooYrCUD8C03wAb33mqXnp66aPGc5sYePnTO1NS0ubFvPAiNdn5+gT/+eKi5sW9zYiA0LWk4RwCagGMagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsEBqATXtoOKY0jbrdawFUolEjE1PtHWJoD42VPbu8SKJ1FHhLlBdKLO21X8ykPTTOXiZyiVpU+1Z11wP+p75aoVSonZrp56C5fjbQex853DpVJhOr9FsdoB6JUHXnTPnQjxya+e3pFvt7qqtSHt3wzNWXb2HDYnPhkPnNJxWqaytlzzJFYz934Vs0ewVE6525/3W/vqJY9pb1LIfKysoIgrC1bddfnDA4noBh7cT2ieC3PFnroXk7bd++ncFgTJ061dCFUBHsdAA2CA3ABqEB2CA0ABuEBmCD0ABsEBqADUIDsEFoADYIDcAGoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdggNAAbhAZgg9AAbBAagA1Cox2DwWiHvjyMFPz4tHa66uXmjQRbGoANQgOwQWgANggNwAahAdggNAAbhAZgg9AAbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCDH59+Rf/+/WtqahBCBPGyXwC1Wm1ubn7t2jVDl0YhsKV5RXh4OEEQNBqNaKRnz56GrotaIDSvGD9+vKOjY+Mhjo6O0dHRhquIiiA0rwgICPD39288JDAw0M/Pz3AVURGEpqmoqCgHBwfysYODw7hx4wxdEeVAaJoKCgoKCAggHwcGBjbZ8AAIjXZRUVE2Nja2trYxMTGGroWK2noLS12VsqpULqxRqNVvw0d012CP4QRBKKscU2/VGLoYvaPTaabmDEt7Vgu9yTXWpvM0t05XvCiSEzRkYctWKKDv5TcNk0WrKpMhDbJ1ZvccbtXq9K2H5urRFywOI6iPhe6KBBSVcq1KrVL3GW3d8mStHNPcPV/JZNEhMW+J4H6WiCD+vFjV8mQthUYh12SnCIP7Weq6NkBdXQZYZSbVqVUt7X9aCk11qZzFgY9Xbx0mh15ZKm9hgpYyIaxT8i3glxPeOgJLlqi2pd8/aGVDolLCZ6W3jkqpbvnTEex9ADYIDcAGoQHYIDQAG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdggNADbWxGaEyePrF6zzNBVvDneitBkZqUbuoQ3io471FCpVN9vXnvr9nUWkzVo0FBvr85LlsWdOnHZzMxcqVT+tPOHe3/eqqgoDwzsMnLE2K4RPchXDR/R7+OPZ1ZVVezbv5PH40WE95g1M87S0gohVFHxYuu2DekZqTKZLCKix6SJ05wcnRFC2TlZ06bHrF61KWH9Cmsrmx3bD+TlPT1z9vjDR/fLy0vdXN2HDRv9/tBRCKHZcz9+8uQxQuj338/v+inRw8PrwsXTZ8+dyM9/6uHh3b/f4NGRUa0u17DhfadMjr1+43JaWsr5sze4XG5aWsrefT9mZWVYWll369pr8qTpJiYmCKHautq9e3fcu3ertq6mU0ffd947IXFzAAARyElEQVR5790hwxFCi76ca8IxcXFxO3J0v1qt9vTwXvDFMg8PL7L927f/2Lvvx/yCXAsLS0/Pjp/PXWxjY9vymsnPz92zd0dyShKdTvfzDfxw7AR//yCyK5Dm1rOu6HhLc+To/vMXTs2ds3DHjoN0OmPvvh8RQgSNhhDauGn1iZOJoyOjDx8616tn3yVL59+6fZ18FYvNPpy4h83mnDl9bc/Pxx+nPtq3/ydy+efFxaY9SYmbv2T3rqN8vmDGjAklpc8RQiwmCyG08+ctUR9O/PzzLxFCm39ISHr452dzF63+z3fvvjti/YZVD5LuIYQ2f7fLx8d/0KCh164keXh4Xbp0IWHdis6dfA8fPDtlcuzRY/u3btvY6nIxWawTJxO9vTuvS9jKZrOfPctfsGiWQqnYumXvsiXfZmdnzouLVavVCKF161ZkZmV8/vmXP+882qmTb8K6FRl/PSELfpT8gMFg/nbxzp7dx83MLZYsiyOv6k96+OfS+C8GDx527MjFr79cVVJS/P3mtS2vGblcPi8ulslibVy/Y823mxFCXy2ZJ5PJWl7PuqLj0Pz2+7ne/9e/9//1F/AFEydMNeFyyeFSqfT3S+fHRU8ePmy0gC8Y+t7Ifv0G7dv3EzmWIAgXZ7dx0ZP5pnxra5vQ0K5/Z2cihB6nPiosLFi8aHl4WDcLC8uZM+aZmvJ/+eUwQohOpyOEevbo88GYmM6dfBFCy5atSVizpUtIeEhw2MgRH3h7dbp//87rFZ49fyIwMGTunIXm5hZhoV0nTZx24mRibW0rNzfR6XRrG9vZM+NCu0TQ6fTLVy4yGczl8QkuLm4eHl7z53+dmZl+5+4NsuY+vQeEh3Wzs7OfPm3O1i17rSytyWWUy2XjoicjhJwcnSdNnPb8eVFGRhpC6Ofd2/r0HjA6MsrMzDwgIDh2+me3bl/Pzc1pYc0UFhZUV1eNjoz28PDy9uoUv2xN/LI1SqWy5fWsK7oMjUqlevYs388vqGHI//XqRz7IzExXKpXhYd0bRgUHhWbnZIlEIvJpx44+DaP4fIFQWI8QSktLYTKZXULCX9ZKowUGdUlLS26YsqP3/16lUauP/XJwwqTIfgPC+g0Iy87JqqlpelW9UqnMyEhrXEZISLhKpUpLS2l16RrP68mTx507+5mZmZNPnRyd7e0cHj9+hBAKCAg+nLh32/ZN9+7dUiqVnTv52tnZk5O5u3sxGC+PB5ydXRFCBc/yEEK5udm+vgENjZPvgb8yn7SwZpydXc3NLVZ/u/Tgod3p6al0Oj0kOIzH4zW3nsVicasL2Ha6PKaRSCQIIXLXThLwzcgHQlE9eXjR5CVVVRU8Hq/xjwg1JhTWKxSKfgPCGg+0svrfXTksNpt8oFKpFi6ardFopk+bExIczuPxPp01+fUGpVKpSqXa9fPWXT9vbTy8+rV4va5xR3NCYX12TlaTwqqrKxFCCxfEnzlz/MrVX48eO2DKM42MjJowfiqZFQ6b0zCxCccEISQWi4RCoUwmYzcaxeXyEEJSiYR8qnXNsNns7zb+dP7CqWPHD+7ctcXJyWXypOkDBwxpdj1XV3L/u9X/93QZGjabTf7/GoY0/DMsLa0RQvPnfeXk5NL4JdbWti00aGVlbWJismrlK8ccDLqWmrOyMv7Ozly/blvDZol8RzZhamrK4XCGDB7Wu/eAxsOdHF1en7gFllbWASYmUybHNh5oJjBHCAn4gvExH8WMm/LkyeMbN6/u279TwDcbPToaISQSCRsmlkglCCEOx4TD4SCEpFJJwyixWETOouUaXF07zIj9bMrk2KSke7/+fnbVf77u4ObR7Hq2ssFawJbpMjRMJtPKyjq/ILdhyO07f5APXFzcWCwWuRUlh1RVVRIE0Xiz9DoPD2+JRGJv7+hg//KHhoqfF1laaLlvlDwoaVg1ubk5hYUFnRpt2F9pUyppKEMul5eVldja2mEtqaeH97VrvwcHhTZsBvLzc52dXWtra65c/W3oeyPZbHZAQHBAQPDf2X9lP80ip3mam11bW0Pu1LKzMxFC7h08GQxGp44+6empH4x5+WMD6empCCEPd68WCigoyPsr88mQwcM4HE6vXn27des1+N0e2TmZvXr107qeyWjqio4PhHt07/3rr2ceJT9Qq9VHju4n3zQIIb4pf/Kk6Xv27khLS5FKpdf/uDwvLrbhM0Jzukb0iIjokZCwvKystKam+sTJI7Gx43/7/dzrU3Zw9yQI4tjxg0KhsKAg74ct60K7RJSWlZBjnZxcsrIyklOSamqqp38y58aNKxcunlapVKmpyd+sWDT/ixlyeUu3+bxu7NgJSpXyh63rpVLps2f523d899HUDwsK8mh0+u7d2+KXL0xPT62urvrtt3PZ2Zn+/z3IMzMz/2HLunphfW1d7b79Pzk6OpOHMsOHj/njxpUTJxLrhfWPkh9s3b4xIry7m5t7CwXU1FSvWfvNtu2bip8X5efnHjj4s1qt9vMN/GfrGZeOz9NMmRxbVl46P26Gk5NLaJeIyFFR69avJD8eR0dN8vLqdChxT1LSPYHAzM83MG7+klYbXL1q05mzvyxfuTgjI83VtcO7744YOeKD1ydzsHf86suV+w/sHDair7Oz65eLV5SVlXyzfNEn08b99OOhYUMj129cFffFp+sStoYEh+3YduDgod3bt2+SK+S+PgErV2zA7RjXTGC2a+eRxMS9U6dFFxcXdu7st/CLZZ6e3gihlSs2bN6SMGvORwghDw+vWTPjyPM05PbJ2dntg7FDZDKZo4PTiuXryQ3Vu0OGV1VVJh7dt3nLOns7h7Cwbp98MrvlAoKCusz7/Ms9e3ccPXYAIRQe1m3j+h2urh3+8XrG0tIPAOQ+ET25U9fvQ4e2NyeVSsvLS8nqEUIHD+0+dvzgqROXdVGqcVsWv0AorF+/bpuhC2nd1cSSwF4Cdz9ecxPoePd06PDuabExp04fq62tuXzl1+O/HBo+bLRuZwEMTve7p9ramosXT2/fscnW1n50ZDR5Oov6RkYOVDXTF/eXi1d07/5/7V4Rdel492S8yG8ntLIwt9Ttpw+Ka3X3pOMtjfFq+FQPWvVWXBoBdAtCA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsEBqAraXQsDk0Or0dawHUQGcQbJOW/vEthcbakV38VNLCBOCNVJwtsnFq6QKjFrc0XJqrD684R5cXsgOKK/pb7O5vymS3FIxWjmmGjLdLuVZZ+Vym69oAFVUUyx7/UTlofCtXTLfedY9CrjmxuciuA5fDpQusmSrl29BJ2NuFTidqK+Qyibr8mThyljODqeWmmcba2pn734+E5UVSmVgtk7wVP3z/ovwFQRDWNq3cR/JmYHPpHBPCxoXTMcS0LdO3NTRvm+3btzMYjKlTpxq6ECqC8zQAG4QGYIPQAGwQGoANQgOwQWgANggNwAahAdggNAAbhAZgg9AAbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsEBqADUIDsEFoADYIDcAGvyOsHYvFYjKZhq6CoiA02snlcrIjU/A62D0BbBAagA1CA7BBaAA2CA3ABqEB2CA0ABuEBmCD0ABsEBqADUIDsEFoADYIDcAGoQHYIDQAG/z49Cv69+9fW1vbsE4IgtBoNObm5levXjV0aRQCW5pXhIaGqtVq2n8RBEEQRI8ePQxdF7VAaF4xYcIEZ2fnxkMcHBzGjh1ruIqoCELzisDAQD8/v8ZD/P39AwMDDVcRFUFomoqKirK1tSUfOzg4xMTEGLoiyoHQNBUcHOzj40M+9vf3DwgIMHRFlAOh0WLixIlWVlY2NjawmdHK+G9h0aDaSoWoTiWqUyrlap10fEdHHUK9RyKEUJ3Lkzu1OmiQQTBZNJ6AwRXQzayYqJWe26jOWM/TqFQoJ6U+O1lUVihTqzVMNoPOojPYdI3S0JVpQzAJpUSpUigVMhVBIHs3TscQnlcQn2acPVgbZWju/1adkyoiGAyuOVdgyyVoxvTO1ag1deVicY1Io1R5BfEiBlkYuiJsRhaa7BThlcNl1h3MrDsY37p+XUVedcWzuoHRtl5Bbeo8kiKMKTQ3T1eWP1dbOFvQGMa0aWmZSqmuLqy2d6b3Gm5l6FraymhCc3FfuVhMt3IzN3QhelFRUMM3VQ8eb2PoQtrEOEJzfneZRMq07mBm6EL06EVeLY+neG9SKx2pU4ERnKe5ebpSImW82YlBCNm4m4lE9NtnKg1dSOuoHpq/k4VlRWrrDm/mXqkJG3eL54WqnBSRoQtpBdVDc+1ouYXLW5EYkoWz+dWjZYauohWUDk3S5WoLRz6dSekidYvBops58B9dqzZ0IS2h7v9Do0HZKSJbL0tDF9Le7Dwtsx5Seg9F3dDkpgk1BHVPs9fVV8Qt6Zqafk33TRNIjWi5T6ibG+qGJuexiGvONXQVhsE15z59LDR0Fc2ibmjKi2QC27c0NAJbXlmh3NBVNIuil0aI61USoYrG0Fema+tenLm4qaAwTaGQdfbu/k6/qdZWzgihm3cTr97YFztly97Di8or8h3svHr3HBceMpR8VXLq779e2SGVCn079fq/HlF6qg0hRGfSRLUKqUjF4VFxB03RLY2oVsni6Gt9qVTK7btn5hU8/mDEV3GzD5uYCL7bPrmq+jlCiEFniSV1J84lfBi5JGH5PT+fPsdOraqte4EQKinLOXR8aVjIewvmHu0SNOTUufV6Ko/EMmEIa1V6ncU/RtXQ1KkYbH2FJjc/+UVFQfSY+E7eXfmmlsPf/czEhH/z7hGEEEGjqVSKwQOmubn4EwQRFvyeWq0qLvkbIXTnz1/Mzezf6fsxj2vm7RneNWyEnsojMdh0cR0lLw6ibGhUKg2Dpa9dZ15BCp3O9PYII5/SaDSPDiF5BSkNE7g6vbwhgWsiQAhJZUKEUEVVob2dR8M0Lk6+eiqPxGTT1SqKfi1I0WMaLp8uF+vrSFAiFapUirglXRsPFPCtGx4ThJZLL8TiOltrt4anLJaJnsojyYQKEz5F/zsULYsnYMgl+tqj8/lWLJbJRzGvHJTQ6a3sDblcgUIpa3gqk+n3PIpcquQJqHgUTN3QmAoYPHN99WfhaOctl0ssLRwsLRzJIRWVRXx+K9dAWZg7/JV1m7xpFyGUkXVLT+WReOYsUwFF/zsUPaahMRCTiYSVEn003rlj987e3Y+cXFldUyoUVd+6d3TT9klJyedbflWQ38B6YeXZX7/TaDTZTx/cuf+LPmoj1VdI2ByCqv8cqm5pEELeIbyMh2JTK70cOnw0fsPdBycOHP26oDDN1qZDRJfhPbuOafklnby7Dh00696DkzfvJlqYO4wbE79l53Skn0vYhBUi/wiePlrWCepeuVdfpTq3u8zB1wiuZNO5kvSy4VPteOYUPaah6hYQIb4l3dyGXv2cul/B6El1cb2lPZ2yiaH07gkh1GeU9YHVzywctd/eoVQq4tcMaWaUnEFnIm2fnB3svGZO3aHDIpetHqxSN3MWTqPRWoOzQ6fYj7Y212D506pJX7s1N5YKqLt7It05X1VeRjd30J4biaRe63CFQsZksrWOIggah6PLw4XmaiC/r6DTtbwtW6ihuljo4KzqNoTSVxFRPTQIoUMJheYuVlwz7SF4k4hrpLXF1dFxzm2Y1pCoe0zTYNwXLvkPSyh7Tl1X1EpNQUop9RNjHFsahJBKodmzosAlyJ7FfTN7sJWJFEWppZOXutGN4eZR4wgNQkit0uxb9czG04pnqd8vfdqfqFJSkV858Us3wgi2+8iYQkO6fLi8tFBh5WZpImAZuhYdkNTJKvOr7F3ZA6ON44ZckpGFBiFUmCW+caqSyWNz+By+DU/bR1qq02hQXblIJpQpxdLeo6ydvY1s22l8oSE9TRM9uVNX+LfIwtGUzqQzWHQmm0Fn0hA1l4ZASoVaKVMqZSqVQllTInLpxPPvLvAIoO53BS0w1tA0KMgUvyiUCWtVwlolQaPJRFS82o1jSteoNTwzhqkZ3caZ7dbZuC+YN/rQgPZnJMfrgEogNAAbhAZgg9AAbBAagA1CA7BBaAC2/wem21/Zww6s7wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualize graph\n",
    "from IPython.display import Image, display\n",
    "display(Image(interrupt_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db687e7e-296b-4456-a694-6ed322baacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from psycopg_pool import AsyncConnectionPool\n",
    "# from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver\n",
    "\n",
    "# MAIN_AGENT_DB_URI = \"postgresql://postgres:1538879@localhost:5430/long_term_memory\"\n",
    "# # Build your async pool\n",
    "# pool = AsyncConnectionPool(conninfo=MAIN_AGENT_DB_URI, max_size=20, kwargs={\"autocommit\": True}, open=False)\n",
    "# await pool.open()  # required for async pool\n",
    "# # Create async checkpointer\n",
    "# checkpointer = AsyncPostgresSaver(pool)\n",
    "# await checkpointer.setup()  # create tables if needed\n",
    "\n",
    "\n",
    "\n",
    "# from langgraph.store.postgres import AsyncPostgresStore\n",
    "\n",
    "# pool2 = AsyncConnectionPool(conninfo=MAIN_AGENT_DB_URI, max_size=20, kwargs={\"autocommit\": True}, open=False)\n",
    "# await pool2.open()  # required for async pool\n",
    "# # Create async checkpointer\n",
    "# store = AsyncPostgresStore(pool)\n",
    "# await store.setup()  # create tables if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30e839ac-d9ec-44fb-b40c-d76c1dc0f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interrupt_agent.store = store\n",
    "# interrupt_agent.checkpointer = checkpointer\n",
    "# from langgraph.checkpoint.memory import MemorySaver\n",
    "# memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76130d7e-df6b-4c26-9a55-4baff14d3647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My name is Ans? what's your name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don't have a personal name, but I'm here to help you with information about zodiac signs and more! The zodiac signs originated from ancient Babylonian astronomy, where they were used to track the movements of celestial bodies and their influence on human affairs.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "store = InMemoryStore()\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "input_messages = [HumanMessage(content=\"My name is Ans? what's your name?\")]\n",
    "\n",
    "async with AsyncSqliteSaver.from_conn_string(settings.SQLITE_DB_PATH) as checkpointer:\n",
    "    # attach the *opened* saver and store\n",
    "    interrupt_agent.checkpointer = checkpointer\n",
    "    interrupt_agent.store = store\n",
    "\n",
    "    async for chunk in interrupt_agent.astream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a2c56b2-e647-43b0-832e-769414873020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What was my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Ans. How can I assist you further?\n"
     ]
    }
   ],
   "source": [
    "input_messages = [HumanMessage(content=\"What was my name?\")]\n",
    "\n",
    "async with AsyncSqliteSaver.from_conn_string(settings.SQLITE_DB_PATH) as checkpointer:\n",
    "    # attach the *opened* saver and store\n",
    "    interrupt_agent.checkpointer = checkpointer\n",
    "    interrupt_agent.store = store\n",
    "\n",
    "    async for chunk in interrupt_agent.astream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8ef6424-cca3-456f-9cff-0ce6aa765612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "10 july 1990\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on your birth date of July 10, 1990, your zodiac sign is Cancer. If you have any more questions about astrology or anything else, feel free to ask!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on your birth date of July 10, 1990, your zodiac sign is Cancer. If you have any more questions about astrology or anything else, feel free to ask!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on your birth date of July 10, 1990, your zodiac sign is Cancer. Cancers are known for being nurturing, sensitive, and intuitive. If you have any more questions about your zodiac sign or anything else, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# User input to create a profile memory\n",
    "input_messages = [HumanMessage(content=\"10 july 1990\")]\n",
    "\n",
    "async with AsyncSqliteSaver.from_conn_string(settings.SQLITE_DB_PATH) as checkpointer:\n",
    "    # attach the *opened* saver and store\n",
    "    interrupt_agent.checkpointer = checkpointer\n",
    "    interrupt_agent.store = store\n",
    "\n",
    "    async for chunk in interrupt_agent.astream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905c929-27eb-4ecb-bba5-9425085df38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd3025d-bb43-4957-8a20-fa4e9a900767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287fb49d-2e08-4e9a-960c-73f896803846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c52cfd7-9135-40f1-b985-03484900891a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe869af-fd55-4312-a1ae-ee2d72c55df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7594e-3040-4faf-bac7-04881619cc37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1549e024-1525-462b-afe5-07800b59d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from schema import (\n",
    "    ChatHistory,\n",
    "    ChatHistoryInput,\n",
    "    ChatMessage,\n",
    "    Feedback,\n",
    "    FeedbackResponse,\n",
    "    ServiceMetadata,\n",
    "    StreamInput,\n",
    "    UserInput,\n",
    ")\n",
    "\n",
    "from service.utils import (\n",
    "    convert_message_content_to_string,\n",
    "    langchain_to_chat_message,\n",
    "    remove_tool_calls,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27fcb020-023b-414e-a87a-d10da23bfe9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cae9d21-e4f6-455c-be3d-fc13973dcea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bffce2c-6f63-4b91-99df-9dced091c87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 messages\n",
      "2 messages\n",
      "data: {\"type\": \"token\", \"content\": \"Hello\"}\n",
      "\n",
      "3 messages\n",
      "data: {\"type\": \"token\", \"content\": \"!\"}\n",
      "\n",
      "4 messages\n",
      "data: {\"type\": \"token\", \"content\": \" How\"}\n",
      "\n",
      "5 messages\n",
      "data: {\"type\": \"token\", \"content\": \" can\"}\n",
      "\n",
      "6 messages\n",
      "data: {\"type\": \"token\", \"content\": \" I\"}\n",
      "\n",
      "7 messages\n",
      "data: {\"type\": \"token\", \"content\": \" assist\"}\n",
      "\n",
      "8 messages\n",
      "data: {\"type\": \"token\", \"content\": \" you\"}\n",
      "\n",
      "9 messages\n",
      "data: {\"type\": \"token\", \"content\": \" today\"}\n",
      "\n",
      "10 messages\n",
      "data: {\"type\": \"token\", \"content\": \"?\"}\n",
      "\n",
      "11 messages\n",
      "12 messages\n",
      "12 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "13 updates\n",
      "13 common block -> isinstance(message, tuple)\n",
      "13 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"Hello! How can I assist you today?\", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"071cfc87-213a-4a73-b3ef-c9a080af9b4e\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "14 messages\n",
      "14 messages -> skip_stream\n",
      "15 messages\n",
      "15 messages -> skip_stream\n",
      "16 messages\n",
      "16 messages -> skip_stream\n",
      "17 messages\n",
      "17 messages -> skip_stream\n",
      "18 messages\n",
      "18 messages -> skip_stream\n",
      "19 messages\n",
      "19 messages -> skip_stream\n",
      "20 messages\n",
      "20 messages -> skip_stream\n",
      "21 messages\n",
      "21 messages -> skip_stream\n",
      "22 messages\n",
      "22 messages -> skip_stream\n",
      "23 messages\n",
      "23 messages -> skip_stream\n",
      "24 messages\n",
      "24 messages -> skip_stream\n",
      "25 messages\n",
      "25 messages -> skip_stream\n",
      "26 messages\n",
      "26 messages -> skip_stream\n",
      "27 messages\n",
      "27 messages -> skip_stream\n",
      "28 messages\n",
      "28 messages -> skip_stream\n",
      "29 messages\n",
      "29 messages -> skip_stream\n",
      "30 messages\n",
      "30 messages -> skip_stream\n",
      "31 messages\n",
      "31 messages -> skip_stream\n",
      "32 messages\n",
      "32 messages -> skip_stream\n",
      "33 messages\n",
      "33 messages -> skip_stream\n",
      "34 messages\n",
      "34 messages -> skip_stream\n",
      "35 messages\n",
      "35 messages -> skip_stream\n",
      "36 messages\n",
      "36 messages -> skip_stream\n",
      "37 messages\n",
      "37 messages -> skip_stream\n",
      "38 updates\n",
      "38 updates -> __interrupt__\n",
      "38 updates -> __interrupt__ -> interrupt in updates\n",
      "38 common block -> isinstance(message, tuple)\n",
      "38 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"No birthdate was mentioned in the user message.\\nPlease tell me your birthdate?\", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"071cfc87-213a-4a73-b3ef-c9a080af9b4e\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "data: [DONE]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from uuid import UUID, uuid4\n",
    "config = {\"configurable\": {\"thread_id\": f\"{str(uuid4())}\", \"user_id\": f\"{str(uuid4())}\"}}\n",
    "run_id    = uuid4()\n",
    "\n",
    "\n",
    "# User input to create a profile memory\n",
    "m = 'hi!'\n",
    "input_messages = [HumanMessage(content=m)]\n",
    "user_input: UserInput = UserInput(message=m)\n",
    "#run_id = \"nkljwkd\"\n",
    "\n",
    "i = 0\n",
    "try:\n",
    "    # Process streamed events from the graph and yield messages over the SSE stream.\n",
    "    async for stream_event in interrupt_agent.astream(\n",
    "        {\"messages\": input_messages},\n",
    "        config,\n",
    "        stream_mode=[\"updates\", \"messages\", \"custom\"],\n",
    "    ):\n",
    "        i += 1\n",
    "        if not isinstance(stream_event, tuple):\n",
    "            continue\n",
    "\n",
    "        stream_mode, event = stream_event\n",
    "#        print(type(stream_mode))\n",
    "        new_messages = []\n",
    "\n",
    "        if stream_mode == \"updates\":\n",
    "            print(i, \"updates\")\n",
    "            for node, updates in event.items():\n",
    "                # A simple approach to handle agent interrupts.\n",
    "                # In a more sophisticated implementation, we could add\n",
    "                # some structured ChatMessage type to return the interrupt value.\n",
    "                if node == \"__interrupt__\":\n",
    "                    \n",
    "                    print(i, \"updates -> __interrupt__\")\n",
    "                    \n",
    "                    for interrupt in updates:\n",
    "                        print(i, \"updates -> __interrupt__ -> interrupt in updates\")\n",
    "                        new_messages.append(AIMessage(content=interrupt.value))\n",
    "                    continue\n",
    "\n",
    "                updates = updates or {}\n",
    "                update_messages = updates.get(\"messages\", [])\n",
    "\n",
    "                # special cases for using langgraph-supervisor library\n",
    "                if node == \"supervisor\":\n",
    "                    print(i, \"updates -> supervisor\")\n",
    "                    # Get only the last AIMessage since supervisor includes all previous messages\n",
    "                    ai_messages = [msg for msg in update_messages if isinstance(msg, AIMessage)]\n",
    "                    if ai_messages:\n",
    "                        print(i, \"updates -> supervisor -> aimessage\")\n",
    "                        update_messages = [ai_messages[-1]]\n",
    "\n",
    "                if node in (\"research_expert\", \"math_expert\"):\n",
    "                    print(i, \"updates -> [research_expert, math_expert]\")\n",
    "                    # By default the sub-agent output is returned as an AIMessage.\n",
    "                    # Convert it to a ToolMessage so it displays in the UI as a tool response.\n",
    "                    msg = ToolMessage(\n",
    "                        content=update_messages[0].content,\n",
    "                        name=node,\n",
    "                        tool_call_id=\"\",\n",
    "                    )\n",
    "                    update_messages = [msg]\n",
    "\n",
    "                new_messages.extend(update_messages)\n",
    "\n",
    "        if stream_mode == \"custom\":\n",
    "            print(i, \"custom\")\n",
    "            new_messages = [event]\n",
    "\n",
    "        # LangGraph streaming may emit tuples: (field_name, field_value)\n",
    "        # e.g. ('content', <str>), ('tool_calls', [ToolCall,...]), ('additional_kwargs', {...}), etc.\n",
    "        # We accumulate only supported fields into `parts` and skip unsupported metadata.\n",
    "        # More info at: https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/\n",
    "        processed_messages = []\n",
    "        current_message: dict[str, Any] = {}\n",
    "\n",
    "        for message in new_messages:\n",
    "            print(i, \"common block -> isinstance(message, tuple)\")\n",
    "            if isinstance(message, tuple):\n",
    "                key, value = message\n",
    "                # Store parts in temporary dict\n",
    "                current_message[key] = value\n",
    "            else:\n",
    "                # Add complete message if we have one in progress\n",
    "                if current_message:\n",
    "                    print(i, \"common block -> else: current_message\")\n",
    "                    processed_messages.append(_create_ai_message(current_message))\n",
    "                    current_message = {}\n",
    "                processed_messages.append(message)\n",
    "\n",
    "        # Add any remaining message parts\n",
    "        if current_message:\n",
    "            print(i, \"common block -> if: current_message\")\n",
    "            processed_messages.append(_create_ai_message(current_message))\n",
    "\n",
    "        for message in processed_messages:\n",
    "            print(i, \"common block -> [message in processed_messages]\")\n",
    "            try:\n",
    "                chat_message = langchain_to_chat_message(message)\n",
    "                chat_message.run_id = str(run_id)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'error', 'content': 'Unexpected error', 'error': str(e)})}\\n\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # LangGraph re-sends the input message, which feels weird, so drop it\n",
    "            if chat_message.type == \"human\" and chat_message.content == user_input.message:\n",
    "                print(i, \"common block -> [if chat_message.type == human and chat_message.content == user_input.message]\")\n",
    "                continue\n",
    "\n",
    "            print(\n",
    "                f\"data: {json.dumps({'type': 'message', 'content': chat_message.model_dump()})}\\n\"\n",
    "            )\n",
    "\n",
    "        if stream_mode == \"messages\":\n",
    "            print(i, \"messages\")\n",
    "            if not True:  # user_input.stream_tokens (default=True). see `schema.schema` -> `StreamInput`\n",
    "                continue\n",
    "\n",
    "            msg, metadata = event\n",
    "\n",
    "            if \"skip_stream\" in metadata.get(\"tags\", []):\n",
    "                print(i, \"messages -> skip_stream\")\n",
    "                continue\n",
    "\n",
    "            # For some reason, astream(\"messages\") causes non-LLM nodes to send extra messages.\n",
    "            # Drop them.\n",
    "            if not isinstance(msg, AIMessageChunk):\n",
    "                print(i, \"messages -> [if not isinstance(msg, AIMessageChunk)]\")\n",
    "                continue\n",
    "\n",
    "            content = remove_tool_calls(msg.content)\n",
    "            if content:\n",
    "                # Actually print the token stream (previously this was constructed but not printed)\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'token', 'content': convert_message_content_to_string(content)})}\\n\"\n",
    "                )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"data: {json.dumps({'type': 'error', 'content': 'Internal server error', 'error': str(e)})}\\n\"\n",
    "    )\n",
    "finally:\n",
    "    print(\"data: [DONE]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b53a4c1-0328-45cf-9c6d-74efcc4153df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83975b53-edc2-490d-8f29-43ffea385599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbad8ce-8388-4e7d-9796-6341532acd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd78997-02ea-4260-bec8-0a49a1e98b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67080291-efb9-4530-aff0-6da33f321e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b580d48-5c6e-48cb-a86b-6413a2cc2b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168fa9c0-20ed-4957-a955-5bd0bb267216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20efda13-e25c-4637-8556-7352db5de490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635d2b9-919a-44b4-8070-cef84afb23bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d7aa8f-edc5-4507-98aa-9df449a1b636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9eaa5e7-2e1f-4a1f-85a0-35365524cadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Option A: import via the package (may import other agents too)\n",
    "from agents.langgraph_supervisor_agent import langgraph_supervisor_agent\n",
    "\n",
    "## Visualize graph\n",
    "from IPython.display import Image, display\n",
    "display(Image(langgraph_supervisor_agent.get_graph().draw_mermaid_png()))\n",
    "\n",
    "langgraph_supervisor_agent.store = store\n",
    "langgraph_supervisor_agent.checkpointer = checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdb696cb-12c2-41c3-a6ff-3d046ee94ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: supervisor\n",
      "\n",
      "The result of the expression \\(2 + 2 - 5 + 6 + 10\\) is \\(15\\). If you have any more questions or calculations, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input to create a profile memory\n",
    "input_messages = [HumanMessage(content=\"2 + 2 - 5 + 6 + 10 = ?\")]\n",
    "\n",
    "# # Run the graph\n",
    "async for output_chunk in langgraph_supervisor_agent.astream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    pass\n",
    "output_chunk[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60e24e92-3a7c-412a-a75d-504565d0b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not True:\n",
    "    print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b45ba-09ca-4a55-9714-8dbb390a9a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bed153-adf1-4e2a-98e1-647cdb7db816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ee576-a8f0-40a1-a39c-091bf230ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input to create a profile memory\n",
    "input_messages = [HumanMessage(content=\"2 + 2 - 5 + 6 + 10 = ?\")]\n",
    "\n",
    "# # Run the graph\n",
    "async for output_chunk in langgraph_supervisor_agent.astream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    pass\n",
    "output_chunk[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "281b0872-cf5e-4f91-994c-507587303dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: supervisor\n",
      "\n",
      "As of 2024, the headcounts for the FAANG companies are as follows:\n",
      "\n",
      "1. **Facebook (Meta)**: 67,317 employees\n",
      "2. **Apple**: 164,000 employees\n",
      "3. **Amazon**: 1,551,000 employees\n",
      "4. **Netflix**: 14,000 employees\n",
      "5. **Google (Alphabet)**: 181,269 employees\n",
      "\n",
      "If you need more information or have any other questions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input to create a profile memory\n",
    "input_messages = [HumanMessage(content=\"FAANG company headcounts in 2024\")]\n",
    "\n",
    "# # Run the graph\n",
    "async for output_chunk in langgraph_supervisor_agent.astream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    pass\n",
    "output_chunk[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b97efff1-8088-45c5-b69f-5057e3c698db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 updates\n",
      "1 updates -> supervisor\n",
      "1 updates -> supervisor -> aimessage\n",
      "1 common block -> isinstance(message, tuple)\n",
      "1 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"\", \"tool_calls\": [{\"name\": \"transfer_to_math_expert\", \"args\": {}, \"id\": \"call_8vS73k3eEYaoPQ6WClvOV7m6\", \"type\": \"tool_call\"}], \"tool_call_id\": null, \"run_id\": \"046ab2aa-4a2c-424f-82ce-3920ef4c1791\", \"response_metadata\": {\"finish_reason\": \"tool_calls\", \"model_name\": \"gpt-4o-mini-2024-07-18\", \"system_fingerprint\": \"fp_62a23a81ef\", \"service_tier\": \"default\"}, \"custom_data\": {}}}\n",
      "\n",
      "2 messages\n",
      "2 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "3 messages\n",
      "3 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "4 messages\n",
      "4 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "5 messages\n",
      "5 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "6 messages\n",
      "6 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "7 messages\n",
      "7 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "8 updates\n",
      "8 updates -> [research_expert, math_expert]\n",
      "8 common block -> isinstance(message, tuple)\n",
      "8 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"tool\", \"content\": \"The result of the expression \\\\(2 + 2 - 5 + 6 + 10\\\\) is \\\\(-1\\\\).\", \"tool_calls\": [], \"tool_call_id\": \"\", \"run_id\": \"046ab2aa-4a2c-424f-82ce-3920ef4c1791\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "9 messages\n",
      "9 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "10 updates\n",
      "10 updates -> supervisor\n",
      "10 updates -> supervisor -> aimessage\n",
      "10 common block -> isinstance(message, tuple)\n",
      "10 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"The result of the expression \\\\(2 + 2 - 5 + 6 + 10\\\\) is \\\\(-1\\\\).\", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"046ab2aa-4a2c-424f-82ce-3920ef4c1791\", \"response_metadata\": {\"finish_reason\": \"stop\", \"model_name\": \"gpt-4o-mini-2024-07-18\", \"system_fingerprint\": \"fp_62a23a81ef\", \"service_tier\": \"default\"}, \"custom_data\": {}}}\n",
      "\n",
      "data: [DONE]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from uuid import UUID, uuid4\n",
    "config = {\"configurable\": {\"thread_id\": f\"{str(uuid4())}\", \"user_id\": f\"{str(uuid4())}\"}}\n",
    "run_id    = uuid4()\n",
    "\n",
    "\n",
    "# User input to create a profile memory\n",
    "m = '2 + 2 - 5 + 6 + 10 = ?'\n",
    "input_messages = [HumanMessage(content=m)]\n",
    "user_input: UserInput = UserInput(message=m)\n",
    "#run_id = \"nkljwkd\"\n",
    "\n",
    "i = 0\n",
    "try:\n",
    "    # Process streamed events from the graph and yield messages over the SSE stream.\n",
    "    async for stream_event in langgraph_supervisor_agent.astream(\n",
    "        {\"messages\": input_messages},\n",
    "        config,\n",
    "        stream_mode=[\"updates\", \"messages\", \"custom\"],\n",
    "    ):\n",
    "        i += 1\n",
    "        if not isinstance(stream_event, tuple):\n",
    "            continue\n",
    "\n",
    "        stream_mode, event = stream_event\n",
    "#        print(type(stream_mode))\n",
    "        new_messages = []\n",
    "\n",
    "        if stream_mode == \"updates\":\n",
    "            print(i, \"updates\")\n",
    "            for node, updates in event.items():\n",
    "                # A simple approach to handle agent interrupts.\n",
    "                # In a more sophisticated implementation, we could add\n",
    "                # some structured ChatMessage type to return the interrupt value.\n",
    "                if node == \"__interrupt__\":\n",
    "                    \n",
    "                    print(i, \"updates -> __interrupt__\")\n",
    "                    \n",
    "                    for interrupt in updates:\n",
    "                        print(i, \"updates -> __interrupt__ -> interrupt in updates\")\n",
    "                        new_messages.append(AIMessage(content=interrupt.value))\n",
    "                    continue\n",
    "\n",
    "                updates = updates or {}\n",
    "                update_messages = updates.get(\"messages\", [])\n",
    "\n",
    "                # special cases for using langgraph-supervisor library\n",
    "                if node == \"supervisor\":\n",
    "                    print(i, \"updates -> supervisor\")\n",
    "                    # Get only the last AIMessage since supervisor includes all previous messages\n",
    "                    ai_messages = [msg for msg in update_messages if isinstance(msg, AIMessage)]\n",
    "                    if ai_messages:\n",
    "                        print(i, \"updates -> supervisor -> aimessage\")\n",
    "                        update_messages = [ai_messages[-1]]\n",
    "\n",
    "                if node in (\"research_expert\", \"math_expert\"):\n",
    "                    print(i, \"updates -> [research_expert, math_expert]\")\n",
    "                    # By default the sub-agent output is returned as an AIMessage.\n",
    "                    # Convert it to a ToolMessage so it displays in the UI as a tool response.\n",
    "                    msg = ToolMessage(\n",
    "                        content=update_messages[0].content,\n",
    "                        name=node,\n",
    "                        tool_call_id=\"\",\n",
    "                    )\n",
    "                    update_messages = [msg]\n",
    "\n",
    "                new_messages.extend(update_messages)\n",
    "\n",
    "        if stream_mode == \"custom\":\n",
    "            print(i, \"custom\")\n",
    "            new_messages = [event]\n",
    "\n",
    "        # LangGraph streaming may emit tuples: (field_name, field_value)\n",
    "        # e.g. ('content', <str>), ('tool_calls', [ToolCall,...]), ('additional_kwargs', {...}), etc.\n",
    "        # We accumulate only supported fields into `parts` and skip unsupported metadata.\n",
    "        # More info at: https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/\n",
    "        processed_messages = []\n",
    "        current_message: dict[str, Any] = {}\n",
    "\n",
    "        for message in new_messages:\n",
    "            print(i, \"common block -> isinstance(message, tuple)\")\n",
    "            if isinstance(message, tuple):\n",
    "                key, value = message\n",
    "                # Store parts in temporary dict\n",
    "                current_message[key] = value\n",
    "            else:\n",
    "                # Add complete message if we have one in progress\n",
    "                if current_message:\n",
    "                    print(i, \"common block -> else: current_message\")\n",
    "                    processed_messages.append(_create_ai_message(current_message))\n",
    "                    current_message = {}\n",
    "                processed_messages.append(message)\n",
    "\n",
    "        # Add any remaining message parts\n",
    "        if current_message:\n",
    "            print(i, \"common block -> if: current_message\")\n",
    "            processed_messages.append(_create_ai_message(current_message))\n",
    "\n",
    "        for message in processed_messages:\n",
    "            print(i, \"common block -> [message in processed_messages]\")\n",
    "            try:\n",
    "                chat_message = langchain_to_chat_message(message)\n",
    "                chat_message.run_id = str(run_id)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'error', 'content': 'Unexpected error', 'error': str(e)})}\\n\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # LangGraph re-sends the input message, which feels weird, so drop it\n",
    "            if chat_message.type == \"human\" and chat_message.content == user_input.message:\n",
    "                print(i, \"common block -> [if chat_message.type == human and chat_message.content == user_input.message]\")\n",
    "                continue\n",
    "\n",
    "            print(\n",
    "                f\"data: {json.dumps({'type': 'message', 'content': chat_message.model_dump()})}\\n\"\n",
    "            )\n",
    "\n",
    "        if stream_mode == \"messages\":\n",
    "            print(i, \"messages\")\n",
    "            if not True:  # user_input.stream_tokens (default=True). see `schema.schema` -> `StreamInput`\n",
    "                continue\n",
    "\n",
    "            msg, metadata = event\n",
    "\n",
    "            if \"skip_stream\" in metadata.get(\"tags\", []):\n",
    "                print(i, \"messages -> skip_stream\")\n",
    "                continue\n",
    "\n",
    "            # For some reason, astream(\"messages\") causes non-LLM nodes to send extra messages.\n",
    "            # Drop them.\n",
    "            if not isinstance(msg, AIMessageChunk):\n",
    "                print(i, \"messages -> [if not isinstance(msg, AIMessageChunk)]\")\n",
    "                continue\n",
    "\n",
    "            content = remove_tool_calls(msg.content)\n",
    "            if content:\n",
    "                # Actually print the token stream (previously this was constructed but not printed)\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'token', 'content': convert_message_content_to_string(content)})}\\n\"\n",
    "                )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"data: {json.dumps({'type': 'error', 'content': 'Internal server error', 'error': str(e)})}\\n\"\n",
    "    )\n",
    "finally:\n",
    "    print(\"data: [DONE]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47021137-021a-4e03-b1aa-ebd15ba8fc7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fe2bf0-2434-4325-9a31-57b9872c844b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf4f68d6-ca1d-4108-bcee-d47d2e3f5b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165.999636"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2 + 7 + 6.090876) * ( 7+3 +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe147621-aa07-443c-b454-e96cae00d178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1441070c-3a10-4742-87f3-1e370e764f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 updates\n",
      "1 updates -> supervisor\n",
      "1 updates -> supervisor -> aimessage\n",
      "1 common block -> isinstance(message, tuple)\n",
      "1 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"\", \"tool_calls\": [{\"name\": \"transfer_to_research_expert\", \"args\": {}, \"id\": \"call_zb13m4mexuARAhVvfPHNdGGK\", \"type\": \"tool_call\"}], \"tool_call_id\": null, \"run_id\": \"70bb1c7c-6c67-4bcd-a299-08a7f33561b3\", \"response_metadata\": {\"finish_reason\": \"tool_calls\", \"model_name\": \"gpt-4o-mini-2024-07-18\", \"system_fingerprint\": \"fp_34a54ae93c\", \"service_tier\": \"default\"}, \"custom_data\": {}}}\n",
      "\n",
      "2 messages\n",
      "2 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "3 messages\n",
      "3 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "4 messages\n",
      "4 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "5 updates\n",
      "5 updates -> [research_expert, math_expert]\n",
      "5 common block -> isinstance(message, tuple)\n",
      "5 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"tool\", \"content\": \"As of 2024, the headcounts for the FAANG companies are as follows:\\n\\n1. **Facebook (Meta)**: 67,317 employees\\n2. **Apple**: 164,000 employees\\n3. **Amazon**: 1,551,000 employees\\n4. **Netflix**: 14,000 employees\\n5. **Google (Alphabet)**: 181,269 employees\", \"tool_calls\": [], \"tool_call_id\": \"\", \"run_id\": \"70bb1c7c-6c67-4bcd-a299-08a7f33561b3\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "6 messages\n",
      "6 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "7 updates\n",
      "7 updates -> supervisor\n",
      "7 updates -> supervisor -> aimessage\n",
      "7 common block -> isinstance(message, tuple)\n",
      "7 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"The headcounts for the FAANG companies in 2024 are as follows:\\n\\n1. **Facebook (Meta)**: 67,317 employees\\n2. **Apple**: 164,000 employees\\n3. **Amazon**: 1,551,000 employees\\n4. **Netflix**: 14,000 employees\\n5. **Google (Alphabet)**: 181,269 employees\", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"70bb1c7c-6c67-4bcd-a299-08a7f33561b3\", \"response_metadata\": {\"finish_reason\": \"stop\", \"model_name\": \"gpt-4o-mini-2024-07-18\", \"system_fingerprint\": \"fp_34a54ae93c\", \"service_tier\": \"default\"}, \"custom_data\": {}}}\n",
      "\n",
      "data: [DONE]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from uuid import UUID, uuid4\n",
    "config = {\"configurable\": {\"thread_id\": f\"{str(uuid4())}\", \"user_id\": f\"{str(uuid4())}\"}}\n",
    "run_id    = uuid4()\n",
    "\n",
    "\n",
    "# User input to create a profile memory\n",
    "m = 'FAANG company headcounts in 2024'\n",
    "input_messages = [HumanMessage(content=m)]\n",
    "user_input: UserInput = UserInput(message=m)\n",
    "#run_id = \"nkljwkd\"\n",
    "\n",
    "i = 0\n",
    "try:\n",
    "    # Process streamed events from the graph and yield messages over the SSE stream.\n",
    "    async for stream_event in langgraph_supervisor_agent.astream(\n",
    "        {\"messages\": input_messages},\n",
    "        config,\n",
    "        stream_mode=[\"updates\", \"messages\", \"custom\"],\n",
    "    ):\n",
    "        i += 1\n",
    "        if not isinstance(stream_event, tuple):\n",
    "            continue\n",
    "\n",
    "        stream_mode, event = stream_event\n",
    "#        print(type(stream_mode))\n",
    "        new_messages = []\n",
    "\n",
    "        if stream_mode == \"updates\":\n",
    "            print(i, \"updates\")\n",
    "            for node, updates in event.items():\n",
    "                # A simple approach to handle agent interrupts.\n",
    "                # In a more sophisticated implementation, we could add\n",
    "                # some structured ChatMessage type to return the interrupt value.\n",
    "                if node == \"__interrupt__\":\n",
    "                    \n",
    "                    print(i, \"updates -> __interrupt__\")\n",
    "                    \n",
    "                    for interrupt in updates:\n",
    "                        print(i, \"updates -> __interrupt__ -> interrupt in updates\")\n",
    "                        new_messages.append(AIMessage(content=interrupt.value))\n",
    "                    continue\n",
    "\n",
    "                updates = updates or {}\n",
    "                update_messages = updates.get(\"messages\", [])\n",
    "\n",
    "                # special cases for using langgraph-supervisor library\n",
    "                if node == \"supervisor\":\n",
    "                    print(i, \"updates -> supervisor\")\n",
    "                    # Get only the last AIMessage since supervisor includes all previous messages\n",
    "                    ai_messages = [msg for msg in update_messages if isinstance(msg, AIMessage)]\n",
    "                    if ai_messages:\n",
    "                        print(i, \"updates -> supervisor -> aimessage\")\n",
    "                        update_messages = [ai_messages[-1]]\n",
    "\n",
    "                if node in (\"research_expert\", \"math_expert\"):\n",
    "                    print(i, \"updates -> [research_expert, math_expert]\")\n",
    "                    # By default the sub-agent output is returned as an AIMessage.\n",
    "                    # Convert it to a ToolMessage so it displays in the UI as a tool response.\n",
    "                    msg = ToolMessage(\n",
    "                        content=update_messages[0].content,\n",
    "                        name=node,\n",
    "                        tool_call_id=\"\",\n",
    "                    )\n",
    "                    update_messages = [msg]\n",
    "\n",
    "                new_messages.extend(update_messages)\n",
    "\n",
    "        if stream_mode == \"custom\":\n",
    "            print(i, \"custom\")\n",
    "            new_messages = [event]\n",
    "\n",
    "        # LangGraph streaming may emit tuples: (field_name, field_value)\n",
    "        # e.g. ('content', <str>), ('tool_calls', [ToolCall,...]), ('additional_kwargs', {...}), etc.\n",
    "        # We accumulate only supported fields into `parts` and skip unsupported metadata.\n",
    "        # More info at: https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/\n",
    "        processed_messages = []\n",
    "        current_message: dict[str, Any] = {}\n",
    "\n",
    "        for message in new_messages:\n",
    "            print(i, \"common block -> isinstance(message, tuple)\")\n",
    "            if isinstance(message, tuple):\n",
    "                key, value = message\n",
    "                # Store parts in temporary dict\n",
    "                current_message[key] = value\n",
    "            else:\n",
    "                # Add complete message if we have one in progress\n",
    "                if current_message:\n",
    "                    print(i, \"common block -> else: current_message\")\n",
    "                    processed_messages.append(_create_ai_message(current_message))\n",
    "                    current_message = {}\n",
    "                processed_messages.append(message)\n",
    "\n",
    "        # Add any remaining message parts\n",
    "        if current_message:\n",
    "            print(i, \"common block -> if: current_message\")\n",
    "            processed_messages.append(_create_ai_message(current_message))\n",
    "\n",
    "        for message in processed_messages:\n",
    "            print(i, \"common block -> [message in processed_messages]\")\n",
    "            try:\n",
    "                chat_message = langchain_to_chat_message(message)\n",
    "                chat_message.run_id = str(run_id)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'error', 'content': 'Unexpected error', 'error': str(e)})}\\n\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # LangGraph re-sends the input message, which feels weird, so drop it\n",
    "            if chat_message.type == \"human\" and chat_message.content == user_input.message:\n",
    "                print(i, \"common block -> [if chat_message.type == human and chat_message.content == user_input.message]\")\n",
    "                continue\n",
    "\n",
    "            print(\n",
    "                f\"data: {json.dumps({'type': 'message', 'content': chat_message.model_dump()})}\\n\"\n",
    "            )\n",
    "\n",
    "        if stream_mode == \"messages\":\n",
    "            print(i, \"messages\")\n",
    "            if not True:  # user_input.stream_tokens (default=True). see `schema.schema` -> `StreamInput`\n",
    "                continue\n",
    "\n",
    "            msg, metadata = event\n",
    "\n",
    "            if \"skip_stream\" in metadata.get(\"tags\", []):\n",
    "                print(i, \"messages -> skip_stream\")\n",
    "                continue\n",
    "\n",
    "            # For some reason, astream(\"messages\") causes non-LLM nodes to send extra messages.\n",
    "            # Drop them.\n",
    "            if not isinstance(msg, AIMessageChunk):\n",
    "                print(i, \"messages -> [if not isinstance(msg, AIMessageChunk)]\")\n",
    "                continue\n",
    "\n",
    "            content = remove_tool_calls(msg.content)\n",
    "            if content:\n",
    "                # Actually print the token stream (previously this was constructed but not printed)\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'token', 'content': convert_message_content_to_string(content)})}\\n\"\n",
    "                )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"data: {json.dumps({'type': 'error', 'content': 'Internal server error', 'error': str(e)})}\\n\"\n",
    "    )\n",
    "finally:\n",
    "    print(\"data: [DONE]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eb8a13-fdc5-48b2-8b4b-99878e9c7243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1df44-00fa-4a25-9fa2-051304f4addd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e659c5e-3302-422e-b115-fa5a6fe91865",
   "metadata": {},
   "source": [
    "# RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54c00732-ff9a-4290-883c-241360a2ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Make sure the .env from the repo root is loaded into the current process\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(\".env\", usecwd=True))  # searches upward from CWD\n",
    "\n",
    "import os\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found after loading .env\"\n",
    "\n",
    "# 2) Ensure the project 'src' is on sys.path\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # now 'src' is on path\n",
    "\n",
    "# --- Option A: import via the package (may import other agents too)\n",
    "from agents.rag_assistant import rag_assistant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d8e6fea-31ab-497c-808e-eb52198a7618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualize graph\n",
    "from IPython.display import Image, display\n",
    "display(Image(rag_assistant.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cfe0cd-742f-407f-9e71-25cce0e321dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b5d5392-dc44-4f5b-9937-fea589837ca4",
   "metadata": {},
   "source": [
    "# Creating a RAG assistant\n",
    "\n",
    "You can build a RAG assistant using a Chroma database.\n",
    "\n",
    "## Setting up Chroma\n",
    "\n",
    "To create a Chroma database:\n",
    "\n",
    "1. Add the data you want to use to a folder, i.e. `./data`, Word and PDF files are currently supported.\n",
    "2. Open [`create_chroma_db.py` file](./scripts/create_chroma_db.py) and set the folder_path variable to the path to your data i.e. `./data`.\n",
    "3. You can change the database name, chunk size and overlap size.\n",
    "4. Assuming you have already followed the [Quickstart](#quickstart) and activated the virtual environment, to create the database run:\n",
    "\n",
    "```sh\n",
    "python scripts/create_chroma_db.py\n",
    "```\n",
    "\n",
    "5. If successful, a Chroma db will be created in the repository root directory.\n",
    "\n",
    "## Configuring the RAG assistant\n",
    "\n",
    "To create a RAG assistant:\n",
    "1. Open [`tools.py` file](./src/agents/tools.py) and make sure the persist_directory is pointing to the database you created previously.\n",
    "2. Modify the amount of documents returned, currently set to 5.\n",
    "3. Update the `database_search_func` function description to accurately describe what the purpose and contents of your database is.\n",
    "4. Open [`rag_assistant.py` file](./src/agents/rag_assistant.py) and update the agent's instuctions to describe what the assistant's speciality is and what knowledge it has access to, for example:\n",
    "\n",
    "```python\n",
    "instructions = f\"\"\"\n",
    "    You are a helpful HR assistant with the ability to search a database containing information on our company's policies, benefits and handbook.\n",
    "    Today's date is {current_date}.\n",
    "\n",
    "    NOTE: THE USER CAN'T SEE THE TOOL RESPONSE.\n",
    "\n",
    "    A few things to remember:\n",
    "    - If you have access to multiple databases, gather information from a diverse range of sources before crafting your response.\n",
    "    - Please include the source of the information used in your response.\n",
    "    - Use a friendly but professional tone when replying.\n",
    "    - Only use information from the database. Do not use information from outside sources.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "5. Open [`streamlit_app.py` file](./src/streamlit_app.py) and update the agent's welcome message:\n",
    "\n",
    "```python\n",
    "WELCOME = \"\"\"Hello! I'm your AI-powered HR assistant, here to help you navigate company policies, the employee handbook, and benefits. Ask me anything!\"\"\n",
    "```\n",
    "\n",
    "6. Run the application and test your RAG assistant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40910e87-3e32-4e93-a9d2-b78b52687103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070da1b4-54cf-462d-8cc5-3065d506ca8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cabfb0-85aa-4c32-9d5b-d860aaf3a534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cc8b8fd-43b0-4a40-8e65-7101d3b38b79",
   "metadata": {},
   "source": [
    "# Self Corrective RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87add4b4-d509-40cb-b423-370fed587bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Make sure the .env from the repo root is loaded into the current process\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(\".env\", usecwd=True))  # searches upward from CWD\n",
    "\n",
    "import os\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found after loading .env\"\n",
    "\n",
    "# 2) Ensure the project 'src' is on sys.path\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # now 'src' is on path\n",
    "\n",
    "# # --- Option A: import via the package (may import other agents too)\n",
    "# from agents.interrupt_agent import interrupt_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6993d8-3544-4bb8-9b1f-507f9d783b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e200731f-92e8-42da-8ce4-52de9dc93d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d05d12f-b6fe-49c9-aac1-19a0a1a644b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c814206-e997-4452-bd07-34e460145389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda426ce-257d-4905-be14-341770f0d59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1539a432-baa6-41f0-bc4b-b1705cfd973a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     41\u001b[39m vec_client = vec_client_timescale(TIMESCALE_DB_URI)\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Compile\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# self_crag = build_rag_agent(vec_client=vec_client, vec_client_from='postgres_timescale')\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m self_crag = \u001b[43mgraph\u001b[49m.compile()\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# injecting checkpointer\u001b[39;00m\n\u001b[32m     48\u001b[39m self_crag.checkpointer=checkpointer\n",
      "\u001b[31mNameError\u001b[39m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "# from modules.agents.self_corrective_rag_agent import build_rag_agent\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from psycopg_pool import AsyncConnectionPool\n",
    "from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver\n",
    "\n",
    "from vector_databases import vec_client_timescale\n",
    "from memory import get_postgres_connection_string\n",
    "\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "import uuid\n",
    "# Generate a random UUID\n",
    "session_id = uuid.uuid4()\n",
    "# Convert UUID to string\n",
    "session_id = str(session_id)\n",
    "\n",
    "#print(uuid_str)\n",
    "\n",
    "# load_dotenv()  # Load environment variables from a .env file\n",
    "# # Access API keys and credentials\n",
    "MAIN_AGENT_DB_URI = get_postgres_connection_string()\n",
    "TIMESCALE_DB_URI  = get_postgres_connection_string()\n",
    "# OPENAI_API_KEY    = settings.OPENAI_API_KEY\n",
    "\n",
    "\n",
    "\n",
    "# Build your async pool\n",
    "pool = AsyncConnectionPool(conninfo=MAIN_AGENT_DB_URI, max_size=20, kwargs={\"autocommit\": True}, open=False)\n",
    "await pool.open()  # required for async pool\n",
    "\n",
    "\n",
    "# Create async checkpointer\n",
    "checkpointer = AsyncPostgresSaver(pool)\n",
    "await checkpointer.setup()  # create tables if needed\n",
    "\n",
    "# create timescale_db_vec_client (async version)\n",
    "vec_client_from = 'postgres_timescale'\n",
    "vec_client = vec_client_timescale(TIMESCALE_DB_URI)\n",
    "\n",
    "# Compile\n",
    "# self_crag = build_rag_agent(vec_client=vec_client, vec_client_from='postgres_timescale')\n",
    "self_crag = graph.compile()\n",
    "\n",
    "# injecting checkpointer\n",
    "self_crag.checkpointer=checkpointer\n",
    "\n",
    "\n",
    "## Visualize graph\n",
    "from IPython.display import Image, display\n",
    "display(Image(self_crag.get_graph().draw_mermaid_png()))\n",
    "######################################################################################################\n",
    "\n",
    "VERBOSE = True\n",
    "\n",
    "from langfuse.langchain import CallbackHandler\n",
    "# Initialize Langfuse CallbackHandler for Langchain (tracing)\n",
    "\n",
    "# langfuse_secret_key = os.environ[\"langfuse_secret_key\"]\n",
    "# langfuse_public_key = os.environ[\"langfuse_public_key\"]\n",
    "# langfuse_host       = os.environ[\"langfuse_host\"]\n",
    "\n",
    "user_id   = '420'\n",
    "thread_id = session_id\n",
    "tag_1     = 'langgraph'\n",
    "tag_2     = 'self_corective_rag'\n",
    "\n",
    "langfuse_handler = CallbackHandler()\n",
    " \n",
    "# for s in graph.stream({\"messages\": [HumanMessage(content = \"what the ideal boobs size?\")]},\n",
    "#                       config={\"callbacks\": [langfuse_handler], \"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}):\n",
    "#     print(s)\n",
    "\n",
    "\n",
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "\n",
    "config = {\n",
    "    \"callbacks\": [langfuse_handler],\n",
    "    \"configurable\": {\"thread_id\": thread_id, \"user_id\": user_id},\n",
    "    \"metadata\": {\n",
    "        # Langfuse special fields\n",
    "        \"langfuse_user_id\": user_id,\n",
    "        \"langfuse_session_id\": thread_id,\n",
    "        \"langfuse_tags\": [tag_1, tag_2],\n",
    "\n",
    "        # Your custom metadata\n",
    "        \"source\": \"jupyter_nb\",\n",
    "        \"feature_flag\": True,\n",
    "    },\n",
    "}\n",
    "\n",
    "# User input to create a profile memory\n",
    "input_messages = [HumanMessage(content=\"need help with accidental insurance.\")]\n",
    "\n",
    "# # Run the graph\n",
    "async for output_chunk in self_crag.astream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    pass\n",
    "output_chunk[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a4cd48-074d-4600-a848-5a456bdbd455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258ac7a-ad8a-4358-b160-cedcf970a67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5070aaf-4ec4-4259-9cd2-76eb4e1ee0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "---DECISION: QUERY/QUESTION <IS RELATED> TO ACCOUNTING---\n",
      "---RETRIEVE---\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---FINALIZING THE RESPONSE---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "PAYE stands for Pay As You Earn. It’s the system by which income tax is deducted from employees’ salaries and reported to HMRC. We can help with:\n",
      "- Calculating PAYE and National Insurance (NI) amounts\n",
      "- Submitting PAYE/NI to HMRC\n",
      "- Managing queries or disputes with HMRC\n",
      "- Related NI matters (e.g., NI number applications)\n"
     ]
    }
   ],
   "source": [
    "# User input to create a profile memory\n",
    "input_messages = [HumanMessage(content=\"paye?\")]\n",
    "\n",
    "# # Run the graph\n",
    "async for output_chunk in self_crag.astream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    pass\n",
    "output_chunk[\"messages\"][-1].pretty_print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d2f1dc-6ee5-4d2a-81ae-390c3304cc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02e3753-eeb0-4670-87db-9205a314b189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5e94937-4e00-4b0f-8772-50820edc159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Make sure the .env from the repo root is loaded into the current process\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(\".env\", usecwd=True))  # searches upward from CWD\n",
    "\n",
    "import os\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found after loading .env\"\n",
    "\n",
    "# 2) Ensure the project 'src' is on sys.path\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # now 'src' is on path\n",
    "\n",
    "from core import settings\n",
    "# # --- Option A: import via the package (may import other agents too)\n",
    "# from agents.interrupt_agent import interrupt_agent\n",
    "from schema import (\n",
    "    ChatHistory,\n",
    "    ChatHistoryInput,\n",
    "    ChatMessage,\n",
    "    Feedback,\n",
    "    FeedbackResponse,\n",
    "    ServiceMetadata,\n",
    "    StreamInput,\n",
    "    UserInput,\n",
    ")\n",
    "\n",
    "from service.utils import (\n",
    "    convert_message_content_to_string,\n",
    "    langchain_to_chat_message,\n",
    "    remove_tool_calls,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a5f3b2-1422-455f-83c2-e30bd84625d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph after 1 retries. To resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mgaierror\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\urllib3\\connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\urllib3\\util\\connection.py:60\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, label empty or too long\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     61\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\socket.py:977\u001b[39m, in \u001b[36mgetaddrinfo\u001b[39m\u001b[34m(host, port, family, type, proto, flags)\u001b[39m\n\u001b[32m    976\u001b[39m addrlist = []\n\u001b[32m--> \u001b[39m\u001b[32m977\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    978\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[31mgaierror\u001b[39m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNameResolutionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:488\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    487\u001b[39m         new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\urllib3\\connection.py:753\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    752\u001b[39m sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\urllib3\\connection.py:205\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mNameResolutionError\u001b[39m: <urllib3.connection.HTTPSConnection object at 0x000002A36B08E710>: Failed to resolve 'mermaid.ink' ([Errno 11001] getaddrinfo failed)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPSConnectionPool(host='mermaid.ink', port=443): Max retries exceeded with url: /img/LS0tCmNvbmZpZzoKICBmbG93Y2hhcnQ6CiAgICBjdXJ2ZTogbGluZWFyCi0tLQpncmFwaCBURDsKCV9fc3RhcnRfXyhbPHA+X19zdGFydF9fPC9wPl0pOjo6Zmlyc3QKCXF1ZXJ5X3JlbGV2YW5jZShxdWVyeV9yZWxldmFuY2UpCglkb2N1bWVudF9zZWFyY2goZG9jdW1lbnRfc2VhcmNoKQoJZ2VuZXJhdGUoZ2VuZXJhdGUpCgl0cmFuc2Zvcm1fcXVlcnkodHJhbnNmb3JtX3F1ZXJ5KQoJY2FudF9oZWxwKGNhbnRfaGVscCkKCWZpbmFsaXplX3Jlc3BvbnNlKGZpbmFsaXplX3Jlc3BvbnNlKQoJX19lbmRfXyhbPHA+X19lbmRfXzwvcD5dKTo6Omxhc3QKCV9fc3RhcnRfXyAtLT4gcXVlcnlfcmVsZXZhbmNlOwoJY2FudF9oZWxwIC0tPiBmaW5hbGl6ZV9yZXNwb25zZTsKCWRvY3VtZW50X3NlYXJjaCAtLT4gZ2VuZXJhdGU7CglnZW5lcmF0ZSAtLi0+IGNhbnRfaGVscDsKCWdlbmVyYXRlIC0uLT4gZmluYWxpemVfcmVzcG9uc2U7CglnZW5lcmF0ZSAtLi0+IHRyYW5zZm9ybV9xdWVyeTsKCXF1ZXJ5X3JlbGV2YW5jZSAtLi0+IGNhbnRfaGVscDsKCXF1ZXJ5X3JlbGV2YW5jZSAtLi0+IGRvY3VtZW50X3NlYXJjaDsKCXRyYW5zZm9ybV9xdWVyeSAtLT4gZG9jdW1lbnRfc2VhcmNoOwoJZmluYWxpemVfcmVzcG9uc2UgLS0+IF9fZW5kX187CglnZW5lcmF0ZSAtLi0+IGdlbmVyYXRlOwoJY2xhc3NEZWYgZGVmYXVsdCBmaWxsOiNmMmYwZmYsbGluZS1oZWlnaHQ6MS4yCgljbGFzc0RlZiBmaXJzdCBmaWxsLW9wYWNpdHk6MAoJY2xhc3NEZWYgbGFzdCBmaWxsOiNiZmI2ZmMK?type=png&bgColor=!white (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A36B08E710>: Failed to resolve 'mermaid.ink' ([Errno 11001] getaddrinfo failed)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:430\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.status_code == requests.codes.ok:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\requests\\adapters.py:700\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    698\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mConnectionError\u001b[39m: HTTPSConnectionPool(host='mermaid.ink', port=443): Max retries exceeded with url: /img/LS0tCmNvbmZpZzoKICBmbG93Y2hhcnQ6CiAgICBjdXJ2ZTogbGluZWFyCi0tLQpncmFwaCBURDsKCV9fc3RhcnRfXyhbPHA+X19zdGFydF9fPC9wPl0pOjo6Zmlyc3QKCXF1ZXJ5X3JlbGV2YW5jZShxdWVyeV9yZWxldmFuY2UpCglkb2N1bWVudF9zZWFyY2goZG9jdW1lbnRfc2VhcmNoKQoJZ2VuZXJhdGUoZ2VuZXJhdGUpCgl0cmFuc2Zvcm1fcXVlcnkodHJhbnNmb3JtX3F1ZXJ5KQoJY2FudF9oZWxwKGNhbnRfaGVscCkKCWZpbmFsaXplX3Jlc3BvbnNlKGZpbmFsaXplX3Jlc3BvbnNlKQoJX19lbmRfXyhbPHA+X19lbmRfXzwvcD5dKTo6Omxhc3QKCV9fc3RhcnRfXyAtLT4gcXVlcnlfcmVsZXZhbmNlOwoJY2FudF9oZWxwIC0tPiBmaW5hbGl6ZV9yZXNwb25zZTsKCWRvY3VtZW50X3NlYXJjaCAtLT4gZ2VuZXJhdGU7CglnZW5lcmF0ZSAtLi0+IGNhbnRfaGVscDsKCWdlbmVyYXRlIC0uLT4gZmluYWxpemVfcmVzcG9uc2U7CglnZW5lcmF0ZSAtLi0+IHRyYW5zZm9ybV9xdWVyeTsKCXF1ZXJ5X3JlbGV2YW5jZSAtLi0+IGNhbnRfaGVscDsKCXF1ZXJ5X3JlbGV2YW5jZSAtLi0+IGRvY3VtZW50X3NlYXJjaDsKCXRyYW5zZm9ybV9xdWVyeSAtLT4gZG9jdW1lbnRfc2VhcmNoOwoJZmluYWxpemVfcmVzcG9uc2UgLS0+IF9fZW5kX187CglnZW5lcmF0ZSAtLi0+IGdlbmVyYXRlOwoJY2xhc3NEZWYgZGVmYXVsdCBmaWxsOiNmMmYwZmYsbGluZS1oZWlnaHQ6MS4yCgljbGFzc0RlZiBmaXJzdCBmaWxsLW9wYWNpdHk6MAoJY2xhc3NEZWYgbGFzdCBmaWxsOiNiZmI2ZmMK?type=png&bgColor=!white (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A36B08E710>: Failed to resolve 'mermaid.ink' ([Errno 11001] getaddrinfo failed)\"))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m## Visualize graph\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, display\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m display(Image(\u001b[43mself_corrective_rag\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# self_corrective_rag.store = store\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# self_corrective_rag.checkpointer = checkpointer\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\graph.py:693\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[39m\n\u001b[32m    685\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[32m    687\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    688\u001b[39m     curve_style=curve_style,\n\u001b[32m    689\u001b[39m     node_colors=node_colors,\n\u001b[32m    690\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    691\u001b[39m     frontmatter_config=frontmatter_config,\n\u001b[32m    692\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:293\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[39m\n\u001b[32m    287\u001b[39m     img_bytes = asyncio.run(\n\u001b[32m    288\u001b[39m         _render_mermaid_using_pyppeteer(\n\u001b[32m    289\u001b[39m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[32m    290\u001b[39m         )\n\u001b[32m    291\u001b[39m     )\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     img_bytes = \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    301\u001b[39m     supported_methods = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([m.value \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\code\\16_agent_services_toolkit\\agent-service-toolkit\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:462\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[39m\n\u001b[32m    457\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m             msg = (\n\u001b[32m    459\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    460\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myour graph after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m retries. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    461\u001b[39m             ) + error_msg_suffix\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[38;5;66;03m# This should not be reached, but just in case\u001b[39;00m\n\u001b[32m    465\u001b[39m msg = (\n\u001b[32m    466\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    467\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myour graph after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m retries. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    468\u001b[39m ) + error_msg_suffix\n",
      "\u001b[31mValueError\u001b[39m: Failed to reach https://mermaid.ink/ API while trying to render your graph after 1 retries. To resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
     ]
    }
   ],
   "source": [
    "# --- Option A: import via the package (may import other agents too)\n",
    "from agents.self_corrective_rag import self_corrective_rag\n",
    "\n",
    "## Visualize graph\n",
    "from IPython.display import Image, display\n",
    "display(Image(self_corrective_rag.get_graph().draw_mermaid_png()))\n",
    "\n",
    "# self_corrective_rag.store = store\n",
    "# self_corrective_rag.checkpointer = checkpointer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750fd705-6b2c-4008-a60c-272172fa84c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b5db01-1a8b-46b1-b213-cb64a7d76eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "---DECISION: QUERY/QUESTION <IS NOT RELATED> TO ACCOUNTING---\n",
      "---FINALIZING THE RESPONSE---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sorry, I cannot help you in this matter.\n"
     ]
    }
   ],
   "source": [
    "# from modules.agents.self_corrective_rag_agent import build_rag_agent\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from psycopg_pool import AsyncConnectionPool\n",
    "from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver\n",
    "\n",
    "from vector_databases import get_vec_client_timescale\n",
    "from memory import get_postgres_connection_string\n",
    "\n",
    "\n",
    "from core import settings\n",
    "\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "import uuid\n",
    "# Generate a random UUID\n",
    "session_id = uuid.uuid4()\n",
    "# Convert UUID to string\n",
    "session_id = str(session_id)\n",
    "\n",
    "#print(uuid_str)\n",
    "\n",
    "# load_dotenv()  # Load environment variables from a .env file\n",
    "# # Access API keys and credentials\n",
    "MAIN_AGENT_DB_URI = get_postgres_connection_string()\n",
    "TIMESCALE_DB_URI  = get_postgres_connection_string()\n",
    "# OPENAI_API_KEY    = settings.OPENAI_API_KEY\n",
    "\n",
    "\n",
    "\n",
    "# Build your async pool\n",
    "pool = AsyncConnectionPool(conninfo=MAIN_AGENT_DB_URI, max_size=20, kwargs={\"autocommit\": True}, open=False)\n",
    "await pool.open()  # required for async pool\n",
    "\n",
    "\n",
    "# Create async checkpointer\n",
    "checkpointer = AsyncPostgresSaver(pool)\n",
    "await checkpointer.setup()  # create tables if needed\n",
    "\n",
    "# create timescale_db_vec_client (async version)\n",
    "vec_client = get_vec_client_timescale(get_postgres_connection_string())\n",
    "\n",
    "# injecting checkpointer\n",
    "self_corrective_rag.checkpointer=checkpointer\n",
    "\n",
    "\n",
    "VERBOSE = True\n",
    "\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "langfuse_public_key = settings.LANGFUSE_PUBLIC_KEY.get_secret_value() #os.environ[\"langfuse_public_key\"]\n",
    "langfuse_secret_key = settings.LANGFUSE_SECRET_KEY.get_secret_value() #os.environ[\"langfuse_secret_key\"]\n",
    "langfuse_host       = settings.LANGFUSE_HOST       #os.environ[\"langfuse_host\"]\n",
    "\n",
    "\n",
    "\n",
    "langfuse_handler = CallbackHandler(public_key=langfuse_public_key)\n",
    "\n",
    "\n",
    "\n",
    "user_id   = '420'\n",
    "thread_id = session_id\n",
    "tag_1     = 'langgraph'\n",
    "tag_2     = 'self_corective_rag'\n",
    "\n",
    "\n",
    " \n",
    "# for s in graph.stream({\"messages\": [HumanMessage(content = \"what the ideal boobs size?\")]},\n",
    "#                       config={\"callbacks\": [langfuse_handler], \"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}):\n",
    "#     print(s)\n",
    "\n",
    "\n",
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "\n",
    "config = {\n",
    "    \"callbacks\": [langfuse_handler],\n",
    "    \"configurable\": {\"thread_id\": thread_id, \"user_id\": user_id, \"vec_client\": vec_client},\n",
    "    \"metadata\": {\n",
    "        # Langfuse special fields\n",
    "        \"langfuse_user_id\": user_id,\n",
    "        \"langfuse_session_id\": thread_id,\n",
    "        \"langfuse_tags\": [tag_1, tag_2],\n",
    "\n",
    "        # Your custom metadata\n",
    "        \"source\": \"jupyter_nb\",\n",
    "        \"feature_flag\": True,\n",
    "    },\n",
    "}\n",
    "\n",
    "# User input to create a profile memory\n",
    "input_messages = [HumanMessage(content=\"need help with accidental insurance.\")]\n",
    "\n",
    "# # Run the graph\n",
    "async for output_chunk in self_corrective_rag.astream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    pass\n",
    "output_chunk[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73504f26-1f11-414b-b5bf-5d382dfd5961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "---DECISION: QUERY/QUESTION <IS RELATED> TO ACCOUNTING---\n",
      "---RETRIEVE---\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---FINALIZING THE RESPONSE---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "PAYE (Pay As You Earn) is the income tax deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations. We offer services including calculation, submission, and management of PAYE and National Insurance contributions.\n"
     ]
    }
   ],
   "source": [
    "# User input to create a profile memory\n",
    "input_messages = [HumanMessage(content=\"paye?\")]\n",
    "\n",
    "# # Run the graph\n",
    "async for output_chunk in self_corrective_rag.astream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    pass\n",
    "output_chunk[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1247c2-fbfc-42d7-942f-0e8f322e1fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c5dfd83-5b45-401d-bb7c-57f5064cd213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "1 messages\n",
      "2 messages\n",
      "data: {\"type\": \"token\", \"content\": \"{\\\"\"}\n",
      "\n",
      "3 messages\n",
      "data: {\"type\": \"token\", \"content\": \"binary\"}\n",
      "\n",
      "4 messages\n",
      "data: {\"type\": \"token\", \"content\": \"_score\"}\n",
      "\n",
      "5 messages\n",
      "data: {\"type\": \"token\", \"content\": \"\\\":\\\"\"}\n",
      "\n",
      "6 messages\n",
      "data: {\"type\": \"token\", \"content\": \"yes\"}\n",
      "\n",
      "7 messages\n",
      "data: {\"type\": \"token\", \"content\": \"\\\"}\"}\n",
      "\n",
      "8 messages\n",
      "9 messages\n",
      "10 messages\n",
      "---DECISION: QUERY/QUESTION <IS RELATED> TO ACCOUNTING---\n",
      "11 updates\n",
      "---RETRIEVE---\n",
      "12 updates\n",
      "12 common block -> isinstance(message, tuple)\n",
      "12 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"{\\\"id\\\":null,\\\"metadata\\\":{\\\"sub_service_name\\\":\\\"paye_&_ni\\\",\\\"main_service_name\\\":\\\"accountancy_services\\\"},\\\"page_content\\\":\\\"PAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee\\u2019s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee\\u2019s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it\\u2019s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. .\\\",\\\"type\\\":\\\"Document\\\"}\\n \\n{\\\"id\\\":null,\\\"metadata\\\":{\\\"sub_service_name\\\":\\\"payroll_services\\\",\\\"main_service_name\\\":\\\"accountancy_services\\\"},\\\"page_content\\\":\\\"Payroll Services. Running payroll is now becoming increasingly complex and time consuming, With the new RTI (Real time information) regulations it is even more important now to run the payroll on time and accurately report all the information to HMRC.. If you are looking for to keep your payroll operation smooth and timely, then. Milton Accountants and Consultants are providing reliable, cost effective payroll services follows employment regulations and adhere to the highest levels of Information and Data Security Regulations..\\\",\\\"type\\\":\\\"Document\\\"}\\n \\n{\\\"id\\\":null,\\\"metadata\\\":{\\\"sub_service_name\\\":\\\"taxation\\\",\\\"main_service_name\\\":\\\"accountancy_services\\\"},\\\"page_content\\\":\\\"Taxation. . Our professionals have vast and extensive function knowledge that is accompanied by technical proficiency. We understand your needs and business issues, which help us formulating business feasible and tax compliant solutions for you.. . Effective and efficient tax services provided by us give a competitive advantage by lowering the tax and administrative costs yet keeping your business compliant with the tax laws and regulations.. . Our variety of Taxation Services includes:. .  . VAT (Value added Tax). .  . . The decisions on whether it applies are taken every day on charges applied by businesses to their customers. Incompetence and wrong decisions are made, can led you to waste to time and financial resources.. . We\\u2019ll help you choose the right VAT scheme, and make sure you understand and comply with VAT laws and regulations. We also keeping up to date with the latest VAT legislation, our clients can be confident that they are being compliant with the VAT regulation.. .     Services that we offer to VAT client:.     Application to enroll on the VAT scheme.     Recommend the most suitable VAT scheme to join.     VAT planning for tax saving.     Complete your VAT return (avoiding any penalties).     Attendance for VAT inspections. .  . PAYE and NI. .  . . Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee\\u2019s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee\\u2019s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it\\u2019s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. .  . . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. . Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.\\u2019stax advisors also ensured that right amount of tax is paid as well as on time.. .  . . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues. .\\\",\\\"type\\\":\\\"Document\\\"}\\n \\n{\\\"id\\\":null,\\\"metadata\\\":{\\\"sub_service_name\\\":\\\"statutory_accounts\\\",\\\"main_service_name\\\":\\\"accountancy_services\\\"},\\\"page_content\\\":\\\"Statutory accounts. . Its Duty of the Directors / PSC to file accounts and reports with the registrar for each financial year, for statutory accounts Milton accountants and Consultants team\\u2019s services are noted as exclusive for their valuable clients. Because our team understand the importance of reliable and timely submissions.\\\",\\\"type\\\":\\\"Document\\\"}\\n \\n{\\\"id\\\":null,\\\"metadata\\\":{\\\"sub_service_name\\\":\\\"self_assessment\\\",\\\"main_service_name\\\":\\\"accountancy_services\\\"},\\\"page_content\\\":\\\"Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.\\u2019stax advisors also ensured that right amount of tax is paid as well as on time.. . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues.\\\",\\\"type\\\":\\\"Document\\\"}\\n \\n\", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"8d2d46c9-ad6c-4b67-8bd8-80224c3808a5\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "---GENERATE---\n",
      "13 messages\n",
      "14 messages\n",
      "data: {\"type\": \"token\", \"content\": \"PAY\"}\n",
      "\n",
      "15 messages\n",
      "data: {\"type\": \"token\", \"content\": \"E\"}\n",
      "\n",
      "16 messages\n",
      "data: {\"type\": \"token\", \"content\": \" (\"}\n",
      "\n",
      "17 messages\n",
      "data: {\"type\": \"token\", \"content\": \"Pay\"}\n",
      "\n",
      "18 messages\n",
      "data: {\"type\": \"token\", \"content\": \" As\"}\n",
      "\n",
      "19 messages\n",
      "data: {\"type\": \"token\", \"content\": \" You\"}\n",
      "\n",
      "20 messages\n",
      "data: {\"type\": \"token\", \"content\": \" Earn\"}\n",
      "\n",
      "21 messages\n",
      "data: {\"type\": \"token\", \"content\": \")\"}\n",
      "\n",
      "22 messages\n",
      "data: {\"type\": \"token\", \"content\": \" is\"}\n",
      "\n",
      "23 messages\n",
      "data: {\"type\": \"token\", \"content\": \" the\"}\n",
      "\n",
      "24 messages\n",
      "data: {\"type\": \"token\", \"content\": \" income\"}\n",
      "\n",
      "25 messages\n",
      "data: {\"type\": \"token\", \"content\": \" tax\"}\n",
      "\n",
      "26 messages\n",
      "data: {\"type\": \"token\", \"content\": \" deducted\"}\n",
      "\n",
      "27 messages\n",
      "data: {\"type\": \"token\", \"content\": \" from\"}\n",
      "\n",
      "28 messages\n",
      "data: {\"type\": \"token\", \"content\": \" an\"}\n",
      "\n",
      "29 messages\n",
      "data: {\"type\": \"token\", \"content\": \" employee\"}\n",
      "\n",
      "30 messages\n",
      "data: {\"type\": \"token\", \"content\": \"\\u2019s\"}\n",
      "\n",
      "31 messages\n",
      "data: {\"type\": \"token\", \"content\": \" salary\"}\n",
      "\n",
      "32 messages\n",
      "data: {\"type\": \"token\", \"content\": \" before\"}\n",
      "\n",
      "33 messages\n",
      "data: {\"type\": \"token\", \"content\": \" they\"}\n",
      "\n",
      "34 messages\n",
      "data: {\"type\": \"token\", \"content\": \" receive\"}\n",
      "\n",
      "35 messages\n",
      "data: {\"type\": \"token\", \"content\": \" it\"}\n",
      "\n",
      "36 messages\n",
      "data: {\"type\": \"token\", \"content\": \".\"}\n",
      "\n",
      "37 messages\n",
      "data: {\"type\": \"token\", \"content\": \" It\"}\n",
      "\n",
      "38 messages\n",
      "data: {\"type\": \"token\", \"content\": \" is\"}\n",
      "\n",
      "39 messages\n",
      "data: {\"type\": \"token\", \"content\": \" mandatory\"}\n",
      "\n",
      "40 messages\n",
      "data: {\"type\": \"token\", \"content\": \" by\"}\n",
      "\n",
      "41 messages\n",
      "data: {\"type\": \"token\", \"content\": \" HM\"}\n",
      "\n",
      "42 messages\n",
      "data: {\"type\": \"token\", \"content\": \"RC\"}\n",
      "\n",
      "43 messages\n",
      "data: {\"type\": \"token\", \"content\": \" regulations\"}\n",
      "\n",
      "44 messages\n",
      "data: {\"type\": \"token\", \"content\": \" to\"}\n",
      "\n",
      "45 messages\n",
      "data: {\"type\": \"token\", \"content\": \" collect\"}\n",
      "\n",
      "46 messages\n",
      "data: {\"type\": \"token\", \"content\": \" taxes\"}\n",
      "\n",
      "47 messages\n",
      "data: {\"type\": \"token\", \"content\": \" from\"}\n",
      "\n",
      "48 messages\n",
      "data: {\"type\": \"token\", \"content\": \" workers\"}\n",
      "\n",
      "49 messages\n",
      "data: {\"type\": \"token\", \"content\": \" and\"}\n",
      "\n",
      "50 messages\n",
      "data: {\"type\": \"token\", \"content\": \" employees\"}\n",
      "\n",
      "51 messages\n",
      "data: {\"type\": \"token\", \"content\": \" at\"}\n",
      "\n",
      "52 messages\n",
      "data: {\"type\": \"token\", \"content\": \" the\"}\n",
      "\n",
      "53 messages\n",
      "data: {\"type\": \"token\", \"content\": \" initial\"}\n",
      "\n",
      "54 messages\n",
      "data: {\"type\": \"token\", \"content\": \" stage\"}\n",
      "\n",
      "55 messages\n",
      "data: {\"type\": \"token\", \"content\": \" of\"}\n",
      "\n",
      "56 messages\n",
      "data: {\"type\": \"token\", \"content\": \" earning\"}\n",
      "\n",
      "57 messages\n",
      "data: {\"type\": \"token\", \"content\": \".\"}\n",
      "\n",
      "58 messages\n",
      "data: {\"type\": \"token\", \"content\": \" We\"}\n",
      "\n",
      "59 messages\n",
      "data: {\"type\": \"token\", \"content\": \" offer\"}\n",
      "\n",
      "60 messages\n",
      "data: {\"type\": \"token\", \"content\": \" services\"}\n",
      "\n",
      "61 messages\n",
      "data: {\"type\": \"token\", \"content\": \" including\"}\n",
      "\n",
      "62 messages\n",
      "data: {\"type\": \"token\", \"content\": \" calculation\"}\n",
      "\n",
      "63 messages\n",
      "data: {\"type\": \"token\", \"content\": \",\"}\n",
      "\n",
      "64 messages\n",
      "data: {\"type\": \"token\", \"content\": \" submission\"}\n",
      "\n",
      "65 messages\n",
      "data: {\"type\": \"token\", \"content\": \",\"}\n",
      "\n",
      "66 messages\n",
      "data: {\"type\": \"token\", \"content\": \" and\"}\n",
      "\n",
      "67 messages\n",
      "data: {\"type\": \"token\", \"content\": \" management\"}\n",
      "\n",
      "68 messages\n",
      "data: {\"type\": \"token\", \"content\": \" of\"}\n",
      "\n",
      "69 messages\n",
      "data: {\"type\": \"token\", \"content\": \" PAY\"}\n",
      "\n",
      "70 messages\n",
      "data: {\"type\": \"token\", \"content\": \"E\"}\n",
      "\n",
      "71 messages\n",
      "data: {\"type\": \"token\", \"content\": \" and\"}\n",
      "\n",
      "72 messages\n",
      "data: {\"type\": \"token\", \"content\": \" National\"}\n",
      "\n",
      "73 messages\n",
      "data: {\"type\": \"token\", \"content\": \" Insurance\"}\n",
      "\n",
      "74 messages\n",
      "data: {\"type\": \"token\", \"content\": \" contributions\"}\n",
      "\n",
      "75 messages\n",
      "data: {\"type\": \"token\", \"content\": \".\"}\n",
      "\n",
      "76 messages\n",
      "---CHECK HALLUCINATIONS---\n",
      "77 messages\n",
      "78 messages\n",
      "data: {\"type\": \"token\", \"content\": \"{\\\"\"}\n",
      "\n",
      "79 messages\n",
      "data: {\"type\": \"token\", \"content\": \"binary\"}\n",
      "\n",
      "80 messages\n",
      "data: {\"type\": \"token\", \"content\": \"_score\"}\n",
      "\n",
      "81 messages\n",
      "data: {\"type\": \"token\", \"content\": \"\\\":\\\"\"}\n",
      "\n",
      "82 messages\n",
      "data: {\"type\": \"token\", \"content\": \"yes\"}\n",
      "\n",
      "83 messages\n",
      "data: {\"type\": \"token\", \"content\": \"\\\"}\"}\n",
      "\n",
      "84 messages\n",
      "85 messages\n",
      "86 messages\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "87 messages\n",
      "88 messages\n",
      "data: {\"type\": \"token\", \"content\": \"{\\\"\"}\n",
      "\n",
      "89 messages\n",
      "data: {\"type\": \"token\", \"content\": \"binary\"}\n",
      "\n",
      "90 messages\n",
      "data: {\"type\": \"token\", \"content\": \"_score\"}\n",
      "\n",
      "91 messages\n",
      "data: {\"type\": \"token\", \"content\": \"\\\":\\\"\"}\n",
      "\n",
      "92 messages\n",
      "data: {\"type\": \"token\", \"content\": \"yes\"}\n",
      "\n",
      "93 messages\n",
      "data: {\"type\": \"token\", \"content\": \"\\\"}\"}\n",
      "\n",
      "94 messages\n",
      "95 messages\n",
      "96 messages\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "97 updates\n",
      "---FINALIZING THE RESPONSE---\n",
      "98 messages\n",
      "98 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "99 updates\n",
      "99 common block -> isinstance(message, tuple)\n",
      "99 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"PAYE (Pay As You Earn) is the income tax deducted from an employee\\u2019s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at the initial stage of earning. We offer services including calculation, submission, and management of PAYE and National Insurance contributions.\", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"8d2d46c9-ad6c-4b67-8bd8-80224c3808a5\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "data: [DONE]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, AIMessageChunk, AnyMessage, HumanMessage, ToolMessage\n",
    "\n",
    "import json\n",
    "from typing import Any\n",
    "from uuid import UUID, uuid4\n",
    "config = {\"configurable\": {\"thread_id\": f\"{str(uuid4())}\", \"user_id\": f\"{str(uuid4())}\", \"vec_client\":vec_client}}\n",
    "run_id    = uuid4()\n",
    "\n",
    "events = []\n",
    "\n",
    "# User input to create a profile memory\n",
    "m = 'paye?'\n",
    "input_messages = [HumanMessage(content=m)]\n",
    "user_input: UserInput = UserInput(message=m)\n",
    "#run_id = \"nkljwkd\"\n",
    "\n",
    "i = 0\n",
    "try:\n",
    "    # Process streamed events from the graph and yield messages over the SSE stream.\n",
    "    async for stream_event in self_corrective_rag.astream(\n",
    "        {\"messages\": input_messages},\n",
    "        config,\n",
    "        stream_mode=[\"updates\", \"messages\", \"custom\"],\n",
    "    ):\n",
    "        i += 1\n",
    "        if not isinstance(stream_event, tuple):\n",
    "            continue\n",
    "\n",
    "        stream_mode, event = stream_event\n",
    "        events.append(event)\n",
    "#        print(type(stream_mode))\n",
    "        new_messages = []\n",
    "\n",
    "        if stream_mode == \"updates\":\n",
    "            print(i, \"updates\")\n",
    "            for node, updates in event.items():\n",
    "                # A simple approach to handle agent interrupts.\n",
    "                # In a more sophisticated implementation, we could add\n",
    "                # some structured ChatMessage type to return the interrupt value.\n",
    "                if node == \"__interrupt__\":\n",
    "                    \n",
    "                    print(i, \"updates -> __interrupt__\")\n",
    "                    \n",
    "                    for interrupt in updates:\n",
    "                        print(i, \"updates -> __interrupt__ -> interrupt in updates\")\n",
    "                        new_messages.append(AIMessage(content=interrupt.value))\n",
    "                    continue\n",
    "\n",
    "                updates = updates or {}\n",
    "                update_messages = updates.get(\"messages\", [])\n",
    "\n",
    "                # special cases for using langgraph-supervisor library\n",
    "                if node == \"supervisor\":\n",
    "                    print(i, \"updates -> supervisor\")\n",
    "                    # Get only the last AIMessage since supervisor includes all previous messages\n",
    "                    ai_messages = [msg for msg in update_messages if isinstance(msg, AIMessage)]\n",
    "                    if ai_messages:\n",
    "                        print(i, \"updates -> supervisor -> aimessage\")\n",
    "                        update_messages = [ai_messages[-1]]\n",
    "\n",
    "                if node in (\"research_expert\", \"math_expert\"):\n",
    "                    print(i, \"updates -> [research_expert, math_expert]\")\n",
    "                    # By default the sub-agent output is returned as an AIMessage.\n",
    "                    # Convert it to a ToolMessage so it displays in the UI as a tool response.\n",
    "                    msg = ToolMessage(\n",
    "                        content=update_messages[0].content,\n",
    "                        name=node,\n",
    "                        tool_call_id=\"\",\n",
    "                    )\n",
    "                    update_messages = [msg]\n",
    "\n",
    "                new_messages.extend(update_messages)\n",
    "\n",
    "                # if node == 'document_search':\n",
    "                #     current_docs = [updates['documents'][i].model_dump_json() + \"\\n \\n\" for i in range(len(updates['documents']))]\n",
    "                #     current_docs = \"\".join(current_docs)\n",
    "                #     new_messages.append(AIMessage(content=current_docs))\n",
    "                #     continue\n",
    "\n",
    "        if stream_mode == \"custom\":\n",
    "            print(i, \"custom\")\n",
    "            new_messages = [event]\n",
    "\n",
    "        # LangGraph streaming may emit tuples: (field_name, field_value)\n",
    "        # e.g. ('content', <str>), ('tool_calls', [ToolCall,...]), ('additional_kwargs', {...}), etc.\n",
    "        # We accumulate only supported fields into `parts` and skip unsupported metadata.\n",
    "        # More info at: https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/\n",
    "        processed_messages = []\n",
    "        current_message: dict[str, Any] = {}\n",
    "\n",
    "        for message in new_messages:\n",
    "            print(i, \"common block -> isinstance(message, tuple)\")\n",
    "            if isinstance(message, tuple):\n",
    "                key, value = message\n",
    "                # Store parts in temporary dict\n",
    "                current_message[key] = value\n",
    "            else:\n",
    "                # Add complete message if we have one in progress\n",
    "                if current_message:\n",
    "                    print(i, \"common block -> else: current_message\")\n",
    "                    processed_messages.append(_create_ai_message(current_message))\n",
    "                    current_message = {}\n",
    "                processed_messages.append(message)\n",
    "\n",
    "        # Add any remaining message parts\n",
    "        if current_message:\n",
    "            print(i, \"common block -> if: current_message\")\n",
    "            processed_messages.append(_create_ai_message(current_message))\n",
    "\n",
    "        for message in processed_messages:\n",
    "            print(i, \"common block -> [message in processed_messages]\")\n",
    "            try:\n",
    "                chat_message = langchain_to_chat_message(message)\n",
    "                chat_message.run_id = str(run_id)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'error', 'content': 'Unexpected error', 'error': str(e)})}\\n\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # LangGraph re-sends the input message, which feels weird, so drop it\n",
    "            if chat_message.type == \"human\" and chat_message.content == user_input.message:\n",
    "                print(i, \"common block -> [if chat_message.type == human and chat_message.content == user_input.message]\")\n",
    "                continue\n",
    "\n",
    "            print(\n",
    "                f\"data: {json.dumps({'type': 'message', 'content': chat_message.model_dump()})}\\n\"\n",
    "            )\n",
    "\n",
    "        if stream_mode == \"messages\":\n",
    "            print(i, \"messages\")\n",
    "            if not True:  # user_input.stream_tokens (default=True). see `schema.schema` -> `StreamInput`\n",
    "                continue\n",
    "\n",
    "            msg, metadata = event\n",
    "\n",
    "            if \"skip_stream\" in metadata.get(\"tags\", []):\n",
    "                print(i, \"messages -> skip_stream\")\n",
    "                continue\n",
    "\n",
    "            # For some reason, astream(\"messages\") causes non-LLM nodes to send extra messages.\n",
    "            # Drop them.\n",
    "            if not isinstance(msg, AIMessageChunk):\n",
    "                print(i, \"messages -> [if not isinstance(msg, AIMessageChunk)]\")\n",
    "                continue\n",
    "\n",
    "            content = remove_tool_calls(msg.content)\n",
    "            if content:\n",
    "                # Actually print the token stream (previously this was constructed but not printed)\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'token', 'content': convert_message_content_to_string(content)})}\\n\"\n",
    "                )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"data: {json.dumps({'type': 'error', 'content': 'Internal server error', 'error': str(e)})}\\n\"\n",
    "    )\n",
    "finally:\n",
    "    print(\"data: [DONE]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3f19d-bcb3-42f9-a5ba-881721589fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff54edd-c1c4-46be-8f51-1ec22724690b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1ee2ee5-747f-4fc2-a2d5-9b3eeaeb3397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_search': {'documents': [Document(metadata={'sub_service_name': 'paye_&_ni', 'main_service_name': 'accountancy_services'}, page_content='PAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. .'),\n",
       "   Document(metadata={'sub_service_name': 'payroll_services', 'main_service_name': 'accountancy_services'}, page_content='Payroll Services. Running payroll is now becoming increasingly complex and time consuming, With the new RTI (Real time information) regulations it is even more important now to run the payroll on time and accurately report all the information to HMRC.. If you are looking for to keep your payroll operation smooth and timely, then. Milton Accountants and Consultants are providing reliable, cost effective payroll services follows employment regulations and adhere to the highest levels of Information and Data Security Regulations..'),\n",
       "   Document(metadata={'sub_service_name': 'taxation', 'main_service_name': 'accountancy_services'}, page_content='Taxation. . Our professionals have vast and extensive function knowledge that is accompanied by technical proficiency. We understand your needs and business issues, which help us formulating business feasible and tax compliant solutions for you.. . Effective and efficient tax services provided by us give a competitive advantage by lowering the tax and administrative costs yet keeping your business compliant with the tax laws and regulations.. . Our variety of Taxation Services includes:. .  . VAT (Value added Tax). .  . . The decisions on whether it applies are taken every day on charges applied by businesses to their customers. Incompetence and wrong decisions are made, can led you to waste to time and financial resources.. . We’ll help you choose the right VAT scheme, and make sure you understand and comply with VAT laws and regulations. We also keeping up to date with the latest VAT legislation, our clients can be confident that they are being compliant with the VAT regulation.. .     Services that we offer to VAT client:.     Application to enroll on the VAT scheme.     Recommend the most suitable VAT scheme to join.     VAT planning for tax saving.     Complete your VAT return (avoiding any penalties).     Attendance for VAT inspections. .  . PAYE and NI. .  . . Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. .  . . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. . Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. .  . . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues. .'),\n",
       "   Document(metadata={'sub_service_name': 'statutory_accounts', 'main_service_name': 'accountancy_services'}, page_content='Statutory accounts. . Its Duty of the Directors / PSC to file accounts and reports with the registrar for each financial year, for statutory accounts Milton accountants and Consultants team’s services are noted as exclusive for their valuable clients. Because our team understand the importance of reliable and timely submissions.'),\n",
       "   Document(metadata={'sub_service_name': 'self_assessment', 'main_service_name': 'accountancy_services'}, page_content='Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues.')],\n",
       "  'question': 'paye?'}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4b32c11-d6be-4742-bddc-71d243afa54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(events[11]['document_search']['documents'][0].model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f35b593-bd13-4a5b-9638-18e3e6e84407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\":null,\"metadata\":{\"sub_service_name\":\"paye_&_ni\",\"main_service_name\":\"accountancy_services\"},\"page_content\":\"PAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. .\",\"type\":\"Document\"}'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[11]['document_search']['documents'][0].model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07a85688-51fe-4794-80ac-60c66cee7c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"id\":null,\"metadata\":{\"sub_service_name\":\"paye_&_ni\",\"main_service_name\":\"accountancy_services\"},\"page_content\":\"PAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. .\",\"type\":\"Document\"}\\n \\n',\n",
       " '{\"id\":null,\"metadata\":{\"sub_service_name\":\"payroll_services\",\"main_service_name\":\"accountancy_services\"},\"page_content\":\"Payroll Services. Running payroll is now becoming increasingly complex and time consuming, With the new RTI (Real time information) regulations it is even more important now to run the payroll on time and accurately report all the information to HMRC.. If you are looking for to keep your payroll operation smooth and timely, then. Milton Accountants and Consultants are providing reliable, cost effective payroll services follows employment regulations and adhere to the highest levels of Information and Data Security Regulations..\",\"type\":\"Document\"}\\n \\n',\n",
       " '{\"id\":null,\"metadata\":{\"sub_service_name\":\"taxation\",\"main_service_name\":\"accountancy_services\"},\"page_content\":\"Taxation. . Our professionals have vast and extensive function knowledge that is accompanied by technical proficiency. We understand your needs and business issues, which help us formulating business feasible and tax compliant solutions for you.. . Effective and efficient tax services provided by us give a competitive advantage by lowering the tax and administrative costs yet keeping your business compliant with the tax laws and regulations.. . Our variety of Taxation Services includes:. .  . VAT (Value added Tax). .  . . The decisions on whether it applies are taken every day on charges applied by businesses to their customers. Incompetence and wrong decisions are made, can led you to waste to time and financial resources.. . We’ll help you choose the right VAT scheme, and make sure you understand and comply with VAT laws and regulations. We also keeping up to date with the latest VAT legislation, our clients can be confident that they are being compliant with the VAT regulation.. .     Services that we offer to VAT client:.     Application to enroll on the VAT scheme.     Recommend the most suitable VAT scheme to join.     VAT planning for tax saving.     Complete your VAT return (avoiding any penalties).     Attendance for VAT inspections. .  . PAYE and NI. .  . . Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. .  . . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. . Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. .  . . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues. .\",\"type\":\"Document\"}\\n \\n',\n",
       " '{\"id\":null,\"metadata\":{\"sub_service_name\":\"statutory_accounts\",\"main_service_name\":\"accountancy_services\"},\"page_content\":\"Statutory accounts. . Its Duty of the Directors / PSC to file accounts and reports with the registrar for each financial year, for statutory accounts Milton accountants and Consultants team’s services are noted as exclusive for their valuable clients. Because our team understand the importance of reliable and timely submissions.\",\"type\":\"Document\"}\\n \\n',\n",
       " '{\"id\":null,\"metadata\":{\"sub_service_name\":\"self_assessment\",\"main_service_name\":\"accountancy_services\"},\"page_content\":\"Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues.\",\"type\":\"Document\"}\\n \\n']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[events[11]['document_search']['documents'][i].model_dump_json() + \"\\n \\n\" for i in range(len(events[11]['document_search']['documents']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b934ca5-72bf-45dc-a052-e243ccaafe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":null,\"metadata\":{\"sub_service_name\":\"paye_&_ni\",\"main_service_name\":\"accountancy_services\"},\"page_content\":\"PAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. .\",\"type\":\"Document\"}\n",
      " \n",
      "{\"id\":null,\"metadata\":{\"sub_service_name\":\"payroll_services\",\"main_service_name\":\"accountancy_services\"},\"page_content\":\"Payroll Services. Running payroll is now becoming increasingly complex and time consuming, With the new RTI (Real time information) regulations it is even more important now to run the payroll on time and accurately report all the information to HMRC.. If you are looking for to keep your payroll operation smooth and timely, then. Milton Accountants and Consultants are providing reliable, cost effective payroll services follows employment regulations and adhere to the highest levels of Information and Data Security Regulations..\",\"type\":\"Document\"}\n",
      " \n",
      "{\"id\":null,\"metadata\":{\"sub_service_name\":\"taxation\",\"main_service_name\":\"accountancy_services\"},\"page_content\":\"Taxation. . Our professionals have vast and extensive function knowledge that is accompanied by technical proficiency. We understand your needs and business issues, which help us formulating business feasible and tax compliant solutions for you.. . Effective and efficient tax services provided by us give a competitive advantage by lowering the tax and administrative costs yet keeping your business compliant with the tax laws and regulations.. . Our variety of Taxation Services includes:. .  . VAT (Value added Tax). .  . . The decisions on whether it applies are taken every day on charges applied by businesses to their customers. Incompetence and wrong decisions are made, can led you to waste to time and financial resources.. . We’ll help you choose the right VAT scheme, and make sure you understand and comply with VAT laws and regulations. We also keeping up to date with the latest VAT legislation, our clients can be confident that they are being compliant with the VAT regulation.. .     Services that we offer to VAT client:.     Application to enroll on the VAT scheme.     Recommend the most suitable VAT scheme to join.     VAT planning for tax saving.     Complete your VAT return (avoiding any penalties).     Attendance for VAT inspections. .  . PAYE and NI. .  . . Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. .  . . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. . Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. .  . . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues. .\",\"type\":\"Document\"}\n",
      " \n",
      "{\"id\":null,\"metadata\":{\"sub_service_name\":\"statutory_accounts\",\"main_service_name\":\"accountancy_services\"},\"page_content\":\"Statutory accounts. . Its Duty of the Directors / PSC to file accounts and reports with the registrar for each financial year, for statutory accounts Milton accountants and Consultants team’s services are noted as exclusive for their valuable clients. Because our team understand the importance of reliable and timely submissions.\",\"type\":\"Document\"}\n",
      " \n",
      "{\"id\":null,\"metadata\":{\"sub_service_name\":\"self_assessment\",\"main_service_name\":\"accountancy_services\"},\"page_content\":\"Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues.\",\"type\":\"Document\"}\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join([events[11]['document_search']['documents'][i].model_dump_json() + \"\\n \\n\" for i in range(len(events[11]['document_search']['documents']))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e19219-2da7-4c86-85f7-39852bc68cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02990ec-b46d-42bf-bdb5-5193ce2a9b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84a22de-d05d-4eb0-895f-d337dc199e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47252a69-47aa-48df-aa3f-cc94c17d5d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356e316-ac18-4c94-8611-dfe946522415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef081b82-1e2b-4f79-ae03-1dc5577020fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a9e29a8-a873-438c-858f-fa2dc0cbd56e",
   "metadata": {},
   "source": [
    "# Research Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c206cdf-6561-4024-ba15-d3d01f6c8891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Make sure the .env from the repo root is loaded into the current process\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(\".env\", usecwd=True))  # searches upward from CWD\n",
    "\n",
    "import os\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found after loading .env\"\n",
    "\n",
    "# 2) Ensure the project 'src' is on sys.path\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # now 'src' is on path\n",
    "\n",
    "from core import settings\n",
    "# # --- Option A: import via the package (may import other agents too)\n",
    "# from agents.interrupt_agent import interrupt_agent\n",
    "from schema import (\n",
    "    ChatHistory,\n",
    "    ChatHistoryInput,\n",
    "    ChatMessage,\n",
    "    Feedback,\n",
    "    FeedbackResponse,\n",
    "    ServiceMetadata,\n",
    "    StreamInput,\n",
    "    UserInput,\n",
    ")\n",
    "\n",
    "from service.utils import (\n",
    "    convert_message_content_to_string,\n",
    "    langchain_to_chat_message,\n",
    "    remove_tool_calls,\n",
    ")\n",
    "from agents.agents import research_assistant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74950c2-04ac-49f2-accc-2ccae51549ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86f52f80-f856-41c3-badf-0d641ed94d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROQ_API_KEY not set, skipping LlamaGuard\n",
      "1 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "2 messages\n",
      "3 messages\n",
      "4 messages\n",
      "5 messages\n",
      "6 messages\n",
      "7 messages\n",
      "8 messages\n",
      "9 messages\n",
      "10 messages\n",
      "GROQ_API_KEY not set, skipping LlamaGuard\n",
      "11 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "11 common block -> isinstance(message, tuple)\n",
      "11 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"\", \"tool_calls\": [{\"name\": \"Calculator\", \"args\": {\"expression\": \"2+2\"}, \"id\": \"call_Mpx5cTipDuDD4gAKnufmYqP2\", \"type\": \"tool_call\"}], \"tool_call_id\": null, \"run_id\": \"2a58e59b-2a7e-4d4c-a097-ab2aadc1b1b9\", \"response_metadata\": {\"finish_reason\": \"tool_calls\", \"model_name\": \"gpt-4.1-nano-2025-04-14\", \"system_fingerprint\": \"fp_c4c155951e\", \"service_tier\": \"default\"}, \"custom_data\": {}}}\n",
      "\n",
      "12 messages\n",
      "12 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "13 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "13 common block -> isinstance(message, tuple)\n",
      "13 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"tool\", \"content\": \"4\", \"tool_calls\": [], \"tool_call_id\": \"call_Mpx5cTipDuDD4gAKnufmYqP2\", \"run_id\": \"2a58e59b-2a7e-4d4c-a097-ab2aadc1b1b9\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "14 messages\n",
      "15 messages\n",
      "data: {\"type\": \"token\", \"content\": \"2\"}\n",
      "\n",
      "16 messages\n",
      "data: {\"type\": \"token\", \"content\": \" +\"}\n",
      "\n",
      "17 messages\n",
      "data: {\"type\": \"token\", \"content\": \" \"}\n",
      "\n",
      "18 messages\n",
      "data: {\"type\": \"token\", \"content\": \"2\"}\n",
      "\n",
      "19 messages\n",
      "data: {\"type\": \"token\", \"content\": \" equals\"}\n",
      "\n",
      "20 messages\n",
      "data: {\"type\": \"token\", \"content\": \" \"}\n",
      "\n",
      "21 messages\n",
      "data: {\"type\": \"token\", \"content\": \"4\"}\n",
      "\n",
      "22 messages\n",
      "data: {\"type\": \"token\", \"content\": \".\"}\n",
      "\n",
      "23 messages\n",
      "GROQ_API_KEY not set, skipping LlamaGuard\n",
      "24 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "24 common block -> isinstance(message, tuple)\n",
      "24 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"2 + 2 equals 4.\", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"2a58e59b-2a7e-4d4c-a097-ab2aadc1b1b9\", \"response_metadata\": {\"finish_reason\": \"stop\", \"model_name\": \"gpt-4.1-nano-2025-04-14\", \"system_fingerprint\": \"fp_c4c155951e\", \"service_tier\": \"default\"}, \"custom_data\": {}}}\n",
      "\n",
      "data: [DONE]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, AIMessageChunk, AnyMessage, HumanMessage, ToolMessage\n",
    "\n",
    "import json\n",
    "from typing import Any\n",
    "from uuid import UUID, uuid4\n",
    "config = {\"configurable\": {\"thread_id\": f\"{str(uuid4())}\", \"user_id\": f\"{str(uuid4())}\"}}#, \"vec_client\":vec_client}}\n",
    "run_id    = uuid4()\n",
    "\n",
    "events = []\n",
    "\n",
    "# User input to create a profile memory\n",
    "m = '2+2=?'\n",
    "input_messages = [HumanMessage(content=m)]\n",
    "user_input: UserInput = UserInput(message=m)\n",
    "#run_id = \"nkljwkd\"\n",
    "\n",
    "i = 0\n",
    "try:\n",
    "    # Process streamed events from the graph and yield messages over the SSE stream.\n",
    "    async for stream_event in research_assistant.astream(\n",
    "        {\"messages\": input_messages},\n",
    "        config,\n",
    "        stream_mode=[\"updates\", \"messages\", \"custom\"],\n",
    "    ):\n",
    "        i += 1\n",
    "        if not isinstance(stream_event, tuple):\n",
    "            continue\n",
    "\n",
    "        stream_mode, event = stream_event\n",
    "        events.append(event)\n",
    "#        print(type(stream_mode))\n",
    "        new_messages = []\n",
    "\n",
    "        if stream_mode == \"updates\":\n",
    "            print(i, \"updates\")\n",
    "            for node, updates in event.items():\n",
    "                # A simple approach to handle agent interrupts.\n",
    "                # In a more sophisticated implementation, we could add\n",
    "                # some structured ChatMessage type to return the interrupt value.\n",
    "                if node == \"__interrupt__\":\n",
    "                    \n",
    "                    print(i, \"updates -> __interrupt__\")\n",
    "                    \n",
    "                    for interrupt in updates:\n",
    "                        print(i, \"updates -> __interrupt__ -> interrupt in updates\")\n",
    "                        new_messages.append(AIMessage(content=interrupt.value))\n",
    "                    continue\n",
    "\n",
    "                updates = updates or {}\n",
    "                print(\"update_messages = updates.get(messages, [])\")\n",
    "                update_messages = updates.get(\"messages\", [])\n",
    "\n",
    "                # special cases for using langgraph-supervisor library\n",
    "                if node == \"supervisor\":\n",
    "                    print(i, \"updates -> supervisor\")\n",
    "                    # Get only the last AIMessage since supervisor includes all previous messages\n",
    "                    ai_messages = [msg for msg in update_messages if isinstance(msg, AIMessage)]\n",
    "                    if ai_messages:\n",
    "                        print(i, \"updates -> supervisor -> aimessage\")\n",
    "                        update_messages = [ai_messages[-1]]\n",
    "\n",
    "                if node in (\"research_expert\", \"math_expert\"):\n",
    "                    print(i, \"updates -> [research_expert, math_expert]\")\n",
    "                    # By default the sub-agent output is returned as an AIMessage.\n",
    "                    # Convert it to a ToolMessage so it displays in the UI as a tool response.\n",
    "                    msg = ToolMessage(\n",
    "                        content=update_messages[0].content,\n",
    "                        name=node,\n",
    "                        tool_call_id=\"\",\n",
    "                    )\n",
    "                    update_messages = [msg]\n",
    "\n",
    "                new_messages.extend(update_messages)\n",
    "\n",
    "                # if node == 'document_search':\n",
    "                #     current_docs = [updates['documents'][i].model_dump_json() + \"\\n \\n\" for i in range(len(updates['documents']))]\n",
    "                #     current_docs = \"\".join(current_docs)\n",
    "                #     new_messages.append(AIMessage(content=current_docs))\n",
    "                #     continue\n",
    "\n",
    "        if stream_mode == \"custom\":\n",
    "            print(i, \"custom\")\n",
    "            new_messages = [event]\n",
    "\n",
    "        # LangGraph streaming may emit tuples: (field_name, field_value)\n",
    "        # e.g. ('content', <str>), ('tool_calls', [ToolCall,...]), ('additional_kwargs', {...}), etc.\n",
    "        # We accumulate only supported fields into `parts` and skip unsupported metadata.\n",
    "        # More info at: https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/\n",
    "        processed_messages = []\n",
    "        current_message: dict[str, Any] = {}\n",
    "\n",
    "        for message in new_messages:\n",
    "            print(i, \"common block -> isinstance(message, tuple)\")\n",
    "            if isinstance(message, tuple):\n",
    "                key, value = message\n",
    "                # Store parts in temporary dict\n",
    "                current_message[key] = value\n",
    "            else:\n",
    "                # Add complete message if we have one in progress\n",
    "                if current_message:\n",
    "                    print(i, \"common block -> else: current_message\")\n",
    "                    processed_messages.append(_create_ai_message(current_message))\n",
    "                    current_message = {}\n",
    "                processed_messages.append(message)\n",
    "\n",
    "        # Add any remaining message parts\n",
    "        if current_message:\n",
    "            print(i, \"common block -> if: current_message\")\n",
    "            processed_messages.append(_create_ai_message(current_message))\n",
    "\n",
    "        for message in processed_messages:\n",
    "            print(i, \"common block -> [message in processed_messages]\")\n",
    "            try:\n",
    "                chat_message = langchain_to_chat_message(message)\n",
    "                chat_message.run_id = str(run_id)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'error', 'content': 'Unexpected error', 'error': str(e)})}\\n\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # LangGraph re-sends the input message, which feels weird, so drop it\n",
    "            if chat_message.type == \"human\" and chat_message.content == user_input.message:\n",
    "                print(i, \"common block -> [if chat_message.type == human and chat_message.content == user_input.message]\")\n",
    "                continue\n",
    "\n",
    "            print(\n",
    "                f\"data: {json.dumps({'type': 'message', 'content': chat_message.model_dump()})}\\n\"\n",
    "            )\n",
    "\n",
    "        if stream_mode == \"messages\":\n",
    "            print(i, \"messages\")\n",
    "            if not True:  # user_input.stream_tokens (default=True). see `schema.schema` -> `StreamInput`\n",
    "                continue\n",
    "\n",
    "            msg, metadata = event\n",
    "\n",
    "            if \"skip_stream\" in metadata.get(\"tags\", []):\n",
    "                print(i, \"messages -> skip_stream\")\n",
    "                continue\n",
    "\n",
    "            # For some reason, astream(\"messages\") causes non-LLM nodes to send extra messages.\n",
    "            # Drop them.\n",
    "            if not isinstance(msg, AIMessageChunk):\n",
    "                print(i, \"messages -> [if not isinstance(msg, AIMessageChunk)]\")\n",
    "                continue\n",
    "\n",
    "            content = remove_tool_calls(msg.content)\n",
    "            if content:\n",
    "                # Actually print the token stream (previously this was constructed but not printed)\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'token', 'content': convert_message_content_to_string(content)})}\\n\"\n",
    "                )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"data: {json.dumps({'type': 'error', 'content': 'Internal server error', 'error': str(e)})}\\n\"\n",
    "    )\n",
    "finally:\n",
    "    print(\"data: [DONE]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac2a1c4f-f004-49d1-bef9-52960df780e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Mpx5cTipDuDD4gAKnufmYqP2', 'function': {'arguments': '{\"expression\":\"2+2\"}', 'name': 'Calculator'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'service_tier': 'default'}, id='run--2d8e4b8b-182c-4e8d-91fa-ff1c51eb681d', tool_calls=[{'name': 'Calculator', 'args': {'expression': '2+2'}, 'id': 'call_Mpx5cTipDuDD4gAKnufmYqP2', 'type': 'tool_call'}])]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40deafc6-5628-4db5-9169-d9466ba33d27",
   "metadata": {},
   "source": [
    "[AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Mpx5cTipDuDD4gAKnufmYqP2', 'function': {'arguments': '{\"expression\":\"2+2\"}', 'name': 'Calculator'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'service_tier': 'default'}, id='run--2d8e4b8b-182c-4e8d-91fa-ff1c51eb681d', tool_calls=[{'name': 'Calculator', 'args': {'expression': '2+2'}, 'id': 'call_Mpx5cTipDuDD4gAKnufmYqP2', 'type': 'tool_call'}])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40648013-12e3-4da6-90bd-ffd677bb1f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualize graph\n",
    "from IPython.display import Image, display\n",
    "display(Image(research_assistant.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65af113-9e9e-4dc8-8d97-98fdd475cd62",
   "metadata": {},
   "source": [
    "# tetsing with tool nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4b6023-7723-4f4e-8527-310829577bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Make sure the .env from the repo root is loaded into the current process\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(\".env\", usecwd=True))  # searches upward from CWD\n",
    "\n",
    "import os\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found after loading .env\"\n",
    "\n",
    "# 2) Ensure the project 'src' is on sys.path\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # now 'src' is on path\n",
    "\n",
    "from core import settings\n",
    "# # --- Option A: import via the package (may import other agents too)\n",
    "# from agents.interrupt_agent import interrupt_agent\n",
    "from schema import (\n",
    "    ChatHistory,\n",
    "    ChatHistoryInput,\n",
    "    ChatMessage,\n",
    "    Feedback,\n",
    "    FeedbackResponse,\n",
    "    ServiceMetadata,\n",
    "    StreamInput,\n",
    "    UserInput,\n",
    ")\n",
    "\n",
    "from service.utils import (\n",
    "    convert_message_content_to_string,\n",
    "    langchain_to_chat_message,\n",
    "    remove_tool_calls,\n",
    ")\n",
    "from agents.agents import research_assistant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b58688-abd1-4971-843a-fa48f141a8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timescale 5\n",
      "None PAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they r\n",
      "None Payroll Services. Running payroll is now becoming increasingly complex and time consuming, With the new RTI (Real time i\n",
      "None Taxation. . Our professionals have vast and extensive function knowledge that is accompanied by technical proficiency. W\n",
      "None Statutory accounts. . Its Duty of the Directors / PSC to file accounts and reports with the registrar for each financial\n",
      "None Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-as\n"
     ]
    }
   ],
   "source": [
    "# basic_forced_retriever_agent.py\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, List, Annotated, Optional\n",
    "from uuid import uuid4\n",
    "import json\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import StateGraph, MessagesState, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Command\n",
    "\n",
    "# --- Your project imports ---\n",
    "from vector_databases import get_docs_pinecone, get_docs_timescale\n",
    "from core import settings  # expects: settings.VEC_CLIENT, settings.PINECONE_VEC_CLIENT, settings.POSTGRES_TIMESCALE_VEC_CLIENT, settings.DEFAULT_EMBEDDING_MODEL\n",
    "\n",
    "# --------------------------- Minimal shared state ---------------------------\n",
    "class AgentState(MessagesState):\n",
    "    question: str\n",
    "    documents: Optional[List[Dict[str, Any]]]  # normalized docs\n",
    "    retrieval_source: Optional[str]\n",
    "\n",
    "# --------------------------- Helpers ---------------------------------------\n",
    "def _normalize_docs(docs: List[Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Convert Pinecone/Timescale/LC Document objects into a unified shape:\n",
    "      {\"id\": str|None, \"text\": str|None, \"metadata\": dict}\n",
    "    \"\"\"\n",
    "    out: List[Dict[str, Any]] = []\n",
    "    for d in docs or []:\n",
    "        text = getattr(d, \"reranking_field\", None)\n",
    "        if text is None:\n",
    "            text = getattr(d, \"page_content\", None)\n",
    "        meta = getattr(d, \"metadata\", {}) or {}\n",
    "        _id = getattr(d, \"id\", None) or meta.get(\"id\") or meta.get(\"source_id\")\n",
    "        out.append({\"id\": _id, \"text\": text, \"metadata\": meta})\n",
    "    return out\n",
    "\n",
    "# --------------------------- Tools (write directly to state) ----------------\n",
    "@tool(\"get_docs_pinecone\")\n",
    "async def tool_get_docs_pinecone(\n",
    "    question: str,\n",
    "    top_k: int = 5,\n",
    "    # LangGraph will inject your runtime config here; NOT exposed to the model\n",
    "    config: RunnableConfig = None,\n",
    "    # ✅ Inject the tool call id so we can build a matching ToolMessage\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId] = \"\",  # injected, never from the LLM\n",
    ") -> Command:\n",
    "    \"\"\"\n",
    "    Retrieve top-k docs from Pinecone and store them in state.documents.\n",
    "    Also appends a ToolMessage tied to the triggering tool_call_id.\n",
    "    \"\"\"\n",
    "    pc  = (config or {}).get(\"configurable\", {}).get(\"pc\")\n",
    "    idx = (config or {}).get(\"configurable\", {}).get(\"idx\")\n",
    "    docs = await get_docs_pinecone(\n",
    "        question,\n",
    "        pc=pc,\n",
    "        idx=idx,\n",
    "        embedding_model_name=settings.DEFAULT_EMBEDDING_MODEL,\n",
    "        max_results=top_k,\n",
    "    )\n",
    "    normalized = _normalize_docs(docs)\n",
    "\n",
    "    tool_msg = ToolMessage(\n",
    "        content=json.dumps({\"status\": \"ok\", \"source\": \"pinecone\", \"count\": len(normalized)}),\n",
    "        tool_call_id=tool_call_id,\n",
    "        name=\"get_docs_pinecone\",\n",
    "    )\n",
    "\n",
    "    return Command(update={\n",
    "        \"messages\": [tool_msg],\n",
    "        \"documents\": normalized,\n",
    "        \"retrieval_source\": \"pinecone\",\n",
    "        \"question\": question,\n",
    "    })\n",
    "\n",
    "@tool(\"get_docs_timescale\")\n",
    "async def tool_get_docs_timescale(\n",
    "    question: str,\n",
    "    top_k: int = 5,\n",
    "    # LangGraph will inject your runtime config here; NOT exposed to the model\n",
    "    config: RunnableConfig = None,\n",
    "    # ✅ Inject the tool call id so we can build a matching ToolMessage\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId] = \"\",  # injected, never from the LLM\n",
    ") -> Command:\n",
    "    \"\"\"\n",
    "    Retrieve top-k docs from Timescale Vector and store them in state.documents.\n",
    "    Also appends a ToolMessage tied to the triggering tool_call_id.\n",
    "    \"\"\"\n",
    "    vec_client = (config or {}).get(\"configurable\", {}).get(\"vec_client\")\n",
    "    docs = await get_docs_timescale(\n",
    "        question,\n",
    "        vec_client,\n",
    "        embedding_model_name=settings.DEFAULT_EMBEDDING_MODEL,\n",
    "        max_results=top_k,\n",
    "    )\n",
    "    normalized = _normalize_docs(docs)\n",
    "\n",
    "    tool_msg = ToolMessage(\n",
    "        content=json.dumps({\"status\": \"ok\", \"source\": \"timescale\", \"count\": len(normalized)}),\n",
    "        tool_call_id=tool_call_id,\n",
    "        name=\"get_docs_timescale\",\n",
    "    )\n",
    "\n",
    "    return Command(update={\n",
    "        \"messages\": [tool_msg],\n",
    "        \"documents\": normalized,\n",
    "        \"retrieval_source\": \"timescale\",\n",
    "        \"question\": question,\n",
    "    })\n",
    "\n",
    "# --------------------------- Router: force a single tool call ---------------\n",
    "async def route_vec_client(state: AgentState, config: RunnableConfig) -> AgentState:\n",
    "    \"\"\"\n",
    "    No model choice. We programmatically inject one tool_call\n",
    "    based on settings.VEC_CLIENT.\n",
    "    \"\"\"\n",
    "    q = state.get(\"question\") or \"\"\n",
    "    call_id = f\"call_{uuid4().hex}\"\n",
    "    top_k = (config or {}).get(\"configurable\", {}).get(\"top_k\", 5)\n",
    "\n",
    "    if settings.VEC_CLIENT == settings.PINECONE_VEC_CLIENT:\n",
    "        tool_name = \"get_docs_pinecone\"\n",
    "    elif settings.VEC_CLIENT == settings.POSTGRES_TIMESCALE_VEC_CLIENT:\n",
    "        tool_name = \"get_docs_timescale\"\n",
    "    else:\n",
    "        # Return empty docs if misconfigured\n",
    "        return {\"documents\": [], \"retrieval_source\": \"invalid\", \"question\": q}\n",
    "\n",
    "    # Create an AIMessage that *already* contains the tool call.\n",
    "    forced_call = AIMessage(\n",
    "        content=\"\",\n",
    "        tool_calls=[{\"name\": tool_name, \"args\": {\"question\": q, \"top_k\": top_k}, \"id\": call_id}],\n",
    "    )\n",
    "    return {\"messages\": [forced_call], \"question\": q}\n",
    "\n",
    "# --------------------------- Build graph ------------------------------------\n",
    "def build_agent():\n",
    "    tools = [tool_get_docs_pinecone, tool_get_docs_timescale]\n",
    "    tool_node = ToolNode(tools)\n",
    "\n",
    "    graph = StateGraph(AgentState)\n",
    "    graph.set_entry_point(\"route_vec_client\")\n",
    "    graph.add_node(\"route_vec_client\", route_vec_client)\n",
    "    graph.add_node(\"force_retrieval_tool\", tool_node)\n",
    "    graph.add_edge(\"route_vec_client\", \"force_retrieval_tool\")\n",
    "    graph.add_edge(\"force_retrieval_tool\", END)\n",
    "    return graph.compile()\n",
    "\n",
    "# --------------------------- Minimal usage ----------------------------------\n",
    "# Example:\n",
    "agent = build_agent()\n",
    "\n",
    "from vector_databases import get_vec_client_timescale\n",
    "from memory import get_postgres_connection_string\n",
    "\n",
    "# create timescale_db_vec_client (async version)\n",
    "vec_client = get_vec_client_timescale(get_postgres_connection_string())\n",
    "\n",
    "state = await agent.ainvoke(\n",
    "    {\"question\": \"paye?\"},\n",
    "    config={\"configurable\": {\n",
    "        \"top_k\": 5,\n",
    "        # # If Pinecone:\n",
    "        # \"pc\": <PineconeAsyncio instance>,\n",
    "        # \"idx\": <_IndexAsyncio instance>,\n",
    "        # If Timescale:\n",
    "        \"vec_client\": vec_client,\n",
    "    }},\n",
    ")\n",
    "\n",
    "print(state[\"retrieval_source\"], len(state[\"documents\"]))\n",
    "for d in state[\"documents\"]:\n",
    "    txt = (d[\"text\"] or \"\")[:120]\n",
    "    print(d[\"id\"], txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505bbab4-47ec-47ff-a4d0-847823fa24df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualize graph\n",
    "from IPython.display import Image, display\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "654bd836-42bb-4742-bb02-60992d8f29db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={}, id='619a6092-c169-4774-bbe9-b6cad4ec6985', tool_calls=[{'name': 'get_docs_timescale', 'args': {'question': 'paye?', 'top_k': 5}, 'id': 'call_5c3fafcc219c45d3a4f0dd6f95676804', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content='{\"status\": \"ok\", \"source\": \"timescale\", \"count\": 5}', name='get_docs_timescale', id='1fd17adc-5515-4f8d-9aac-5eacb5725c7f', tool_call_id='call_5c3fafcc219c45d3a4f0dd6f95676804')],\n",
       " 'question': 'paye?',\n",
       " 'documents': [{'id': None,\n",
       "   'text': 'PAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. .',\n",
       "   'metadata': {'sub_service_name': 'paye_&_ni',\n",
       "    'main_service_name': 'accountancy_services'}},\n",
       "  {'id': None,\n",
       "   'text': 'Payroll Services. Running payroll is now becoming increasingly complex and time consuming, With the new RTI (Real time information) regulations it is even more important now to run the payroll on time and accurately report all the information to HMRC.. If you are looking for to keep your payroll operation smooth and timely, then. Milton Accountants and Consultants are providing reliable, cost effective payroll services follows employment regulations and adhere to the highest levels of Information and Data Security Regulations..',\n",
       "   'metadata': {'sub_service_name': 'payroll_services',\n",
       "    'main_service_name': 'accountancy_services'}},\n",
       "  {'id': None,\n",
       "   'text': 'Taxation. . Our professionals have vast and extensive function knowledge that is accompanied by technical proficiency. We understand your needs and business issues, which help us formulating business feasible and tax compliant solutions for you.. . Effective and efficient tax services provided by us give a competitive advantage by lowering the tax and administrative costs yet keeping your business compliant with the tax laws and regulations.. . Our variety of Taxation Services includes:. .  . VAT (Value added Tax). .  . . The decisions on whether it applies are taken every day on charges applied by businesses to their customers. Incompetence and wrong decisions are made, can led you to waste to time and financial resources.. . We’ll help you choose the right VAT scheme, and make sure you understand and comply with VAT laws and regulations. We also keeping up to date with the latest VAT legislation, our clients can be confident that they are being compliant with the VAT regulation.. .     Services that we offer to VAT client:.     Application to enroll on the VAT scheme.     Recommend the most suitable VAT scheme to join.     VAT planning for tax saving.     Complete your VAT return (avoiding any penalties).     Attendance for VAT inspections. .  . PAYE and NI. .  . . Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. .  . . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. . Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. .  . . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues. .',\n",
       "   'metadata': {'sub_service_name': 'taxation',\n",
       "    'main_service_name': 'accountancy_services'}},\n",
       "  {'id': None,\n",
       "   'text': 'Statutory accounts. . Its Duty of the Directors / PSC to file accounts and reports with the registrar for each financial year, for statutory accounts Milton accountants and Consultants team’s services are noted as exclusive for their valuable clients. Because our team understand the importance of reliable and timely submissions.',\n",
       "   'metadata': {'sub_service_name': 'statutory_accounts',\n",
       "    'main_service_name': 'accountancy_services'}},\n",
       "  {'id': None,\n",
       "   'text': 'Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues.',\n",
       "   'metadata': {'sub_service_name': 'self_assessment',\n",
       "    'main_service_name': 'accountancy_services'}}],\n",
       " 'retrieval_source': 'timescale'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb793ebf-e054-4527-a59d-a253e40b106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 messages\n",
      "1 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "2 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "2 common block -> isinstance(message, tuple)\n",
      "2 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"\", \"tool_calls\": [{\"name\": \"get_docs_timescale\", \"args\": {\"question\": \"\", \"top_k\": 5}, \"id\": \"call_585e478ee57549578c5efc2b14b08949\", \"type\": \"tool_call\"}], \"tool_call_id\": null, \"run_id\": \"e0ae5efe-3ab3-4e95-80d0-78b3af21946b\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "3 messages\n",
      "3 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "4 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "4 common block -> isinstance(message, tuple)\n",
      "4 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"tool\", \"content\": \"Error: BadRequestError('Error code: 400 - {\\\\'error\\\\': {\\\\'message\\\\': \\\"\\\\'$.input\\\\' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\\\", \\\\'type\\\\': \\\\'invalid_request_error\\\\', \\\\'param\\\\': None, \\\\'code\\\\': None}}')\\n Please fix your mistakes.\", \"tool_calls\": [], \"tool_call_id\": \"call_585e478ee57549578c5efc2b14b08949\", \"run_id\": \"e0ae5efe-3ab3-4e95-80d0-78b3af21946b\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "data: [DONE]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, AIMessageChunk, AnyMessage, HumanMessage, ToolMessage\n",
    "\n",
    "import json\n",
    "from typing import Any\n",
    "from uuid import UUID, uuid4\n",
    "config = {\"configurable\": {\"thread_id\": f\"{str(uuid4())}\", \"user_id\": f\"{str(uuid4())}\", \"vec_client\":vec_client}}\n",
    "run_id    = uuid4()\n",
    "\n",
    "events = []\n",
    "\n",
    "# User input to create a profile memory\n",
    "m = 'paye?'\n",
    "input_messages = [HumanMessage(content=m)]\n",
    "user_input: UserInput = UserInput(message=m)\n",
    "#run_id = \"nkljwkd\"\n",
    "\n",
    "i = 0\n",
    "try:\n",
    "    # Process streamed events from the graph and yield messages over the SSE stream.\n",
    "    async for stream_event in agent.astream(\n",
    "        {\"messages\": input_messages},\n",
    "        config,\n",
    "        stream_mode=[\"updates\", \"messages\", \"custom\"],\n",
    "    ):\n",
    "        i += 1\n",
    "        if not isinstance(stream_event, tuple):\n",
    "            continue\n",
    "\n",
    "        stream_mode, event = stream_event\n",
    "        events.append(event)\n",
    "#        print(type(stream_mode))\n",
    "        new_messages = []\n",
    "\n",
    "        if stream_mode == \"updates\":\n",
    "            print(i, \"updates\")\n",
    "            for node, updates in event.items():\n",
    "                # A simple approach to handle agent interrupts.\n",
    "                # In a more sophisticated implementation, we could add\n",
    "                # some structured ChatMessage type to return the interrupt value.\n",
    "                if node == \"__interrupt__\":\n",
    "                    \n",
    "                    print(i, \"updates -> __interrupt__\")\n",
    "                    \n",
    "                    for interrupt in updates:\n",
    "                        print(i, \"updates -> __interrupt__ -> interrupt in updates\")\n",
    "                        new_messages.append(AIMessage(content=interrupt.value))\n",
    "                    continue\n",
    "\n",
    "                updates = updates or {}\n",
    "                print(\"update_messages = updates.get(messages, [])\")\n",
    "                update_messages = updates.get(\"messages\", [])\n",
    "\n",
    "                # special cases for using langgraph-supervisor library\n",
    "                if node == \"supervisor\":\n",
    "                    print(i, \"updates -> supervisor\")\n",
    "                    # Get only the last AIMessage since supervisor includes all previous messages\n",
    "                    ai_messages = [msg for msg in update_messages if isinstance(msg, AIMessage)]\n",
    "                    if ai_messages:\n",
    "                        print(i, \"updates -> supervisor -> aimessage\")\n",
    "                        update_messages = [ai_messages[-1]]\n",
    "\n",
    "                if node in (\"research_expert\", \"math_expert\"):\n",
    "                    print(i, \"updates -> [research_expert, math_expert]\")\n",
    "                    # By default the sub-agent output is returned as an AIMessage.\n",
    "                    # Convert it to a ToolMessage so it displays in the UI as a tool response.\n",
    "                    msg = ToolMessage(\n",
    "                        content=update_messages[0].content,\n",
    "                        name=node,\n",
    "                        tool_call_id=\"\",\n",
    "                    )\n",
    "                    update_messages = [msg]\n",
    "\n",
    "                new_messages.extend(update_messages)\n",
    "\n",
    "                # if node == 'document_search':\n",
    "                #     current_docs = [updates['documents'][i].model_dump_json() + \"\\n \\n\" for i in range(len(updates['documents']))]\n",
    "                #     current_docs = \"\".join(current_docs)\n",
    "                #     new_messages.append(AIMessage(content=current_docs))\n",
    "                #     continue\n",
    "\n",
    "        if stream_mode == \"custom\":\n",
    "            print(i, \"custom\")\n",
    "            new_messages = [event]\n",
    "\n",
    "        # LangGraph streaming may emit tuples: (field_name, field_value)\n",
    "        # e.g. ('content', <str>), ('tool_calls', [ToolCall,...]), ('additional_kwargs', {...}), etc.\n",
    "        # We accumulate only supported fields into `parts` and skip unsupported metadata.\n",
    "        # More info at: https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/\n",
    "        processed_messages = []\n",
    "        current_message: dict[str, Any] = {}\n",
    "\n",
    "        for message in new_messages:\n",
    "            print(i, \"common block -> isinstance(message, tuple)\")\n",
    "            if isinstance(message, tuple):\n",
    "                key, value = message\n",
    "                # Store parts in temporary dict\n",
    "                current_message[key] = value\n",
    "            else:\n",
    "                # Add complete message if we have one in progress\n",
    "                if current_message:\n",
    "                    print(i, \"common block -> else: current_message\")\n",
    "                    processed_messages.append(_create_ai_message(current_message))\n",
    "                    current_message = {}\n",
    "                processed_messages.append(message)\n",
    "\n",
    "        # Add any remaining message parts\n",
    "        if current_message:\n",
    "            print(i, \"common block -> if: current_message\")\n",
    "            processed_messages.append(_create_ai_message(current_message))\n",
    "\n",
    "        for message in processed_messages:\n",
    "            print(i, \"common block -> [message in processed_messages]\")\n",
    "            try:\n",
    "                chat_message = langchain_to_chat_message(message)\n",
    "                chat_message.run_id = str(run_id)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'error', 'content': 'Unexpected error', 'error': str(e)})}\\n\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # LangGraph re-sends the input message, which feels weird, so drop it\n",
    "            if chat_message.type == \"human\" and chat_message.content == user_input.message:\n",
    "                print(i, \"common block -> [if chat_message.type == human and chat_message.content == user_input.message]\")\n",
    "                continue\n",
    "\n",
    "            print(\n",
    "                f\"data: {json.dumps({'type': 'message', 'content': chat_message.model_dump()})}\\n\"\n",
    "            )\n",
    "\n",
    "        if stream_mode == \"messages\":\n",
    "            print(i, \"messages\")\n",
    "            if not True:  # user_input.stream_tokens (default=True). see `schema.schema` -> `StreamInput`\n",
    "                continue\n",
    "\n",
    "            msg, metadata = event\n",
    "\n",
    "            if \"skip_stream\" in metadata.get(\"tags\", []):\n",
    "                print(i, \"messages -> skip_stream\")\n",
    "                continue\n",
    "\n",
    "            # For some reason, astream(\"messages\") causes non-LLM nodes to send extra messages.\n",
    "            # Drop them.\n",
    "            if not isinstance(msg, AIMessageChunk):\n",
    "                print(i, \"messages -> [if not isinstance(msg, AIMessageChunk)]\")\n",
    "                continue\n",
    "\n",
    "            content = remove_tool_calls(msg.content)\n",
    "            if content:\n",
    "                # Actually print the token stream (previously this was constructed but not printed)\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'token', 'content': convert_message_content_to_string(content)})}\\n\"\n",
    "                )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"data: {json.dumps({'type': 'error', 'content': 'Internal server error', 'error': str(e)})}\\n\"\n",
    "    )\n",
    "finally:\n",
    "    print(\"data: [DONE]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22b7cfd-f6d8-4ece-99e5-be2415af7517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27778e2d-0cdb-4b27-baa1-a38307d3c7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d52fc0f-e27b-4098-aa00-d766b806f5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33614d-601b-45a2-8b39-f512293a151e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61901e0e-75a6-4f85-8653-7e42d1513935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Make sure the .env from the repo root is loaded into the current process\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(\".env\", usecwd=True))  # searches upward from CWD\n",
    "\n",
    "import os\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found after loading .env\"\n",
    "\n",
    "# 2) Ensure the project 'src' is on sys.path\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # now 'src' is on path\n",
    "\n",
    "from core import settings\n",
    "# # --- Option A: import via the package (may import other agents too)\n",
    "# from agents.interrupt_agent import interrupt_agent\n",
    "from schema import (\n",
    "    ChatHistory,\n",
    "    ChatHistoryInput,\n",
    "    ChatMessage,\n",
    "    Feedback,\n",
    "    FeedbackResponse,\n",
    "    ServiceMetadata,\n",
    "    StreamInput,\n",
    "    UserInput,\n",
    ")\n",
    "\n",
    "from service.utils import (\n",
    "    convert_message_content_to_string,\n",
    "    langchain_to_chat_message,\n",
    "    remove_tool_calls,\n",
    ")\n",
    "from agents.agents import research_assistant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ffc8ee0-6a9f-4fb1-a31e-5bc7d89c3e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timescale 5\n",
      "None PAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they r\n",
      "None Payroll Services. Running payroll is now becoming increasingly complex and time consuming, With the new RTI (Real time i\n",
      "None Taxation. . Our professionals have vast and extensive function knowledge that is accompanied by technical proficiency. W\n",
      "None Statutory accounts. . Its Duty of the Directors / PSC to file accounts and reports with the registrar for each financial\n",
      "None Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-as\n"
     ]
    }
   ],
   "source": [
    "# basic_forced_retriever_agent.py\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, List, Annotated, Optional\n",
    "from uuid import uuid4\n",
    "import json\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import StateGraph, MessagesState, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Command\n",
    "\n",
    "# --- Your project imports ---\n",
    "from vector_databases import get_docs_pinecone, get_docs_timescale\n",
    "from core import settings  # expects: settings.VEC_CLIENT, settings.PINECONE_VEC_CLIENT, settings.POSTGRES_TIMESCALE_VEC_CLIENT, settings.DEFAULT_EMBEDDING_MODEL\n",
    "\n",
    "\n",
    "# --------------------------- Minimal shared state ---------------------------\n",
    "class AgentState(MessagesState):\n",
    "    question: str\n",
    "    documents: Optional[List[Dict[str, Any]]]  # normalized docs\n",
    "    retrieval_source: Optional[str]\n",
    "\n",
    "\n",
    "# --------------------------- Helpers ---------------------------------------\n",
    "def _normalize_docs(docs: List[Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Convert Pinecone/Timescale/LC Document objects into a unified shape:\n",
    "      {\"id\": str|None, \"text\": str|None, \"metadata\": dict}\n",
    "    \"\"\"\n",
    "    out: List[Dict[str, Any]] = []\n",
    "    for d in docs or []:\n",
    "        text = getattr(d, \"reranking_field\", None)\n",
    "        if text is None:\n",
    "            text = getattr(d, \"page_content\", None)\n",
    "        meta = getattr(d, \"metadata\", {}) or {}\n",
    "        _id = getattr(d, \"id\", None) or meta.get(\"id\") or meta.get(\"source_id\")\n",
    "        out.append({\"id\": _id, \"text\": text, \"metadata\": meta})\n",
    "    return out\n",
    "\n",
    "\n",
    "def _format_docs_for_tool_message(docs: List[Dict[str, Any]], max_chars_per_doc: int = 800) -> str:\n",
    "    \"\"\"\n",
    "    Create a readable plaintext for ToolMessage.content so streamers show 'my docs here ...'\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        return \"No documents found.\"\n",
    "    parts: List[str] = []\n",
    "    for i, d in enumerate(docs, start=1):\n",
    "        txt = (d.get(\"text\") or \"\").strip()\n",
    "        if max_chars_per_doc and len(txt) > max_chars_per_doc:\n",
    "            txt = txt[:max_chars_per_doc].rstrip() + \"…\"\n",
    "        meta = d.get(\"metadata\") or {}\n",
    "        src = meta.get(\"source\") or meta.get(\"url\") or meta.get(\"source_id\") or d.get(\"id\") or \"\"\n",
    "        header = f\"[{i}] {src}\".strip()\n",
    "        block = f\"{header}\\n{txt}\" if txt else header\n",
    "        parts.append(block)\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "\n",
    "# --------------------------- Tools (write directly to state) ----------------\n",
    "@tool(\"get_docs_pinecone\")\n",
    "async def tool_get_docs_pinecone(\n",
    "    # ✅ accept 'query' (preferred) and 'question' (back-compat)\n",
    "    query: Optional[str] = None,\n",
    "    question: Optional[str] = None,\n",
    "    top_k: int = 5,\n",
    "    config: RunnableConfig = None,\n",
    "    # ✅ Injected call id for matching ToolMessage\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId] = \"\",\n",
    ") -> Command:\n",
    "    \"\"\"\n",
    "    Retrieve top-k docs from Pinecone and store them in state.documents.\n",
    "    Also appends a ToolMessage tied to the triggering tool_call_id with the docs text.\n",
    "    \"\"\"\n",
    "    q = (query if query is not None else question) or \"\"\n",
    "    pc  = (config or {}).get(\"configurable\", {}).get(\"pc\")\n",
    "    idx = (config or {}).get(\"configurable\", {}).get(\"idx\")\n",
    "\n",
    "    docs = await get_docs_pinecone(\n",
    "        q,\n",
    "        pc=pc,\n",
    "        idx=idx,\n",
    "        embedding_model_name=settings.DEFAULT_EMBEDDING_MODEL,\n",
    "        max_results=top_k,\n",
    "    )\n",
    "    normalized = _normalize_docs(docs)\n",
    "\n",
    "    tool_msg = ToolMessage(\n",
    "        # 👇 Human-readable docs for your streamer (\"my docs here ...\")\n",
    "        content=_format_docs_for_tool_message(normalized),\n",
    "        tool_call_id=tool_call_id,\n",
    "        name=\"get_docs_pinecone\",\n",
    "    )\n",
    "\n",
    "    return Command(update={\n",
    "        \"messages\": [tool_msg],\n",
    "        \"documents\": normalized,\n",
    "        \"retrieval_source\": \"pinecone\",\n",
    "        \"question\": q,\n",
    "    })\n",
    "\n",
    "\n",
    "@tool(\"get_docs_timescale\")\n",
    "async def tool_get_docs_timescale(\n",
    "    # ✅ accept 'query' (preferred) and 'question' (back-compat)\n",
    "    query: Optional[str] = None,\n",
    "    question: Optional[str] = None,\n",
    "    top_k: int = 5,\n",
    "    config: RunnableConfig = None,\n",
    "    # ✅ Injected call id for matching ToolMessage\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId] = \"\",\n",
    ") -> Command:\n",
    "    \"\"\"\n",
    "    Retrieve top-k docs from Timescale Vector and store them in state.documents.\n",
    "    Also appends a ToolMessage tied to the triggering tool_call_id with the docs text.\n",
    "    \"\"\"\n",
    "    q = (query if query is not None else question) or \"\"\n",
    "    vec_client = (config or {}).get(\"configurable\", {}).get(\"vec_client\")\n",
    "\n",
    "    docs = await get_docs_timescale(\n",
    "        q,\n",
    "        vec_client,\n",
    "        embedding_model_name=settings.DEFAULT_EMBEDDING_MODEL,\n",
    "        max_results=top_k,\n",
    "    )\n",
    "    normalized = _normalize_docs(docs)\n",
    "\n",
    "    tool_msg = ToolMessage(\n",
    "        # 👇 Human-readable docs for your streamer (\"my docs here ...\")\n",
    "        content=_format_docs_for_tool_message(normalized),\n",
    "        tool_call_id=tool_call_id,\n",
    "        name=\"get_docs_timescale\",\n",
    "    )\n",
    "\n",
    "    return Command(update={\n",
    "        \"messages\": [tool_msg],\n",
    "        \"documents\": normalized,\n",
    "        \"retrieval_source\": \"timescale\",\n",
    "        \"question\": q,\n",
    "    })\n",
    "\n",
    "\n",
    "# --------------------------- Router: force a single tool call ---------------\n",
    "async def route_vec_client(state: AgentState, config: RunnableConfig) -> AgentState:\n",
    "    \"\"\"\n",
    "    No model choice. We programmatically inject one tool_call\n",
    "    based on settings.VEC_CLIENT.\n",
    "    \"\"\"\n",
    "    q = state.get(\"question\") or \"\"\n",
    "    call_id = f\"call_{uuid4().hex}\"\n",
    "    top_k = (config or {}).get(\"configurable\", {}).get(\"top_k\", 5)\n",
    "\n",
    "    if settings.VEC_CLIENT == settings.PINECONE_VEC_CLIENT:\n",
    "        tool_name = \"get_docs_pinecone\"\n",
    "    elif settings.VEC_CLIENT == settings.POSTGRES_TIMESCALE_VEC_CLIENT:\n",
    "        tool_name = \"get_docs_timescale\"\n",
    "    else:\n",
    "        # Return empty docs if misconfigured\n",
    "        return {\"documents\": [], \"retrieval_source\": \"invalid\", \"question\": q}\n",
    "\n",
    "    # ✅ Use \"query\" in args so your streamer sees {\"query\": \"paye?\"}\n",
    "    forced_call = AIMessage(\n",
    "        content=\"\",\n",
    "        tool_calls=[{\"name\": tool_name, \"args\": {\"query\": q, \"top_k\": top_k}, \"id\": call_id}],\n",
    "    )\n",
    "    return {\"messages\": [forced_call], \"question\": q}\n",
    "\n",
    "\n",
    "# --------------------------- Build graph ------------------------------------\n",
    "def build_agent():\n",
    "    tools = [tool_get_docs_pinecone, tool_get_docs_timescale]\n",
    "    tool_node = ToolNode(tools)\n",
    "\n",
    "    graph = StateGraph(AgentState)\n",
    "    graph.set_entry_point(\"route_vec_client\")\n",
    "    graph.add_node(\"route_vec_client\", route_vec_client)\n",
    "    graph.add_node(\"force_retrieval_tool\", tool_node)\n",
    "    graph.add_edge(\"route_vec_client\", \"force_retrieval_tool\")\n",
    "    graph.add_edge(\"force_retrieval_tool\", END)\n",
    "    return graph.compile()\n",
    "\n",
    "\n",
    "# --------------------------- Minimal usage ----------------------------------\n",
    "# Example:\n",
    "agent = build_agent()\n",
    "\n",
    "from vector_databases import get_vec_client_timescale\n",
    "from memory import get_postgres_connection_string\n",
    "\n",
    "# create timescale_db_vec_client (async version)\n",
    "vec_client = get_vec_client_timescale(get_postgres_connection_string())\n",
    "\n",
    "state = await agent.ainvoke(\n",
    "    {\"question\": \"paye?\"},\n",
    "    config={\"configurable\": {\n",
    "        \"top_k\": 5,\n",
    "        # # If Pinecone:\n",
    "        # \"pc\": <PineconeAsyncio instance>,\n",
    "        # \"idx\": <_IndexAsyncio instance>,\n",
    "        # If Timescale:\n",
    "        \"vec_client\": vec_client,\n",
    "    }},\n",
    ")\n",
    "\n",
    "print(state[\"retrieval_source\"], len(state[\"documents\"]))\n",
    "for d in state[\"documents\"]:\n",
    "    txt = (d[\"text\"] or \"\")[:120]\n",
    "    print(d[\"id\"], txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e521324-ae6f-4fa2-b8c4-73b9e0dfde86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={}, id='f5b7ee93-e241-4446-ac85-38d0bc91d6a9', tool_calls=[{'name': 'get_docs_timescale', 'args': {'query': 'paye?', 'top_k': 5}, 'id': 'call_de2a27ce59ba4978aa3c05582d6d216d', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content='[1]\\nPAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an em…\\n\\n[2]\\nPayroll Services. Running payroll is now becoming increasingly complex and time consuming, With the new RTI (Real time information) regulations it is even more important now to run the payroll on time and accurately report all the information to HMRC.. If you are looking for to keep your payroll operation smooth and timely, then. Milton Accountants and Consultants are providing reliable, cost effective payroll services follows employment regulations and adhere to the highest levels of Information and Data Security Regulations..\\n\\n[3]\\nTaxation. . Our professionals have vast and extensive function knowledge that is accompanied by technical proficiency. We understand your needs and business issues, which help us formulating business feasible and tax compliant solutions for you.. . Effective and efficient tax services provided by us give a competitive advantage by lowering the tax and administrative costs yet keeping your business compliant with the tax laws and regulations.. . Our variety of Taxation Services includes:. .  . VAT (Value added Tax). .  . . The decisions on whether it applies are taken every day on charges applied by businesses to their customers. Incompetence and wrong decisions are made, can led you to waste to time and financial resources.. . We’ll help you choose the right VAT scheme, and make sure you u…\\n\\n[4]\\nStatutory accounts. . Its Duty of the Directors / PSC to file accounts and reports with the registrar for each financial year, for statutory accounts Milton accountants and Consultants team’s services are noted as exclusive for their valuable clients. Because our team understand the importance of reliable and timely submissions.\\n\\n[5]\\nSelf-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes..…', name='get_docs_timescale', id='7c513c17-f637-470b-b818-62b2915ed3d1', tool_call_id='call_de2a27ce59ba4978aa3c05582d6d216d')],\n",
       " 'question': 'paye?',\n",
       " 'documents': [{'id': None,\n",
       "   'text': 'PAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. .',\n",
       "   'metadata': {'sub_service_name': 'paye_&_ni',\n",
       "    'main_service_name': 'accountancy_services'}},\n",
       "  {'id': None,\n",
       "   'text': 'Payroll Services. Running payroll is now becoming increasingly complex and time consuming, With the new RTI (Real time information) regulations it is even more important now to run the payroll on time and accurately report all the information to HMRC.. If you are looking for to keep your payroll operation smooth and timely, then. Milton Accountants and Consultants are providing reliable, cost effective payroll services follows employment regulations and adhere to the highest levels of Information and Data Security Regulations..',\n",
       "   'metadata': {'sub_service_name': 'payroll_services',\n",
       "    'main_service_name': 'accountancy_services'}},\n",
       "  {'id': None,\n",
       "   'text': 'Taxation. . Our professionals have vast and extensive function knowledge that is accompanied by technical proficiency. We understand your needs and business issues, which help us formulating business feasible and tax compliant solutions for you.. . Effective and efficient tax services provided by us give a competitive advantage by lowering the tax and administrative costs yet keeping your business compliant with the tax laws and regulations.. . Our variety of Taxation Services includes:. .  . VAT (Value added Tax). .  . . The decisions on whether it applies are taken every day on charges applied by businesses to their customers. Incompetence and wrong decisions are made, can led you to waste to time and financial resources.. . We’ll help you choose the right VAT scheme, and make sure you understand and comply with VAT laws and regulations. We also keeping up to date with the latest VAT legislation, our clients can be confident that they are being compliant with the VAT regulation.. .     Services that we offer to VAT client:.     Application to enroll on the VAT scheme.     Recommend the most suitable VAT scheme to join.     VAT planning for tax saving.     Complete your VAT return (avoiding any penalties).     Attendance for VAT inspections. .  . PAYE and NI. .  . . Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. .  . . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. . Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. .  . . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues. .',\n",
       "   'metadata': {'sub_service_name': 'taxation',\n",
       "    'main_service_name': 'accountancy_services'}},\n",
       "  {'id': None,\n",
       "   'text': 'Statutory accounts. . Its Duty of the Directors / PSC to file accounts and reports with the registrar for each financial year, for statutory accounts Milton accountants and Consultants team’s services are noted as exclusive for their valuable clients. Because our team understand the importance of reliable and timely submissions.',\n",
       "   'metadata': {'sub_service_name': 'statutory_accounts',\n",
       "    'main_service_name': 'accountancy_services'}},\n",
       "  {'id': None,\n",
       "   'text': 'Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues.',\n",
       "   'metadata': {'sub_service_name': 'self_assessment',\n",
       "    'main_service_name': 'accountancy_services'}}],\n",
       " 'retrieval_source': 'timescale'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c513eafd-2eae-43c0-b886-e8af265fada3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 messages\n",
      "1 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "2 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "2 common block -> isinstance(message, tuple)\n",
      "2 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"\", \"tool_calls\": [{\"name\": \"get_docs_timescale\", \"args\": {\"query\": \"\", \"top_k\": 5}, \"id\": \"call_f4ef26b2430e49fd82727933f1c3d668\", \"type\": \"tool_call\"}], \"tool_call_id\": null, \"run_id\": \"e2457ea3-f1cd-49f6-9a6b-03c08ecc8fad\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "3 messages\n",
      "3 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "4 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "4 common block -> isinstance(message, tuple)\n",
      "4 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"tool\", \"content\": \"Error: BadRequestError('Error code: 400 - {\\\\'error\\\\': {\\\\'message\\\\': \\\"\\\\'$.input\\\\' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\\\", \\\\'type\\\\': \\\\'invalid_request_error\\\\', \\\\'param\\\\': None, \\\\'code\\\\': None}}')\\n Please fix your mistakes.\", \"tool_calls\": [], \"tool_call_id\": \"call_f4ef26b2430e49fd82727933f1c3d668\", \"run_id\": \"e2457ea3-f1cd-49f6-9a6b-03c08ecc8fad\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "data: [DONE]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, AIMessageChunk, AnyMessage, HumanMessage, ToolMessage\n",
    "\n",
    "import json\n",
    "from typing import Any\n",
    "from uuid import UUID, uuid4\n",
    "config = {\"configurable\": {\"thread_id\": f\"{str(uuid4())}\", \"user_id\": f\"{str(uuid4())}\", \"vec_client\":vec_client}}\n",
    "run_id    = uuid4()\n",
    "\n",
    "events = []\n",
    "\n",
    "# User input to create a profile memory\n",
    "m = 'paye?'\n",
    "input_messages = [HumanMessage(content=m)]\n",
    "user_input: UserInput = UserInput(message=m)\n",
    "#run_id = \"nkljwkd\"\n",
    "\n",
    "i = 0\n",
    "try:\n",
    "    # Process streamed events from the graph and yield messages over the SSE stream.\n",
    "    async for stream_event in agent.astream(\n",
    "        {\"messages\": input_messages},\n",
    "        config,\n",
    "        stream_mode=[\"updates\", \"messages\", \"custom\"],\n",
    "    ):\n",
    "        i += 1\n",
    "        if not isinstance(stream_event, tuple):\n",
    "            continue\n",
    "\n",
    "        stream_mode, event = stream_event\n",
    "        events.append(event)\n",
    "#        print(type(stream_mode))\n",
    "        new_messages = []\n",
    "\n",
    "        if stream_mode == \"updates\":\n",
    "            print(i, \"updates\")\n",
    "            for node, updates in event.items():\n",
    "                # A simple approach to handle agent interrupts.\n",
    "                # In a more sophisticated implementation, we could add\n",
    "                # some structured ChatMessage type to return the interrupt value.\n",
    "                if node == \"__interrupt__\":\n",
    "                    \n",
    "                    print(i, \"updates -> __interrupt__\")\n",
    "                    \n",
    "                    for interrupt in updates:\n",
    "                        print(i, \"updates -> __interrupt__ -> interrupt in updates\")\n",
    "                        new_messages.append(AIMessage(content=interrupt.value))\n",
    "                    continue\n",
    "\n",
    "                updates = updates or {}\n",
    "                print(\"update_messages = updates.get(messages, [])\")\n",
    "                update_messages = updates.get(\"messages\", [])\n",
    "\n",
    "                # special cases for using langgraph-supervisor library\n",
    "                if node == \"supervisor\":\n",
    "                    print(i, \"updates -> supervisor\")\n",
    "                    # Get only the last AIMessage since supervisor includes all previous messages\n",
    "                    ai_messages = [msg for msg in update_messages if isinstance(msg, AIMessage)]\n",
    "                    if ai_messages:\n",
    "                        print(i, \"updates -> supervisor -> aimessage\")\n",
    "                        update_messages = [ai_messages[-1]]\n",
    "\n",
    "                if node in (\"research_expert\", \"math_expert\"):\n",
    "                    print(i, \"updates -> [research_expert, math_expert]\")\n",
    "                    # By default the sub-agent output is returned as an AIMessage.\n",
    "                    # Convert it to a ToolMessage so it displays in the UI as a tool response.\n",
    "                    msg = ToolMessage(\n",
    "                        content=update_messages[0].content,\n",
    "                        name=node,\n",
    "                        tool_call_id=\"\",\n",
    "                    )\n",
    "                    update_messages = [msg]\n",
    "\n",
    "                new_messages.extend(update_messages)\n",
    "\n",
    "                # if node == 'document_search':\n",
    "                #     current_docs = [updates['documents'][i].model_dump_json() + \"\\n \\n\" for i in range(len(updates['documents']))]\n",
    "                #     current_docs = \"\".join(current_docs)\n",
    "                #     new_messages.append(AIMessage(content=current_docs))\n",
    "                #     continue\n",
    "\n",
    "        if stream_mode == \"custom\":\n",
    "            print(i, \"custom\")\n",
    "            new_messages = [event]\n",
    "\n",
    "        # LangGraph streaming may emit tuples: (field_name, field_value)\n",
    "        # e.g. ('content', <str>), ('tool_calls', [ToolCall,...]), ('additional_kwargs', {...}), etc.\n",
    "        # We accumulate only supported fields into `parts` and skip unsupported metadata.\n",
    "        # More info at: https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/\n",
    "        processed_messages = []\n",
    "        current_message: dict[str, Any] = {}\n",
    "\n",
    "        for message in new_messages:\n",
    "            print(i, \"common block -> isinstance(message, tuple)\")\n",
    "            if isinstance(message, tuple):\n",
    "                key, value = message\n",
    "                # Store parts in temporary dict\n",
    "                current_message[key] = value\n",
    "            else:\n",
    "                # Add complete message if we have one in progress\n",
    "                if current_message:\n",
    "                    print(i, \"common block -> else: current_message\")\n",
    "                    processed_messages.append(_create_ai_message(current_message))\n",
    "                    current_message = {}\n",
    "                processed_messages.append(message)\n",
    "\n",
    "        # Add any remaining message parts\n",
    "        if current_message:\n",
    "            print(i, \"common block -> if: current_message\")\n",
    "            processed_messages.append(_create_ai_message(current_message))\n",
    "\n",
    "        for message in processed_messages:\n",
    "            print(i, \"common block -> [message in processed_messages]\")\n",
    "            try:\n",
    "                chat_message = langchain_to_chat_message(message)\n",
    "                chat_message.run_id = str(run_id)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'error', 'content': 'Unexpected error', 'error': str(e)})}\\n\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # LangGraph re-sends the input message, which feels weird, so drop it\n",
    "            if chat_message.type == \"human\" and chat_message.content == user_input.message:\n",
    "                print(i, \"common block -> [if chat_message.type == human and chat_message.content == user_input.message]\")\n",
    "                continue\n",
    "\n",
    "            print(\n",
    "                f\"data: {json.dumps({'type': 'message', 'content': chat_message.model_dump()})}\\n\"\n",
    "            )\n",
    "\n",
    "        if stream_mode == \"messages\":\n",
    "            print(i, \"messages\")\n",
    "            if not True:  # user_input.stream_tokens (default=True). see `schema.schema` -> `StreamInput`\n",
    "                continue\n",
    "\n",
    "            msg, metadata = event\n",
    "\n",
    "            if \"skip_stream\" in metadata.get(\"tags\", []):\n",
    "                print(i, \"messages -> skip_stream\")\n",
    "                continue\n",
    "\n",
    "            # For some reason, astream(\"messages\") causes non-LLM nodes to send extra messages.\n",
    "            # Drop them.\n",
    "            if not isinstance(msg, AIMessageChunk):\n",
    "                print(i, \"messages -> [if not isinstance(msg, AIMessageChunk)]\")\n",
    "                continue\n",
    "\n",
    "            content = remove_tool_calls(msg.content)\n",
    "            if content:\n",
    "                # Actually print the token stream (previously this was constructed but not printed)\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'token', 'content': convert_message_content_to_string(content)})}\\n\"\n",
    "                )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"data: {json.dumps({'type': 'error', 'content': 'Internal server error', 'error': str(e)})}\\n\"\n",
    "    )\n",
    "finally:\n",
    "    print(\"data: [DONE]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c7097f-0d3a-496b-9672-806b123ad54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5067c2c-cb5d-486b-af10-879743dad161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323853f8-3852-4956-bc0a-4baff5450c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddddf5d3-bf8d-480f-bae8-597571b9aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Make sure the .env from the repo root is loaded into the current process\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(\".env\", usecwd=True))  # searches upward from CWD\n",
    "\n",
    "import os\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found after loading .env\"\n",
    "\n",
    "# 2) Ensure the project 'src' is on sys.path\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # now 'src' is on path\n",
    "\n",
    "from core import settings\n",
    "# # --- Option A: import via the package (may import other agents too)\n",
    "# from agents.interrupt_agent import interrupt_agent\n",
    "from schema import (\n",
    "    ChatHistory,\n",
    "    ChatHistoryInput,\n",
    "    ChatMessage,\n",
    "    Feedback,\n",
    "    FeedbackResponse,\n",
    "    ServiceMetadata,\n",
    "    StreamInput,\n",
    "    UserInput,\n",
    ")\n",
    "\n",
    "from service.utils import (\n",
    "    convert_message_content_to_string,\n",
    "    langchain_to_chat_message,\n",
    "    remove_tool_calls,\n",
    ")\n",
    "from agents.agents import research_assistant\n",
    "\n",
    "from agents.prototype_rag_tool import prototype_rag_tool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38877489-483e-4af1-848c-333c4b0cc573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic_forced_retriever_agent.py\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, List, Annotated, Optional\n",
    "from uuid import uuid4\n",
    "import json\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage, HumanMessage\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import StateGraph, MessagesState, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Command\n",
    "\n",
    "# --- Your project imports ---\n",
    "from vector_databases import get_docs_pinecone, get_docs_timescale\n",
    "from core import settings  # expects: settings.VEC_CLIENT, settings.PINECONE_VEC_CLIENT, settings.POSTGRES_TIMESCALE_VEC_CLIENT, settings.DEFAULT_EMBEDDING_MODEL\n",
    "import openai\n",
    "openai.api_type=openai\n",
    "\n",
    "# from vector_databases import get_vec_client_timescale\n",
    "# from memory import get_postgres_connection_string\n",
    "\n",
    "# # create timescale_db_vec_client (async version)\n",
    "# vec_client = get_vec_client_timescale(get_postgres_connection_string())\n",
    "\n",
    "\n",
    "# --------------------------- Minimal shared state ---------------------------\n",
    "class AgentState(MessagesState):\n",
    "    question: str\n",
    "    documents: Optional[List[Dict[str, Any]]]  # normalized docs\n",
    "    retrieval_source: Optional[str]\n",
    "\n",
    "\n",
    "# --------------------------- Helpers ---------------------------------------\n",
    "def _normalize_docs(docs: List[Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Convert Pinecone/Timescale/LC Document objects into a unified shape:\n",
    "      {\"id\": str|None, \"text\": str|None, \"metadata\": dict}\n",
    "    \"\"\"\n",
    "    out: List[Dict[str, Any]] = []\n",
    "    for d in docs or []:\n",
    "        text = getattr(d, \"reranking_field\", None)\n",
    "        if text is None:\n",
    "            text = getattr(d, \"page_content\", None)\n",
    "        meta = getattr(d, \"metadata\", {}) or {}\n",
    "        _id = getattr(d, \"id\", None) or meta.get(\"id\") or meta.get(\"source_id\")\n",
    "        out.append({\"id\": _id, \"text\": text, \"metadata\": meta})\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- helper ---\n",
    "from typing import Optional\n",
    "import json\n",
    "\n",
    "def _format_docs_for_tool_message(\n",
    "    docs: List[Dict[str, Any]],\n",
    "    *,\n",
    "    max_chars_per_doc: Optional[int] = None,   # None => no truncation\n",
    "    include_metadata: bool = True,             # controls whether metadata is printed\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Render docs for ToolMessage.content.\n",
    "\n",
    "    For each doc:\n",
    "      [i] <best source>\n",
    "      <metadata as 1-line JSON>\n",
    "      \n",
    "      <text (optionally truncated)>\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        return \"No documents found.\"\n",
    "\n",
    "    parts: List[str] = []\n",
    "    for i, d in enumerate(docs, start=1):\n",
    "        txt = (d.get(\"text\") or \"\").strip()\n",
    "        if max_chars_per_doc and len(txt) > max_chars_per_doc:\n",
    "            txt = txt[:max_chars_per_doc].rstrip() + \"…\"\n",
    "\n",
    "        meta = d.get(\"metadata\") or {}\n",
    "        # stringify metadata (single line, JSON)\n",
    "        meta_str = json.dumps(meta, ensure_ascii=False, sort_keys=True, default=str)\n",
    "\n",
    "        src = meta.get(\"source\") or meta.get(\"url\") or meta.get(\"source_id\") or d.get(\"id\") or \"\"\n",
    "        header = f\"[{i}] {src}\".strip() if src else f\"[{i}]\"\n",
    "\n",
    "        if include_metadata:\n",
    "            block = f\"{header}\\n{meta_str}\\n\\n{txt}\" if txt else f\"{header}\\n{meta_str}\"\n",
    "        else:\n",
    "            block = f\"{header}\\n{txt}\" if txt else header\n",
    "\n",
    "        parts.append(block)\n",
    "\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _to_text(content: Any) -> str:\n",
    "    \"\"\"Best-effort to turn LC message.content into plain text.\"\"\"\n",
    "    if isinstance(content, str):\n",
    "        return content\n",
    "    if isinstance(content, list):\n",
    "        texts: List[str] = []\n",
    "        for part in content:\n",
    "            if isinstance(part, dict):\n",
    "                if part.get(\"type\") == \"text\" and \"text\" in part:\n",
    "                    texts.append(str(part[\"text\"]))\n",
    "                elif \"text\" in part:\n",
    "                    texts.append(str(part[\"text\"]))\n",
    "                elif \"content\" in part:\n",
    "                    texts.append(str(part[\"content\"]))\n",
    "            else:\n",
    "                texts.append(str(part))\n",
    "        return \"\\n\".join(t for t in texts if t)\n",
    "    return str(content)\n",
    "\n",
    "\n",
    "def _get_last_user_text(state: AgentState) -> str:\n",
    "    \"\"\"Pull the latest human message text from state.messages for streaming inputs.\"\"\"\n",
    "    msgs = state.get(\"messages\") or []\n",
    "    for msg in reversed(msgs):\n",
    "        if isinstance(msg, HumanMessage) or getattr(msg, \"type\", \"\") == \"human\":\n",
    "            return (_to_text(msg.content) or \"\").strip()\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# --------------------------- Tools (write directly to state) ----------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- tools (pinecone) ---\n",
    "@tool(\"get_docs_pinecone\")\n",
    "async def tool_get_docs_pinecone(\n",
    "    query:             Optional[str]  = None,\n",
    "    # question:          Optional[str]  = None,\n",
    "    top_k:             int            = 5,\n",
    "    max_chars_per_doc: Optional[int]  = None,   # <-- new\n",
    "    include_metadata:  bool           = True,             # <-- new\n",
    "    config:            RunnableConfig = None,\n",
    "    tool_call_id:      Annotated[str, InjectedToolCallId] = \"\",\n",
    ") -> Command:\n",
    "\n",
    "    \"\"\"\n",
    "    Retrieve top-k docs from Pinecone and store them in state.documents.\n",
    "    Also appends a ToolMessage tied to the triggering tool_call_id with the docs text.\n",
    "    \"\"\"\n",
    "    \n",
    "    # q   = query #(query if query is not None else question) or \"\"\n",
    "    pc  = (config or {}).get(\"configurable\", {}).get(\"pc\")\n",
    "    idx = (config or {}).get(\"configurable\", {}).get(\"idx\")\n",
    "\n",
    "    docs = await get_docs_pinecone(\n",
    "        query,\n",
    "        pc                   = pc,\n",
    "        idx                  = idx,\n",
    "        embedding_model_name = settings.DEFAULT_EMBEDDING_MODEL,\n",
    "        max_results          = top_k,\n",
    "    )\n",
    "    normalized = _normalize_docs(docs)\n",
    "\n",
    "    tool_msg = ToolMessage(\n",
    "        content=_format_docs_for_tool_message(\n",
    "            normalized,\n",
    "            max_chars_per_doc = max_chars_per_doc,\n",
    "            include_metadata  = include_metadata,\n",
    "        ),\n",
    "        tool_call_id = tool_call_id,\n",
    "        name         = \"get_docs_pinecone\",\n",
    "    )\n",
    "\n",
    "    return Command(update={\n",
    "        \"messages\":  [tool_msg],\n",
    "        \"documents\": normalized,\n",
    "        \"retrieval_source\": \"pinecone\",\n",
    "        \"question\":  query,\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- tools (timescale) ---\n",
    "@tool(\"get_docs_timescale\")\n",
    "async def tool_get_docs_timescale(\n",
    "    query:             Optional[str]  = None,\n",
    "    # question:          Optional[str]  = None,\n",
    "    top_k:             int            = 5,\n",
    "    max_chars_per_doc: Optional[int]  = None,   # <-- new\n",
    "    include_metadata:  bool           = True,             # <-- new\n",
    "    config:            RunnableConfig = None,\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId] = \"\",\n",
    ") -> Command:\n",
    "    \"\"\"\n",
    "    Retrieve top-k docs from Timescale Vector and store them in state.documents.\n",
    "    Also appends a ToolMessage tied to the triggering tool_call_id with the docs text.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # q          = query #(query if query is not None else question) or \"\"\n",
    "    vec_client = (config or {}).get(\"configurable\", {}).get(\"vec_client\")\n",
    "\n",
    "    docs = await get_docs_timescale(\n",
    "        query,\n",
    "        vec_client,\n",
    "        embedding_model_name = settings.DEFAULT_EMBEDDING_MODEL,\n",
    "        max_results          = top_k,\n",
    "    )\n",
    "    normalized = _normalize_docs(docs)\n",
    "\n",
    "    tool_msg = ToolMessage(\n",
    "        content=_format_docs_for_tool_message(\n",
    "            normalized,\n",
    "            max_chars_per_doc = max_chars_per_doc,     # None => full text\n",
    "            include_metadata  = include_metadata,      # metadata on top\n",
    "        ),\n",
    "        tool_call_id = tool_call_id,\n",
    "        name         = \"get_docs_timescale\",\n",
    "    )\n",
    "\n",
    "    return Command(update={\n",
    "        \"messages\":  [tool_msg],\n",
    "        \"documents\": normalized,\n",
    "        \"retrieval_source\": \"timescale\",\n",
    "        \"question\":  query,\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------- Router: force a single tool call ---------------\n",
    "async def route_vec_client(state: AgentState, config: RunnableConfig) -> AgentState:\n",
    "    \"\"\"\n",
    "    No model choice. We programmatically inject one tool_call\n",
    "    based on settings.VEC_CLIENT. If 'question' is missing (astream case),\n",
    "    derive it from the latest HumanMessage in state.messages.\n",
    "    \"\"\"\n",
    "    # q = (state.get(\"question\") or \"\").strip()\n",
    "    # if not q:\n",
    "    #     q = _get_last_user_text(state)\n",
    "\n",
    "    call_id = f\"call_{uuid4().hex}\"\n",
    "    top_k   = (config or {}).get(\"configurable\", {}).get(\"top_k\", 5)\n",
    "\n",
    "    if settings.VEC_CLIENT == settings.PINECONE_VEC_CLIENT:\n",
    "        tool_name = \"get_docs_pinecone\"\n",
    "    elif settings.VEC_CLIENT == settings.POSTGRES_TIMESCALE_VEC_CLIENT:\n",
    "        tool_name = \"get_docs_timescale\"\n",
    "    else:\n",
    "        # Return empty docs if misconfigured\n",
    "        return {\"documents\": [], \"retrieval_source\": \"invalid\", \"question\": state['question']}\n",
    "\n",
    "    top_k      = (config or {}).get(\"configurable\", {}).get(\"top_k\", 5)\n",
    "    max_chars  = (config or {}).get(\"configurable\", {}).get(\"max_chars_per_doc\", None)\n",
    "    inc_meta   = (config or {}).get(\"configurable\", {}).get(\"include_metadata\", True)\n",
    "\n",
    "    manual_tool_call = AIMessage(\n",
    "                                content    = \"\",\n",
    "                                tool_calls = [{\n",
    "                                    \"name\":  tool_name,\n",
    "                                    \"args\":  {\"query\": state['question'], \"top_k\": top_k, \"max_chars_per_doc\": max_chars, \"include_metadata\": inc_meta},\n",
    "                                    \"id\":    call_id\n",
    "                                }],\n",
    "    )\n",
    "    return {\"messages\": [manual_tool_call], \"question\": state['question']}\n",
    "\n",
    "\n",
    "\n",
    "# --- router: allow config control (optional) ---\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------- Build graph ------------------------------------\n",
    "def build_agent():\n",
    "    tools = [tool_get_docs_pinecone, tool_get_docs_timescale]\n",
    "    \n",
    "    tool_node = ToolNode(tools)\n",
    "\n",
    "    graph = StateGraph(AgentState)\n",
    "    \n",
    "    graph.set_entry_point(\"route_vec_client\")\n",
    "    graph.add_node(\"route_vec_client\",     route_vec_client)\n",
    "    graph.add_node(\"docs_retrieval_tool\", tool_node)\n",
    "    \n",
    "    graph.add_edge(\"route_vec_client\",     \"docs_retrieval_tool\")\n",
    "    graph.add_edge(\"docs_retrieval_tool\", END)\n",
    "    \n",
    "    return graph.compile()\n",
    "\n",
    "# --------------------------- Minimal usage ----------------------------------\n",
    "# Example:\n",
    "prototype_rag_tool = build_agent()\n",
    "\n",
    "from vector_databases import get_vec_client_timescale\n",
    "from memory import get_postgres_connection_string\n",
    "\n",
    "# create timescale_db_vec_client (async version)\n",
    "vec_client = get_vec_client_timescale(get_postgres_connection_string())\n",
    "\n",
    "# Non-streaming:\n",
    "state = await prototype_rag_tool.ainvoke(\n",
    "    {\"question\": \"paye?\"},\n",
    "    config={\"configurable\": {\"top_k\": 5, \"vec_client\": vec_client}},\n",
    ")\n",
    "\n",
    "# Streaming callers can pass {\"messages\": [HumanMessage(...)]} and the router will\n",
    "# automatically extract the user text into 'question'/'query'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5055173d-b59a-4782-9d2f-90ddd6991751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={}, id='2366ea16-297a-4ee1-844a-c10359730fab', tool_calls=[{'name': 'get_docs_timescale', 'args': {'query': 'paye?', 'top_k': 5, 'max_chars_per_doc': None, 'include_metadata': True}, 'id': 'call_78574c74f36943dc81a15dddad0a248f', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content='[1]\\n{\"main_service_name\": \"accountancy_services\", \"sub_service_name\": \"paye_&_ni\"}\\n\\nPAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. .\\n\\n[2]\\n{\"main_service_name\": \"accountancy_services\", \"sub_service_name\": \"payroll_services\"}\\n\\nPayroll Services. Running payroll is now becoming increasingly complex and time consuming, With the new RTI (Real time information) regulations it is even more important now to run the payroll on time and accurately report all the information to HMRC.. If you are looking for to keep your payroll operation smooth and timely, then. Milton Accountants and Consultants are providing reliable, cost effective payroll services follows employment regulations and adhere to the highest levels of Information and Data Security Regulations..\\n\\n[3]\\n{\"main_service_name\": \"accountancy_services\", \"sub_service_name\": \"taxation\"}\\n\\nTaxation. . Our professionals have vast and extensive function knowledge that is accompanied by technical proficiency. We understand your needs and business issues, which help us formulating business feasible and tax compliant solutions for you.. . Effective and efficient tax services provided by us give a competitive advantage by lowering the tax and administrative costs yet keeping your business compliant with the tax laws and regulations.. . Our variety of Taxation Services includes:. .  . VAT (Value added Tax). .  . . The decisions on whether it applies are taken every day on charges applied by businesses to their customers. Incompetence and wrong decisions are made, can led you to waste to time and financial resources.. . We’ll help you choose the right VAT scheme, and make sure you understand and comply with VAT laws and regulations. We also keeping up to date with the latest VAT legislation, our clients can be confident that they are being compliant with the VAT regulation.. .     Services that we offer to VAT client:.     Application to enroll on the VAT scheme.     Recommend the most suitable VAT scheme to join.     VAT planning for tax saving.     Complete your VAT return (avoiding any penalties).     Attendance for VAT inspections. .  . PAYE and NI. .  . . Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. .  . . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. . Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. .  . . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues. .\\n\\n[4]\\n{\"main_service_name\": \"accountancy_services\", \"sub_service_name\": \"statutory_accounts\"}\\n\\nStatutory accounts. . Its Duty of the Directors / PSC to file accounts and reports with the registrar for each financial year, for statutory accounts Milton accountants and Consultants team’s services are noted as exclusive for their valuable clients. Because our team understand the importance of reliable and timely submissions.\\n\\n[5]\\n{\"main_service_name\": \"accountancy_services\", \"sub_service_name\": \"self_assessment\"}\\n\\nSelf-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues.', name='get_docs_timescale', id='8d4a3646-edb8-4a68-9792-8249d68bf55d', tool_call_id='call_78574c74f36943dc81a15dddad0a248f')],\n",
       " 'question': 'paye?',\n",
       " 'documents': [{'id': None,\n",
       "   'text': 'PAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. .',\n",
       "   'metadata': {'sub_service_name': 'paye_&_ni',\n",
       "    'main_service_name': 'accountancy_services'}},\n",
       "  {'id': None,\n",
       "   'text': 'Payroll Services. Running payroll is now becoming increasingly complex and time consuming, With the new RTI (Real time information) regulations it is even more important now to run the payroll on time and accurately report all the information to HMRC.. If you are looking for to keep your payroll operation smooth and timely, then. Milton Accountants and Consultants are providing reliable, cost effective payroll services follows employment regulations and adhere to the highest levels of Information and Data Security Regulations..',\n",
       "   'metadata': {'sub_service_name': 'payroll_services',\n",
       "    'main_service_name': 'accountancy_services'}},\n",
       "  {'id': None,\n",
       "   'text': 'Taxation. . Our professionals have vast and extensive function knowledge that is accompanied by technical proficiency. We understand your needs and business issues, which help us formulating business feasible and tax compliant solutions for you.. . Effective and efficient tax services provided by us give a competitive advantage by lowering the tax and administrative costs yet keeping your business compliant with the tax laws and regulations.. . Our variety of Taxation Services includes:. .  . VAT (Value added Tax). .  . . The decisions on whether it applies are taken every day on charges applied by businesses to their customers. Incompetence and wrong decisions are made, can led you to waste to time and financial resources.. . We’ll help you choose the right VAT scheme, and make sure you understand and comply with VAT laws and regulations. We also keeping up to date with the latest VAT legislation, our clients can be confident that they are being compliant with the VAT regulation.. .     Services that we offer to VAT client:.     Application to enroll on the VAT scheme.     Recommend the most suitable VAT scheme to join.     VAT planning for tax saving.     Complete your VAT return (avoiding any penalties).     Attendance for VAT inspections. .  . PAYE and NI. .  . . Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. .  . . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. . Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. .  . . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues. .',\n",
       "   'metadata': {'sub_service_name': 'taxation',\n",
       "    'main_service_name': 'accountancy_services'}},\n",
       "  {'id': None,\n",
       "   'text': 'Statutory accounts. . Its Duty of the Directors / PSC to file accounts and reports with the registrar for each financial year, for statutory accounts Milton accountants and Consultants team’s services are noted as exclusive for their valuable clients. Because our team understand the importance of reliable and timely submissions.',\n",
       "   'metadata': {'sub_service_name': 'statutory_accounts',\n",
       "    'main_service_name': 'accountancy_services'}},\n",
       "  {'id': None,\n",
       "   'text': 'Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues.',\n",
       "   'metadata': {'sub_service_name': 'self_assessment',\n",
       "    'main_service_name': 'accountancy_services'}}],\n",
       " 'retrieval_source': 'timescale'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "812dee39-ccfc-4e06-bc8e-384861f1b348",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 messages\n",
      "1 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "2 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "2 common block -> isinstance(message, tuple)\n",
      "2 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"\", \"tool_calls\": [{\"name\": \"get_docs_timescale\", \"args\": {\"query\": \"paye?\", \"top_k\": 5, \"max_chars_per_doc\": null, \"include_metadata\": true}, \"id\": \"call_59610945cc1f4d9ba33cbe006d7dee4f\", \"type\": \"tool_call\"}], \"tool_call_id\": null, \"run_id\": \"519a5af6-4f77-4e60-8930-4fab9549eff5\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "3 messages\n",
      "3 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "4 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "4 common block -> isinstance(message, tuple)\n",
      "4 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"tool\", \"content\": \"[1]\\n{\\\"main_service_name\\\": \\\"accountancy_services\\\", \\\"sub_service_name\\\": \\\"paye_&_ni\\\"}\\n\\nPAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee\\u2019s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee\\u2019s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it\\u2019s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. .\\n\\n[2]\\n{\\\"main_service_name\\\": \\\"accountancy_services\\\", \\\"sub_service_name\\\": \\\"payroll_services\\\"}\\n\\nPayroll Services. Running payroll is now becoming increasingly complex and time consuming, With the new RTI (Real time information) regulations it is even more important now to run the payroll on time and accurately report all the information to HMRC.. If you are looking for to keep your payroll operation smooth and timely, then. Milton Accountants and Consultants are providing reliable, cost effective payroll services follows employment regulations and adhere to the highest levels of Information and Data Security Regulations..\\n\\n[3]\\n{\\\"main_service_name\\\": \\\"accountancy_services\\\", \\\"sub_service_name\\\": \\\"taxation\\\"}\\n\\nTaxation. . Our professionals have vast and extensive function knowledge that is accompanied by technical proficiency. We understand your needs and business issues, which help us formulating business feasible and tax compliant solutions for you.. . Effective and efficient tax services provided by us give a competitive advantage by lowering the tax and administrative costs yet keeping your business compliant with the tax laws and regulations.. . Our variety of Taxation Services includes:. .  . VAT (Value added Tax). .  . . The decisions on whether it applies are taken every day on charges applied by businesses to their customers. Incompetence and wrong decisions are made, can led you to waste to time and financial resources.. . We\\u2019ll help you choose the right VAT scheme, and make sure you understand and comply with VAT laws and regulations. We also keeping up to date with the latest VAT legislation, our clients can be confident that they are being compliant with the VAT regulation.. .     Services that we offer to VAT client:.     Application to enroll on the VAT scheme.     Recommend the most suitable VAT scheme to join.     VAT planning for tax saving.     Complete your VAT return (avoiding any penalties).     Attendance for VAT inspections. .  . PAYE and NI. .  . . Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee\\u2019s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee\\u2019s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it\\u2019s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. .  . . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. . Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.\\u2019stax advisors also ensured that right amount of tax is paid as well as on time.. .  . . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues. .\\n\\n[4]\\n{\\\"main_service_name\\\": \\\"accountancy_services\\\", \\\"sub_service_name\\\": \\\"statutory_accounts\\\"}\\n\\nStatutory accounts. . Its Duty of the Directors / PSC to file accounts and reports with the registrar for each financial year, for statutory accounts Milton accountants and Consultants team\\u2019s services are noted as exclusive for their valuable clients. Because our team understand the importance of reliable and timely submissions.\\n\\n[5]\\n{\\\"main_service_name\\\": \\\"accountancy_services\\\", \\\"sub_service_name\\\": \\\"self_assessment\\\"}\\n\\nSelf-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.\\u2019stax advisors also ensured that right amount of tax is paid as well as on time.. . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues.\", \"tool_calls\": [], \"tool_call_id\": \"call_59610945cc1f4d9ba33cbe006d7dee4f\", \"run_id\": \"519a5af6-4f77-4e60-8930-4fab9549eff5\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "data: [DONE]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, AIMessageChunk, AnyMessage, HumanMessage, ToolMessage\n",
    "\n",
    "import json\n",
    "from typing import Any\n",
    "from uuid import UUID, uuid4\n",
    "config = {\"configurable\": {\"thread_id\": f\"{str(uuid4())}\", \"user_id\": f\"{str(uuid4())}\", \"vec_client\":vec_client}}\n",
    "run_id    = uuid4()\n",
    "\n",
    "events = []\n",
    "\n",
    "# User input to create a profile memory\n",
    "m = 'paye?'\n",
    "input_messages = [HumanMessage(content=m)]\n",
    "user_input: UserInput = UserInput(message=m)\n",
    "#run_id = \"nkljwkd\"\n",
    "\n",
    "i = 0\n",
    "try:\n",
    "    # Process streamed events from the graph and yield messages over the SSE stream.\n",
    "    async for stream_event in prototype_rag_tool.astream(\n",
    "        {\"question\": \"paye?\"},\n",
    "        config,\n",
    "        stream_mode=[\"updates\", \"messages\", \"custom\"],\n",
    "    ):\n",
    "        i += 1\n",
    "        if not isinstance(stream_event, tuple):\n",
    "            continue\n",
    "\n",
    "        stream_mode, event = stream_event\n",
    "        events.append(event)\n",
    "#        print(type(stream_mode))\n",
    "        new_messages = []\n",
    "\n",
    "        if stream_mode == \"updates\":\n",
    "            print(i, \"updates\")\n",
    "            for node, updates in event.items():\n",
    "                # A simple approach to handle agent interrupts.\n",
    "                # In a more sophisticated implementation, we could add\n",
    "                # some structured ChatMessage type to return the interrupt value.\n",
    "                if node == \"__interrupt__\":\n",
    "                    \n",
    "                    print(i, \"updates -> __interrupt__\")\n",
    "                    \n",
    "                    for interrupt in updates:\n",
    "                        print(i, \"updates -> __interrupt__ -> interrupt in updates\")\n",
    "                        new_messages.append(AIMessage(content=interrupt.value))\n",
    "                    continue\n",
    "\n",
    "                updates = updates or {}\n",
    "                print(\"update_messages = updates.get(messages, [])\")\n",
    "                update_messages = updates.get(\"messages\", [])\n",
    "\n",
    "                # special cases for using langgraph-supervisor library\n",
    "                if node == \"supervisor\":\n",
    "                    print(i, \"updates -> supervisor\")\n",
    "                    # Get only the last AIMessage since supervisor includes all previous messages\n",
    "                    ai_messages = [msg for msg in update_messages if isinstance(msg, AIMessage)]\n",
    "                    if ai_messages:\n",
    "                        print(i, \"updates -> supervisor -> aimessage\")\n",
    "                        update_messages = [ai_messages[-1]]\n",
    "\n",
    "                if node in (\"research_expert\", \"math_expert\"):\n",
    "                    print(i, \"updates -> [research_expert, math_expert]\")\n",
    "                    # By default the sub-agent output is returned as an AIMessage.\n",
    "                    # Convert it to a ToolMessage so it displays in the UI as a tool response.\n",
    "                    msg = ToolMessage(\n",
    "                        content=update_messages[0].content,\n",
    "                        name=node,\n",
    "                        tool_call_id=\"\",\n",
    "                    )\n",
    "                    update_messages = [msg]\n",
    "\n",
    "                new_messages.extend(update_messages)\n",
    "\n",
    "                # if node == 'document_search':\n",
    "                #     current_docs = [updates['documents'][i].model_dump_json() + \"\\n \\n\" for i in range(len(updates['documents']))]\n",
    "                #     current_docs = \"\".join(current_docs)\n",
    "                #     new_messages.append(AIMessage(content=current_docs))\n",
    "                #     continue\n",
    "\n",
    "        if stream_mode == \"custom\":\n",
    "            print(i, \"custom\")\n",
    "            new_messages = [event]\n",
    "\n",
    "        # LangGraph streaming may emit tuples: (field_name, field_value)\n",
    "        # e.g. ('content', <str>), ('tool_calls', [ToolCall,...]), ('additional_kwargs', {...}), etc.\n",
    "        # We accumulate only supported fields into `parts` and skip unsupported metadata.\n",
    "        # More info at: https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/\n",
    "        processed_messages = []\n",
    "        current_message: dict[str, Any] = {}\n",
    "\n",
    "        for message in new_messages:\n",
    "            print(i, \"common block -> isinstance(message, tuple)\")\n",
    "            if isinstance(message, tuple):\n",
    "                key, value = message\n",
    "                # Store parts in temporary dict\n",
    "                current_message[key] = value\n",
    "            else:\n",
    "                # Add complete message if we have one in progress\n",
    "                if current_message:\n",
    "                    print(i, \"common block -> else: current_message\")\n",
    "                    processed_messages.append(_create_ai_message(current_message))\n",
    "                    current_message = {}\n",
    "                processed_messages.append(message)\n",
    "\n",
    "        # Add any remaining message parts\n",
    "        if current_message:\n",
    "            print(i, \"common block -> if: current_message\")\n",
    "            processed_messages.append(_create_ai_message(current_message))\n",
    "\n",
    "        for message in processed_messages:\n",
    "            print(i, \"common block -> [message in processed_messages]\")\n",
    "            try:\n",
    "                chat_message = langchain_to_chat_message(message)\n",
    "                chat_message.run_id = str(run_id)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'error', 'content': 'Unexpected error', 'error': str(e)})}\\n\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # LangGraph re-sends the input message, which feels weird, so drop it\n",
    "            if chat_message.type == \"human\" and chat_message.content == user_input.message:\n",
    "                print(i, \"common block -> [if chat_message.type == human and chat_message.content == user_input.message]\")\n",
    "                continue\n",
    "\n",
    "            print(\n",
    "                f\"data: {json.dumps({'type': 'message', 'content': chat_message.model_dump()})}\\n\"\n",
    "            )\n",
    "\n",
    "        if stream_mode == \"messages\":\n",
    "            print(i, \"messages\")\n",
    "            if not True:  # user_input.stream_tokens (default=True). see `schema.schema` -> `StreamInput`\n",
    "                continue\n",
    "\n",
    "            msg, metadata = event\n",
    "\n",
    "            if \"skip_stream\" in metadata.get(\"tags\", []):\n",
    "                print(i, \"messages -> skip_stream\")\n",
    "                continue\n",
    "\n",
    "            # For some reason, astream(\"messages\") causes non-LLM nodes to send extra messages.\n",
    "            # Drop them.\n",
    "            if not isinstance(msg, AIMessageChunk):\n",
    "                print(i, \"messages -> [if not isinstance(msg, AIMessageChunk)]\")\n",
    "                continue\n",
    "\n",
    "            content = remove_tool_calls(msg.content)\n",
    "            if content:\n",
    "                # Actually print the token stream (previously this was constructed but not printed)\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'token', 'content': convert_message_content_to_string(content)})}\\n\"\n",
    "                )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"data: {json.dumps({'type': 'error', 'content': 'Internal server error', 'error': str(e)})}\\n\"\n",
    "    )\n",
    "finally:\n",
    "    print(\"data: [DONE]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98b2e6f4-44c9-46b8-8389-218b6ee6cfc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ToolMessage(content='[1]\\n{\"main_service_name\": \"accountancy_services\", \"sub_service_name\": \"paye_&_ni\"}\\n\\nPAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. .\\n\\n[2]\\n{\"main_service_name\": \"accountancy_services\", \"sub_service_name\": \"payroll_services\"}\\n\\nPayroll Services. Running payroll is now becoming increasingly complex and time consuming, With the new RTI (Real time information) regulations it is even more important now to run the payroll on time and accurately report all the information to HMRC.. If you are looking for to keep your payroll operation smooth and timely, then. Milton Accountants and Consultants are providing reliable, cost effective payroll services follows employment regulations and adhere to the highest levels of Information and Data Security Regulations..\\n\\n[3]\\n{\"main_service_name\": \"accountancy_services\", \"sub_service_name\": \"taxation\"}\\n\\nTaxation. . Our professionals have vast and extensive function knowledge that is accompanied by technical proficiency. We understand your needs and business issues, which help us formulating business feasible and tax compliant solutions for you.. . Effective and efficient tax services provided by us give a competitive advantage by lowering the tax and administrative costs yet keeping your business compliant with the tax laws and regulations.. . Our variety of Taxation Services includes:. .  . VAT (Value added Tax). .  . . The decisions on whether it applies are taken every day on charges applied by businesses to their customers. Incompetence and wrong decisions are made, can led you to waste to time and financial resources.. . We’ll help you choose the right VAT scheme, and make sure you understand and comply with VAT laws and regulations. We also keeping up to date with the latest VAT legislation, our clients can be confident that they are being compliant with the VAT regulation.. .     Services that we offer to VAT client:.     Application to enroll on the VAT scheme.     Recommend the most suitable VAT scheme to join.     VAT planning for tax saving.     Complete your VAT return (avoiding any penalties).     Attendance for VAT inspections. .  . PAYE and NI. .  . . Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. .  . . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. . Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. .  . . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues. .\\n\\n[4]\\n{\"main_service_name\": \"accountancy_services\", \"sub_service_name\": \"statutory_accounts\"}\\n\\nStatutory accounts. . Its Duty of the Directors / PSC to file accounts and reports with the registrar for each financial year, for statutory accounts Milton accountants and Consultants team’s services are noted as exclusive for their valuable clients. Because our team understand the importance of reliable and timely submissions.\\n\\n[5]\\n{\"main_service_name\": \"accountancy_services\", \"sub_service_name\": \"self_assessment\"}\\n\\nSelf-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues.', name='get_docs_timescale', id='deed4572-7ecd-4243-a847-3d07e44a1274', tool_call_id='call_59610945cc1f4d9ba33cbe006d7dee4f'),\n",
       " {'thread_id': 'da2b38d7-ad69-4670-9b10-9e00482dd2d5',\n",
       "  'user_id': '1ce2c321-4d55-4327-9429-82de3924c8d6',\n",
       "  'langgraph_step': 2,\n",
       "  'langgraph_node': 'docs_retrieval_tool',\n",
       "  'langgraph_triggers': ('branch:to:docs_retrieval_tool',),\n",
       "  'langgraph_path': ('__pregel_pull', 'docs_retrieval_tool'),\n",
       "  'langgraph_checkpoint_ns': 'docs_retrieval_tool:1cadb6ac-ccc5-27be-d6c2-68794319bb48'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401a1cb-f77a-4068-9c2b-3f680e5e6318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f24aa87-43c9-474e-8004-70e5b3583b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fe2f9-3937-4346-9044-a2aee8d1caaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cf0723-cf0a-42cb-a13e-5fb9185ce38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd88217-369c-4584-a5ef-ec01a74441be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71baf1da-b6a0-4434-b502-460ec314aa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, List, Annotated, Optional\n",
    "from uuid import uuid4\n",
    "import json\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage, HumanMessage\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import StateGraph, MessagesState, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Command\n",
    "\n",
    "# --- Your project imports ---\n",
    "from vector_databases import get_docs_pinecone, get_docs_timescale\n",
    "from core import settings  # expects: settings.VEC_CLIENT, settings.PINECONE_VEC_CLIENT, settings.POSTGRES_TIMESCALE_VEC_CLIENT, settings.DEFAULT_EMBEDDING_MODEL\n",
    "import openai\n",
    "openai.api_type=openai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from typing import Literal\n",
    "from langchain_core.messages import AIMessage, convert_to_messages\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import END, StateGraph, MessagesState\n",
    "import openai\n",
    "import re\n",
    "from pinecone.db_data.index_asyncio import _IndexAsyncio\n",
    "from pinecone.pinecone_asyncio import PineconeAsyncio\n",
    "from timescale_vector import client\n",
    "from langfuse import Langfuse, get_client\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from timescale_vector import client\n",
    "\n",
    "\n",
    "from vector_databases import (\n",
    "                                get_docs_timescale,\n",
    "                                get_docs_pinecone\n",
    ")\n",
    "from core import get_model, settings\n",
    "\n",
    "\n",
    "from memory import get_postgres_connection_string\n",
    "\n",
    "MAIN_AGENT_DB_URI = get_postgres_connection_string()\n",
    "TIMESCALE_DB_URI  = get_postgres_connection_string()\n",
    "# vec_client = vec_client_timescale(TIMESCALE_DB_URI)\n",
    "\n",
    "\n",
    "\n",
    "import openai\n",
    "openai.api_type = \"openai\"  ##################################################################################################\n",
    "max_results     = 5\n",
    "\n",
    "# yahan if lagao k agar vec client name postgres ho to vo vala load otherwose 2sray vaa load.\n",
    "vec_client_name = settings.VEC_CLIENT\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()  # Load environment variables from a .env file\n",
    "\n",
    "if settings.LANGFUSE_PUBLIC_KEY:\n",
    "    langfuse_public_key = settings.LANGFUSE_PUBLIC_KEY #os.environ[\"langfuse_public_key\"]\n",
    "    langfuse_secret_key = settings.LANGFUSE_SECRET_KEY #os.environ[\"langfuse_secret_key\"]\n",
    "    langfuse_host       = settings.LANGFUSE_HOST       #os.environ[\"langfuse_host\"]\n",
    "    \n",
    "    langfuse = Langfuse(\n",
    "      secret_key = langfuse_secret_key.get_secret_value(),\n",
    "      public_key = langfuse_public_key.get_secret_value(),\n",
    "      host       = langfuse_host\n",
    "    )\n",
    "    \n",
    "    langfuse_cl = get_client(public_key=langfuse_public_key.get_secret_value())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "## Define Pydantic Schemas for Grading\n",
    "class GradeRelevance(BaseModel):\n",
    "    binary_score: str = Field(description=\"Question is related to accounting, 'yes' or 'no'\")\n",
    "\n",
    "class GradeHallucinations(BaseModel):\n",
    "    binary_score: str = Field(description=\"Answer is grounded in the facts, 'yes' or 'no'\")\n",
    "\n",
    "class GradeAnswer(BaseModel):\n",
    "    binary_score: str = Field(description=\"Answer addresses the question, 'yes' or 'no'\")\n",
    "\n",
    "class Input_State(BaseModel):\n",
    "    question: str = Field(description=\"Question asked by the user.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "## Define Prompts\n",
    "RELEVANCE_GRADER_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a grader assessing whether the user's query/question is related to accounting/accountance or accounting firm. Give a binary score 'yes' or 'no'.\"),\n",
    "    (\"human\", \"The query/question of user: \\n {query}\")\n",
    "])\n",
    "\n",
    "# langfuse_RELEVANCE_GRADER_PROMPT = langfuse_cl.get_prompt(\n",
    "#     \"RELEVANCE_GRADER_PROMPT\",\n",
    "#     type=\"chat\"\n",
    "# )\n",
    "\n",
    "# RELEVANCE_GRADER_PROMPT = ChatPromptTemplate(\n",
    "#     langfuse_RELEVANCE_GRADER_PROMPT.get_langchain_prompt(),\n",
    "#     metadata={\"langfuse_prompt\": langfuse_RELEVANCE_GRADER_PROMPT}  # exactly like that for linked generation\n",
    "# )\n",
    "\n",
    "HALLUCINATION_GRADER_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a grader assessing whether an LLM generation is grounded in a set of retrieved facts. Give a binary score 'yes' or 'no'.\"),\n",
    "    (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\")\n",
    "])\n",
    "\n",
    "ANSWER_GRADER_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a grader assessing whether an answer resolves a question. Give a binary score 'yes' or 'no'.\"),\n",
    "    (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\")\n",
    "])\n",
    "\n",
    "QUERY_REWRITER_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a question re-writer that converts an input question to a better version optimized for vectorstore retrieval.\"),\n",
    "    (\"human\", \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\")\n",
    "])\n",
    "\n",
    "RAG_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a chatbot assistant on the website of an accounting firm. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say so. Keep it concise.\"),\n",
    "    (\"human\", \"\\nQuestion: {question} \\nContext: {context} \\nAnswer:\")\n",
    "])\n",
    "\n",
    "\n",
    "# # Load prompts from Langfuse\n",
    "# langfuse_HALLUCINATION_GRADER_PROMPT = langfuse_cl.get_prompt(\n",
    "#     \"HALLUCINATION_GRADER_PROMPT\",\n",
    "#     type=\"chat\"\n",
    "# )\n",
    "# HALLUCINATION_GRADER_PROMPT = ChatPromptTemplate(\n",
    "#     langfuse_HALLUCINATION_GRADER_PROMPT.get_langchain_prompt(),\n",
    "#     metadata={\"langfuse_prompt\": langfuse_HALLUCINATION_GRADER_PROMPT}\n",
    "# )\n",
    "\n",
    "# langfuse_ANSWER_GRADER_PROMPT = langfuse_cl.get_prompt(\n",
    "#     \"ANSWER_GRADER_PROMPT\",\n",
    "#     type=\"chat\"\n",
    "# )\n",
    "# ANSWER_GRADER_PROMPT = ChatPromptTemplate(\n",
    "#     langfuse_ANSWER_GRADER_PROMPT.get_langchain_prompt(),\n",
    "#     metadata={\"langfuse_prompt\": langfuse_ANSWER_GRADER_PROMPT}\n",
    "# )\n",
    "\n",
    "# langfuse_QUERY_REWRITER_PROMPT = langfuse_cl.get_prompt(\n",
    "#     \"QUERY_REWRITER_PROMPT\",\n",
    "#     type=\"chat\"\n",
    "# )\n",
    "# QUERY_REWRITER_PROMPT = ChatPromptTemplate(\n",
    "#     langfuse_QUERY_REWRITER_PROMPT.get_langchain_prompt(),\n",
    "#     metadata={\"langfuse_prompt\": langfuse_QUERY_REWRITER_PROMPT}\n",
    "# )\n",
    "\n",
    "# langfuse_RAG_PROMPT = langfuse_cl.get_prompt(\n",
    "#     \"RAG_PROMPT\",\n",
    "#     type=\"chat\"\n",
    "# )\n",
    "# RAG_PROMPT = ChatPromptTemplate(\n",
    "#     langfuse_RAG_PROMPT.get_langchain_prompt(),\n",
    "#     metadata={\"langfuse_prompt\": langfuse_RAG_PROMPT}\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "## Constants\n",
    "MAX_RETRIES = 3\n",
    "VERBOSE = True\n",
    "\n",
    "\n",
    "\n",
    "#         vec_client_name:      str | None             = None,\n",
    "#         vec_client:           client.Async | None    = None,\n",
    "#         pc:                   PineconeAsyncio | None = None,\n",
    "#         idx:                  _IndexAsyncio | None   = None,\n",
    "#         embedding_model_name: str                    = \"text-embedding-3-small\",\n",
    "#         max_results:          int                    = 5,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Build and return a Retrieval-Augmented Generation (RAG) agent with self-corrective capabilities.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     vec_client_name : str, optional\n",
    "#         Source of the vector store. Use ``\"pinecone\"`` or ``\"postgres_timescale\"``.\n",
    "#     vec_client : client.Async, optional\n",
    "#         Asynchronous client instance that connects to the chosen vector store.\n",
    "#     pc : PineconeAsyncio, optional\n",
    "#         Initialized asynchronous Pinecone client used when ``vec_client_name`` is\n",
    "#         ``\"pinecone\"``.\n",
    "#     idx : _IndexAsyncio, optional\n",
    "#         Handle to an existing asynchronous index (e.g., a Pinecone index) that the\n",
    "#         agent should query.\n",
    "#     embedding_model_name : str, default \"text-embedding-3-small\"\n",
    "#         Name of the embedding model used to encode text before vector search.\n",
    "#     max_results : int, default 5\n",
    "#         Maximum number of context chunks to retrieve for each user query.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     RAGAgent\n",
    "#         A fully configured RAG agent that:\n",
    "#           - retrieves up to ``max_results`` relevant context passages from the specified vector store,\n",
    "#           - uses a lightweight evaluator to self-grade and filter retrieved content,\n",
    "#           - triggers additional retrieval (e.g., web search) or query reformulation when relevance falls below threshold,\n",
    "#           - and generates a final response grounded in the most accurate and refined context, using the OpenAI Chat Completion API.\n",
    "#     \"\"\"\n",
    "\n",
    "\n",
    "#     ################################################################################################################\n",
    "## Define Graph State and Configuration\n",
    "class AgentState(MessagesState):\n",
    "    question:         str\n",
    "    # documents:        list[Document]\n",
    "    documents:        Optional[List[Dict[str, Any]]]  # normalized docs\n",
    "    candidate_answer: str\n",
    "    retries:          int\n",
    "    retrieval_source: Optional[str]\n",
    "\n",
    "class GraphConfig(BaseModel):\n",
    "    max_retries: int = MAX_RETRIES\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "## Query Relevance\n",
    "async def query_relevance(state: AgentState, config: RunnableConfig) -> AgentState:\n",
    "    question = convert_to_messages(state[\"messages\"])[-1].content\n",
    "    return {\"question\": question}\n",
    "\n",
    "\n",
    "## isay history deni ho tu simply last 3,4 messages ko keys str main convert kr k, pass kr dena isay ...\n",
    "## yani last 4 messages + append the current question and that's it!\n",
    "## yani question vala string hi fn k andr update ho jaye ga ...\n",
    "async def query_relevance_router(state: Input_State, config: RunnableConfig) -> Literal[\"route_vec_client\", \"cant_help\"]:\n",
    "    question = state.question\n",
    "    if VERBOSE:\n",
    "        print(\"---CHECK RELEVANCE---\")\n",
    "\n",
    "    # Initialize the model\n",
    "    llm = get_model(config[\"configurable\"].get(\"model\", settings.DEFAULT_MODEL))\n",
    "    \n",
    "    grader = (RELEVANCE_GRADER_PROMPT | llm.with_structured_output(GradeRelevance)).with_config(tags=[\"skip_stream\"])\n",
    "    relevance_grade: GradeRelevance = await grader.ainvoke({\"query\": question})\n",
    "\n",
    "    if relevance_grade.binary_score == \"yes\":\n",
    "        if VERBOSE: print(\"---DECISION: QUERY/QUESTION <IS RELATED> TO ACCOUNTING---\")\n",
    "        return \"route_vec_client\"\n",
    "    else:\n",
    "        if VERBOSE: print(\"---DECISION: QUERY/QUESTION <IS NOT RELATED> TO ACCOUNTING---\")\n",
    "        return \"cant_help\"\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "################################################################################################################\n",
    "\n",
    "# --------------------------- Helpers ---------------------------------------\n",
    "def _normalize_docs(docs: List[Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Convert Pinecone/Timescale/LC Document objects into a unified shape:\n",
    "      {\"id\": str|None, \"text\": str|None, \"metadata\": dict}\n",
    "    \"\"\"\n",
    "    out: List[Dict[str, Any]] = []\n",
    "    for d in docs or []:\n",
    "        text = getattr(d, \"reranking_field\", None)\n",
    "        if text is None:\n",
    "            text = getattr(d, \"page_content\", None)\n",
    "        meta = getattr(d, \"metadata\", {}) or {}\n",
    "        _id = getattr(d, \"id\", None) or meta.get(\"id\") or meta.get(\"source_id\")\n",
    "        out.append({\"id\": _id, \"text\": text, \"metadata\": meta})\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- helper ---\n",
    "from typing import Optional\n",
    "import json\n",
    "\n",
    "def _format_docs_for_tool_message(\n",
    "    docs: List[Dict[str, Any]],\n",
    "    *,\n",
    "    max_chars_per_doc: Optional[int] = None,   # None => no truncation\n",
    "    include_metadata: bool = True,             # controls whether metadata is printed\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Render docs for ToolMessage.content.\n",
    "\n",
    "    For each doc:\n",
    "      [i] <best source>\n",
    "      <metadata as 1-line JSON>\n",
    "      \n",
    "      <text (optionally truncated)>\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        return \"No documents found.\"\n",
    "\n",
    "    parts: List[str] = []\n",
    "    for i, d in enumerate(docs, start=1):\n",
    "        txt = (d.get(\"text\") or \"\").strip()\n",
    "        if max_chars_per_doc and len(txt) > max_chars_per_doc:\n",
    "            txt = txt[:max_chars_per_doc].rstrip() + \"…\"\n",
    "\n",
    "        meta = d.get(\"metadata\") or {}\n",
    "        # stringify metadata (single line, JSON)\n",
    "        meta_str = json.dumps(meta, ensure_ascii=False, sort_keys=True, default=str)\n",
    "\n",
    "        src = meta.get(\"source\") or meta.get(\"url\") or meta.get(\"source_id\") or d.get(\"id\") or \"\"\n",
    "        header = f\"[{i}] {src}\".strip() if src else f\"[{i}]\"\n",
    "\n",
    "        if include_metadata:\n",
    "            block = f\"{header}\\n{meta_str}\\n\\n{txt}\" if txt else f\"{header}\\n{meta_str}\"\n",
    "        else:\n",
    "            block = f\"{header}\\n{txt}\" if txt else header\n",
    "\n",
    "        parts.append(block)\n",
    "\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _to_text(content: Any) -> str:\n",
    "    \"\"\"Best-effort to turn LC message.content into plain text.\"\"\"\n",
    "    if isinstance(content, str):\n",
    "        return content\n",
    "    if isinstance(content, list):\n",
    "        texts: List[str] = []\n",
    "        for part in content:\n",
    "            if isinstance(part, dict):\n",
    "                if part.get(\"type\") == \"text\" and \"text\" in part:\n",
    "                    texts.append(str(part[\"text\"]))\n",
    "                elif \"text\" in part:\n",
    "                    texts.append(str(part[\"text\"]))\n",
    "                elif \"content\" in part:\n",
    "                    texts.append(str(part[\"content\"]))\n",
    "            else:\n",
    "                texts.append(str(part))\n",
    "        return \"\\n\".join(t for t in texts if t)\n",
    "    return str(content)\n",
    "\n",
    "\n",
    "def _get_last_user_text(state: AgentState) -> str:\n",
    "    \"\"\"Pull the latest human message text from state.messages for streaming inputs.\"\"\"\n",
    "    msgs = state.get(\"messages\") or []\n",
    "    for msg in reversed(msgs):\n",
    "        if isinstance(msg, HumanMessage) or getattr(msg, \"type\", \"\") == \"human\":\n",
    "            return (_to_text(msg.content) or \"\").strip()\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# --------------------------- Tools (write directly to state) ----------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- tools (pinecone) ---\n",
    "@tool(\"get_docs_pinecone\")\n",
    "async def tool_get_docs_pinecone(\n",
    "    query:             Optional[str]  = None,\n",
    "    top_k:             int            = 5,\n",
    "    max_chars_per_doc: Optional[int]  = None,   # <-- new\n",
    "    include_metadata:  bool           = True,             # <-- new\n",
    "    config:            RunnableConfig = None,\n",
    "    tool_call_id:      Annotated[str, InjectedToolCallId] = \"\",\n",
    ") -> Command:\n",
    "\n",
    "    \"\"\"\n",
    "    Retrieve top-k docs from Pinecone and store them in state.documents.\n",
    "    Also appends a ToolMessage tied to the triggering tool_call_id with the docs text.\n",
    "    \"\"\"\n",
    "    \n",
    "    # q   = query #(query if query is not None else question) or \"\"\n",
    "    pc  = (config or {}).get(\"configurable\", {}).get(\"pc\")\n",
    "    idx = (config or {}).get(\"configurable\", {}).get(\"idx\")\n",
    "\n",
    "    docs = await get_docs_pinecone(\n",
    "        query,\n",
    "        pc                   = pc,\n",
    "        idx                  = idx,\n",
    "        embedding_model_name = settings.DEFAULT_EMBEDDING_MODEL,\n",
    "        max_results          = top_k,\n",
    "    )\n",
    "    normalized = _normalize_docs(docs)\n",
    "\n",
    "    tool_msg = ToolMessage(\n",
    "        content=_format_docs_for_tool_message(\n",
    "            normalized,\n",
    "            max_chars_per_doc = max_chars_per_doc,\n",
    "            include_metadata  = include_metadata,\n",
    "        ),\n",
    "        tool_call_id = tool_call_id,\n",
    "        name         = \"get_docs_pinecone\",\n",
    "    )\n",
    "\n",
    "    return Command(update={\n",
    "        \"messages\":  [tool_msg],\n",
    "        \"documents\": normalized,\n",
    "        \"retrieval_source\": \"pinecone\",\n",
    "        \"question\":  query,\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- tools (timescale) ---\n",
    "@tool(\"get_docs_timescale\")\n",
    "async def tool_get_docs_timescale(\n",
    "    query:             Optional[str]  = None,\n",
    "    top_k:             int            = 5,\n",
    "    max_chars_per_doc: Optional[int]  = None,   # <-- new\n",
    "    include_metadata:  bool           = True,             # <-- new\n",
    "    config:            RunnableConfig = None,\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId] = \"\",\n",
    ") -> Command:\n",
    "    \"\"\"\n",
    "    Retrieve top-k docs from Timescale Vector and store them in state.documents.\n",
    "    Also appends a ToolMessage tied to the triggering tool_call_id with the docs text.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # q          = query #(query if query is not None else question) or \"\"\n",
    "    vec_client = (config or {}).get(\"configurable\", {}).get(\"vec_client\")\n",
    "\n",
    "    docs = await get_docs_timescale(\n",
    "        query,\n",
    "        vec_client,\n",
    "        embedding_model_name = settings.DEFAULT_EMBEDDING_MODEL,\n",
    "        max_results          = top_k,\n",
    "    )\n",
    "    normalized = _normalize_docs(docs)\n",
    "\n",
    "    tool_msg = ToolMessage(\n",
    "        content=_format_docs_for_tool_message(\n",
    "            normalized,\n",
    "            max_chars_per_doc = max_chars_per_doc,     # None => full text\n",
    "            include_metadata  = include_metadata,      # metadata on top\n",
    "        ),\n",
    "        tool_call_id = tool_call_id,\n",
    "        name         = \"get_docs_timescale\",\n",
    "    )\n",
    "\n",
    "\n",
    "    return Command(update={\n",
    "        \"messages\":  [tool_msg],\n",
    "        \"documents\": normalized,\n",
    "        \"retrieval_source\": \"timescale\",\n",
    "        \"question\":  query,\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------- Router: force a single tool call ---------------\n",
    "async def route_vec_client(state: AgentState, config: RunnableConfig) -> AgentState:\n",
    "    \"\"\"\n",
    "    No model choice. We programmatically inject one tool_call\n",
    "    based on settings.VEC_CLIENT. If 'question' is missing (astream case),\n",
    "    derive it from the latest HumanMessage in state.messages.\n",
    "    \"\"\"\n",
    "\n",
    "    call_id = f\"call_{uuid4().hex}\"\n",
    "    top_k   = (config or {}).get(\"configurable\", {}).get(\"top_k\", 5)\n",
    "\n",
    "    if settings.VEC_CLIENT == settings.PINECONE_VEC_CLIENT:\n",
    "        tool_name = \"get_docs_pinecone\"\n",
    "    elif settings.VEC_CLIENT == settings.POSTGRES_TIMESCALE_VEC_CLIENT:\n",
    "        tool_name = \"get_docs_timescale\"\n",
    "    else:\n",
    "        # Return empty docs if misconfigured\n",
    "        return {\"documents\": [], \"retrieval_source\": \"invalid\", \"question\": state[\"question\"]}\n",
    "\n",
    "    top_k      = (config or {}).get(\"configurable\", {}).get(\"top_k\", 5)\n",
    "    max_chars  = (config or {}).get(\"configurable\", {}).get(\"max_chars_per_doc\", None)\n",
    "    inc_meta   = (config or {}).get(\"configurable\", {}).get(\"include_metadata\", True)\n",
    "\n",
    "    manual_tool_call = AIMessage(\n",
    "                                content    = \"\",\n",
    "                                tool_calls = [{\n",
    "                                    \"name\":  tool_name,\n",
    "                                    \"args\":  {\"query\": state[\"question\"], \"top_k\": top_k, \"max_chars_per_doc\": max_chars, \"include_metadata\": inc_meta},\n",
    "                                    \"id\":    call_id\n",
    "                                }],\n",
    "    )\n",
    "    return {\"messages\": [manual_tool_call], \"question\": state[\"question\"]}\n",
    "            \n",
    "################################################################################################################\n",
    "################################################################################################################\n",
    "## Answer Generation\n",
    "async def generate(state: AgentState, config: RunnableConfig) -> AgentState:\n",
    "    if VERBOSE:\n",
    "        print(\"---GENERATE---\")\n",
    "\n",
    "    # Initialize the model\n",
    "    llm = get_model(config[\"configurable\"].get(\"model\", settings.DEFAULT_MODEL))\n",
    "\n",
    "    rag_chain = RAG_PROMPT | llm | StrOutputParser()\n",
    "    generation = await rag_chain.ainvoke({\"context\": state[\"documents\"], \"question\": state[\"question\"]})\n",
    "    return {\"retries\": state.get(\"retries\", 0) + 1, \"candidate_answer\": generation}\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "## Answer Grading\n",
    "async def grade_generation_v_documents_and_question(state: AgentState, config: RunnableConfig) -> Literal[\"generate\", \"transform_query\", \"cant_help\", \"finalize_response\"]:\n",
    "    if VERBOSE:\n",
    "        print(\"---CHECK HALLUCINATIONS---\")\n",
    "\n",
    "    # Initialize the model\n",
    "    llm = get_model(config[\"configurable\"].get(\"model\", settings.DEFAULT_MODEL))\n",
    "\n",
    "    halluc_grader = (HALLUCINATION_GRADER_PROMPT | llm.with_structured_output(GradeHallucinations)).with_config(tags=[\"skip_stream\"])\n",
    "    hall_result = await halluc_grader.ainvoke({\"documents\": state[\"documents\"], \"generation\": state[\"candidate_answer\"]})\n",
    "\n",
    "    if hall_result.binary_score == \"no\":\n",
    "        if VERBOSE: print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"generate\" if state.get(\"retries\", 0) < config.get(\"configurable\", {}).get(\"max_retries\", MAX_RETRIES) else \"cant_help\"\n",
    "\n",
    "    if VERBOSE:\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # print(state[\"documents\"])\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "\n",
    "    answer_grader = (ANSWER_GRADER_PROMPT | llm.with_structured_output(GradeAnswer)).with_config(tags=[\"skip_stream\"])\n",
    "    answer_result = await answer_grader.ainvoke({\"question\": state[\"question\"], \"generation\": state[\"candidate_answer\"]})\n",
    "\n",
    "    if answer_result.binary_score == \"yes\":\n",
    "        if VERBOSE: print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "        return \"finalize_response\"\n",
    "    else:\n",
    "        if VERBOSE: print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "        return \"transform_query\" if state.get(\"retries\", 0) < config.get(\"configurable\", {}).get(\"max_retries\", MAX_RETRIES) else \"cant_help\"\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "## Transform Query\n",
    "async def transform_query(state: AgentState, config: RunnableConfig) -> AgentState:\n",
    "    if VERBOSE:\n",
    "        print(\"---TRANSFORM QUERY---\")\n",
    "\n",
    "    # Initialize the model\n",
    "    llm = get_model(config[\"configurable\"].get(\"model\", settings.DEFAULT_MODEL))\n",
    "\n",
    "    rewriter = QUERY_REWRITER_PROMPT | llm | StrOutputParser()\n",
    "    better_question = await rewriter.ainvoke({\"question\": state[\"question\"]})\n",
    "    return {\"question\": better_question}\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "## Fallback Handler\n",
    "# async def cant_help(state: AgentState, config: RunnableConfig) -> AgentState:\n",
    "#     return {\"candidate_answer\": \"Sorry, I cannot help you in this matter.\"}\n",
    "\n",
    "from langgraph.types import StreamWriter\n",
    "async def cant_help(state: AgentState, config: RunnableConfig, writer: StreamWriter) -> AgentState:  # writer auto-injected\n",
    "    PRESET = \"Sorry, I cannot help you in this matter.\"\n",
    "    for word in PRESET.split():\n",
    "        writer(word + ' ')\n",
    "    return {\"candidate_answer\": PRESET}\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "## Finalize Response\n",
    "async def finalize_response(state: AgentState, config: RunnableConfig) -> AgentState:\n",
    "    if VERBOSE:\n",
    "        print(\"---FINALIZING THE RESPONSE---\")\n",
    "        return {\"messages\": [AIMessage(content=state[\"candidate_answer\"])]}\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "## Build Graph\n",
    "graph = StateGraph(AgentState, config_schema=GraphConfig)\n",
    "\n",
    "tools     = [tool_get_docs_pinecone, tool_get_docs_timescale]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "\n",
    "graph.set_entry_point(\"query_relevance\")\n",
    "\n",
    "graph.add_node(\"query_relevance\",   query_relevance)\n",
    "graph.add_node(\"route_vec_client\",    route_vec_client)\n",
    "graph.add_node(\"docs_retrieval_tool\", tool_node)\n",
    "# graph.add_node(\"document_search\",   document_search)\n",
    "graph.add_node(\"generate\",          generate)\n",
    "graph.add_node(\"transform_query\",   transform_query)\n",
    "graph.add_node(\"cant_help\",         cant_help)\n",
    "graph.add_node(\"finalize_response\", finalize_response)\n",
    "\n",
    "graph.add_conditional_edges(\"query_relevance\", query_relevance_router, [\"cant_help\", \"route_vec_client\"])#\"document_search\"])\n",
    "graph.add_edge(\"route_vec_client\",     \"docs_retrieval_tool\")\n",
    "graph.add_edge(\"docs_retrieval_tool\",  \"generate\")\n",
    "# graph.add_edge(\"document_search\", \"generate\")\n",
    "graph.add_conditional_edges(\"generate\", grade_generation_v_documents_and_question, [\"generate\", \"transform_query\", \"cant_help\", \"finalize_response\"])\n",
    "graph.add_edge(\"transform_query\", \"route_vec_client\")#\"document_search\"])\n",
    "graph.add_edge(\"cant_help\", \"finalize_response\")\n",
    "graph.add_edge(\"finalize_response\", END)\n",
    "\n",
    "self_corrective_rag = graph.compile()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06114a96-3f3f-4bd5-a21c-5c115e05e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Make sure the .env from the repo root is loaded into the current process\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(\".env\", usecwd=True))  # searches upward from CWD\n",
    "\n",
    "import os\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found after loading .env\"\n",
    "\n",
    "# 2) Ensure the project 'src' is on sys.path\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # now 'src' is on path\n",
    "\n",
    "from core import settings\n",
    "# # --- Option A: import via the package (may import other agents too)\n",
    "# from agents.interrupt_agent import interrupt_agent\n",
    "from schema import (\n",
    "    ChatHistory,\n",
    "    ChatHistoryInput,\n",
    "    ChatMessage,\n",
    "    Feedback,\n",
    "    FeedbackResponse,\n",
    "    ServiceMetadata,\n",
    "    StreamInput,\n",
    "    UserInput,\n",
    ")\n",
    "\n",
    "from service.utils import (\n",
    "    convert_message_content_to_string,\n",
    "    langchain_to_chat_message,\n",
    "    remove_tool_calls,\n",
    ")\n",
    "\n",
    "from agents.self_corrective_rag import self_corrective_rag\n",
    "\n",
    "from schema import ChatMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f8ec09-ba4c-4d44-b71e-e343854d6556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654b15e6-fbb7-4b44-a3f1-95d89d73610c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ad8ebcd-cffd-4ff1-ad55-ae0ba6d8539c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualize graph\n",
    "from IPython.display import Image, display\n",
    "display(Image(self_corrective_rag.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8830e293-d1e5-4108-8b3c-cacbfb650cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "---DECISION: QUERY/QUESTION <IS RELATED> TO ACCOUNTING---\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---FINALIZING THE RESPONSE---\n"
     ]
    }
   ],
   "source": [
    "from vector_databases import get_vec_client_timescale\n",
    "from memory import get_postgres_connection_string\n",
    "\n",
    "# create timescale_db_vec_client (async version)\n",
    "vec_client = get_vec_client_timescale(get_postgres_connection_string())\n",
    "\n",
    "# Non-streaming:\n",
    "state = await self_corrective_rag.ainvoke(\n",
    "    {\"messages\": \"paye?\"},\n",
    "    config={\"configurable\": {\"top_k\": 5, \"vec_client\": vec_client}},\n",
    ")\n",
    "\n",
    "# Streaming callers can pass {\"messages\": [HumanMessage(...)]} and the router will\n",
    "# automatically extract the user text into 'question'/'query'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d9debb1-af28-49cc-a950-201131ae7278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='paye?', additional_kwargs={}, response_metadata={}, id='8bcf86cc-dcca-4060-a1a6-1fa6956b9d5b'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={}, id='52641c7f-4942-46f7-b8c4-ef1b6ee8c9f0', tool_calls=[{'name': 'get_docs_timescale', 'args': {'query': 'paye?', 'top_k': 5, 'max_chars_per_doc': None, 'include_metadata': True}, 'id': 'call_5d499a9321ab465b98bc64a0c3c07659', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content='[1]\\n{\"main_service_name\": \"accountancy_services\", \"sub_service_name\": \"paye_&_ni\"}\\n\\nPAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. .\\n\\n[2]\\n{\"main_service_name\": \"accountancy_services\", \"sub_service_name\": \"payroll_services\"}\\n\\nPayroll Services. Running payroll is now becoming increasingly complex and time consuming, With the new RTI (Real time information) regulations it is even more important now to run the payroll on time and accurately report all the information to HMRC.. If you are looking for to keep your payroll operation smooth and timely, then. Milton Accountants and Consultants are providing reliable, cost effective payroll services follows employment regulations and adhere to the highest levels of Information and Data Security Regulations..\\n\\n[3]\\n{\"main_service_name\": \"accountancy_services\", \"sub_service_name\": \"taxation\"}\\n\\nTaxation. . Our professionals have vast and extensive function knowledge that is accompanied by technical proficiency. We understand your needs and business issues, which help us formulating business feasible and tax compliant solutions for you.. . Effective and efficient tax services provided by us give a competitive advantage by lowering the tax and administrative costs yet keeping your business compliant with the tax laws and regulations.. . Our variety of Taxation Services includes:. .  . VAT (Value added Tax). .  . . The decisions on whether it applies are taken every day on charges applied by businesses to their customers. Incompetence and wrong decisions are made, can led you to waste to time and financial resources.. . We’ll help you choose the right VAT scheme, and make sure you understand and comply with VAT laws and regulations. We also keeping up to date with the latest VAT legislation, our clients can be confident that they are being compliant with the VAT regulation.. .     Services that we offer to VAT client:.     Application to enroll on the VAT scheme.     Recommend the most suitable VAT scheme to join.     VAT planning for tax saving.     Complete your VAT return (avoiding any penalties).     Attendance for VAT inspections. .  . PAYE and NI. .  . . Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. .  . . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. . Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. .  . . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues. .\\n\\n[4]\\n{\"main_service_name\": \"accountancy_services\", \"sub_service_name\": \"statutory_accounts\"}\\n\\nStatutory accounts. . Its Duty of the Directors / PSC to file accounts and reports with the registrar for each financial year, for statutory accounts Milton accountants and Consultants team’s services are noted as exclusive for their valuable clients. Because our team understand the importance of reliable and timely submissions.\\n\\n[5]\\n{\"main_service_name\": \"accountancy_services\", \"sub_service_name\": \"self_assessment\"}\\n\\nSelf-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues.', name='get_docs_timescale', id='82ac9d18-2e31-43c3-8706-9b9e581eb280', tool_call_id='call_5d499a9321ab465b98bc64a0c3c07659'),\n",
       "  AIMessage(content='PAYE (Pay As You Earn) is the income tax deducted from an employee’s salary before they receive it. It is mandatory under HMRC regulations, and businesses must report employee payments and deductions to HMRC. We can assist with calculating, submitting, and managing PAYE and National Insurance contributions.', additional_kwargs={}, response_metadata={}, id='87cd58cb-6c3e-4220-93b8-a25d72d44203')],\n",
       " 'question': 'paye?',\n",
       " 'documents': [{'id': None,\n",
       "   'text': 'PAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. .',\n",
       "   'metadata': {'sub_service_name': 'paye_&_ni',\n",
       "    'main_service_name': 'accountancy_services'}},\n",
       "  {'id': None,\n",
       "   'text': 'Payroll Services. Running payroll is now becoming increasingly complex and time consuming, With the new RTI (Real time information) regulations it is even more important now to run the payroll on time and accurately report all the information to HMRC.. If you are looking for to keep your payroll operation smooth and timely, then. Milton Accountants and Consultants are providing reliable, cost effective payroll services follows employment regulations and adhere to the highest levels of Information and Data Security Regulations..',\n",
       "   'metadata': {'sub_service_name': 'payroll_services',\n",
       "    'main_service_name': 'accountancy_services'}},\n",
       "  {'id': None,\n",
       "   'text': 'Taxation. . Our professionals have vast and extensive function knowledge that is accompanied by technical proficiency. We understand your needs and business issues, which help us formulating business feasible and tax compliant solutions for you.. . Effective and efficient tax services provided by us give a competitive advantage by lowering the tax and administrative costs yet keeping your business compliant with the tax laws and regulations.. . Our variety of Taxation Services includes:. .  . VAT (Value added Tax). .  . . The decisions on whether it applies are taken every day on charges applied by businesses to their customers. Incompetence and wrong decisions are made, can led you to waste to time and financial resources.. . We’ll help you choose the right VAT scheme, and make sure you understand and comply with VAT laws and regulations. We also keeping up to date with the latest VAT legislation, our clients can be confident that they are being compliant with the VAT regulation.. .     Services that we offer to VAT client:.     Application to enroll on the VAT scheme.     Recommend the most suitable VAT scheme to join.     VAT planning for tax saving.     Complete your VAT return (avoiding any penalties).     Attendance for VAT inspections. .  . PAYE and NI. .  . . Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee’s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee’s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it’s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. .  . . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. . Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. .  . . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues. .',\n",
       "   'metadata': {'sub_service_name': 'taxation',\n",
       "    'main_service_name': 'accountancy_services'}},\n",
       "  {'id': None,\n",
       "   'text': 'Statutory accounts. . Its Duty of the Directors / PSC to file accounts and reports with the registrar for each financial year, for statutory accounts Milton accountants and Consultants team’s services are noted as exclusive for their valuable clients. Because our team understand the importance of reliable and timely submissions.',\n",
       "   'metadata': {'sub_service_name': 'statutory_accounts',\n",
       "    'main_service_name': 'accountancy_services'}},\n",
       "  {'id': None,\n",
       "   'text': 'Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.’stax advisors also ensured that right amount of tax is paid as well as on time.. . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues.',\n",
       "   'metadata': {'sub_service_name': 'self_assessment',\n",
       "    'main_service_name': 'accountancy_services'}}],\n",
       " 'candidate_answer': 'PAYE (Pay As You Earn) is the income tax deducted from an employee’s salary before they receive it. It is mandatory under HMRC regulations, and businesses must report employee payments and deductions to HMRC. We can assist with calculating, submitting, and managing PAYE and National Insurance contributions.',\n",
       " 'retries': 1,\n",
       " 'retrieval_source': 'timescale'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fe6f0c-f2e0-47fa-9cd5-6a2dfe1f8d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7923771c-3df5-43bf-b8c4-637b87b67069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "1 messages\n",
      "1 messages -> skip_stream\n",
      "2 messages\n",
      "2 messages -> skip_stream\n",
      "3 messages\n",
      "3 messages -> skip_stream\n",
      "4 messages\n",
      "4 messages -> skip_stream\n",
      "5 messages\n",
      "5 messages -> skip_stream\n",
      "6 messages\n",
      "6 messages -> skip_stream\n",
      "7 messages\n",
      "7 messages -> skip_stream\n",
      "8 messages\n",
      "8 messages -> skip_stream\n",
      "9 messages\n",
      "9 messages -> skip_stream\n",
      "10 messages\n",
      "10 messages -> skip_stream\n",
      "---DECISION: QUERY/QUESTION <IS RELATED> TO ACCOUNTING---\n",
      "11 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "12 messages\n",
      "12 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "13 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "13 common block -> isinstance(message, tuple)\n",
      "13 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"\", \"tool_calls\": [{\"name\": \"get_docs_timescale\", \"args\": {\"query\": \"paye?\", \"top_k\": 5, \"max_chars_per_doc\": null, \"include_metadata\": true}, \"id\": \"call_8ef562a397c8423ab16a6cb02f87e134\", \"type\": \"tool_call\"}], \"tool_call_id\": null, \"run_id\": \"ad30652d-54f2-44ee-aea2-a1c6bc949c3f\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "14 messages\n",
      "14 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "15 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "15 common block -> isinstance(message, tuple)\n",
      "15 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"tool\", \"content\": \"[1]\\n{\\\"main_service_name\\\": \\\"accountancy_services\\\", \\\"sub_service_name\\\": \\\"paye_&_ni\\\"}\\n\\nPAYE and NI. Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee\\u2019s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee\\u2019s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it\\u2019s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. .\\n\\n[2]\\n{\\\"main_service_name\\\": \\\"accountancy_services\\\", \\\"sub_service_name\\\": \\\"payroll_services\\\"}\\n\\nPayroll Services. Running payroll is now becoming increasingly complex and time consuming, With the new RTI (Real time information) regulations it is even more important now to run the payroll on time and accurately report all the information to HMRC.. If you are looking for to keep your payroll operation smooth and timely, then. Milton Accountants and Consultants are providing reliable, cost effective payroll services follows employment regulations and adhere to the highest levels of Information and Data Security Regulations..\\n\\n[3]\\n{\\\"main_service_name\\\": \\\"accountancy_services\\\", \\\"sub_service_name\\\": \\\"taxation\\\"}\\n\\nTaxation. . Our professionals have vast and extensive function knowledge that is accompanied by technical proficiency. We understand your needs and business issues, which help us formulating business feasible and tax compliant solutions for you.. . Effective and efficient tax services provided by us give a competitive advantage by lowering the tax and administrative costs yet keeping your business compliant with the tax laws and regulations.. . Our variety of Taxation Services includes:. .  . VAT (Value added Tax). .  . . The decisions on whether it applies are taken every day on charges applied by businesses to their customers. Incompetence and wrong decisions are made, can led you to waste to time and financial resources.. . We\\u2019ll help you choose the right VAT scheme, and make sure you understand and comply with VAT laws and regulations. We also keeping up to date with the latest VAT legislation, our clients can be confident that they are being compliant with the VAT regulation.. .     Services that we offer to VAT client:.     Application to enroll on the VAT scheme.     Recommend the most suitable VAT scheme to join.     VAT planning for tax saving.     Complete your VAT return (avoiding any penalties).     Attendance for VAT inspections. .  . PAYE and NI. .  . . Pay as you earn, or PAYE, refers to the income tax that is deducted from an employee\\u2019s salary before they receive it. It is mandatory by HMRC regulations to collect taxes from workers and employees at its initial stage of earning. Deductions of PAYE from workers salary and submission of PAYE is a time consuming and demanding job. As a business owner, you need to report your employee\\u2019s payments and deductions to HMRC. We are ready to take you burden at an economical and efficient terms.. . You pay National Insurance contributions to build up your entitlement to certain state benefits, including the State Pension. Information about how much National Insurance you pay, what it\\u2019s for and how to check your National Insurance record. For the National insurance contributions as an employee or employer, you can trust Milton Accountants and Consultants for the quality work.. .  . . Services related to Payee and National insurance. .     Apply for national insurance number.     Calculation of PAYE and NI amount.     Submission of PAYE and NI.     Managing your quires and disputes arise with HMRC in relation to PAYE.     National Insurance legal claims for individuals and corporations.. . Self-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.\\u2019stax advisors also ensured that right amount of tax is paid as well as on time.. .  . . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues. .\\n\\n[4]\\n{\\\"main_service_name\\\": \\\"accountancy_services\\\", \\\"sub_service_name\\\": \\\"statutory_accounts\\\"}\\n\\nStatutory accounts. . Its Duty of the Directors / PSC to file accounts and reports with the registrar for each financial year, for statutory accounts Milton accountants and Consultants team\\u2019s services are noted as exclusive for their valuable clients. Because our team understand the importance of reliable and timely submissions.\\n\\n[5]\\n{\\\"main_service_name\\\": \\\"accountancy_services\\\", \\\"sub_service_name\\\": \\\"self_assessment\\\"}\\n\\nSelf-Assessment. . It is compulsory for the individual who is working as self-employed to submit tax return. Our self-assessment services for individuals help to ensure the completion and submission of tax return on time. Milton accountants and Consultants ltd.\\u2019stax advisors also ensured that right amount of tax is paid as well as on time.. . Individuals who are liable for the self-assessment:. .     Self-employed people including business partners.     Company Directors.     Pensioners with more complex tax affairs.     People who receive rent or other income from land and property in the UK.     Non-resident company landlords. . Milton Accountants and Consultants Ltd are offering services to liable individual with quality of work to avoid penalties and calculation for appropriate taxes.. .     Personal Tax-Self Assessment Registration for directors and self employed.     Preparation of personal tax returns for self-employed, partners and company directors.     Calculating your tax liability.     Advising you when various payments are due and how much to pay.     Advising on appropriate record retention.     Efficient personal tax planning to minimise overall tax bill..     Tax claims and refund administration.     Handling disputes with HMRC regarding tax liability and other related issues.\", \"tool_calls\": [], \"tool_call_id\": \"call_8ef562a397c8423ab16a6cb02f87e134\", \"run_id\": \"ad30652d-54f2-44ee-aea2-a1c6bc949c3f\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "---GENERATE---\n",
      "16 messages\n",
      "17 messages\n",
      "data: {\"type\": \"token\", \"content\": \"PAY\"}\n",
      "\n",
      "18 messages\n",
      "data: {\"type\": \"token\", \"content\": \"E\"}\n",
      "\n",
      "19 messages\n",
      "data: {\"type\": \"token\", \"content\": \" (\"}\n",
      "\n",
      "20 messages\n",
      "data: {\"type\": \"token\", \"content\": \"Pay\"}\n",
      "\n",
      "21 messages\n",
      "data: {\"type\": \"token\", \"content\": \" As\"}\n",
      "\n",
      "22 messages\n",
      "data: {\"type\": \"token\", \"content\": \" You\"}\n",
      "\n",
      "23 messages\n",
      "data: {\"type\": \"token\", \"content\": \" Earn\"}\n",
      "\n",
      "24 messages\n",
      "data: {\"type\": \"token\", \"content\": \")\"}\n",
      "\n",
      "25 messages\n",
      "data: {\"type\": \"token\", \"content\": \" is\"}\n",
      "\n",
      "26 messages\n",
      "data: {\"type\": \"token\", \"content\": \" a\"}\n",
      "\n",
      "27 messages\n",
      "data: {\"type\": \"token\", \"content\": \" system\"}\n",
      "\n",
      "28 messages\n",
      "data: {\"type\": \"token\", \"content\": \" where\"}\n",
      "\n",
      "29 messages\n",
      "data: {\"type\": \"token\", \"content\": \" income\"}\n",
      "\n",
      "30 messages\n",
      "data: {\"type\": \"token\", \"content\": \" tax\"}\n",
      "\n",
      "31 messages\n",
      "data: {\"type\": \"token\", \"content\": \" is\"}\n",
      "\n",
      "32 messages\n",
      "data: {\"type\": \"token\", \"content\": \" deducted\"}\n",
      "\n",
      "33 messages\n",
      "data: {\"type\": \"token\", \"content\": \" from\"}\n",
      "\n",
      "34 messages\n",
      "data: {\"type\": \"token\", \"content\": \" an\"}\n",
      "\n",
      "35 messages\n",
      "data: {\"type\": \"token\", \"content\": \" employee\"}\n",
      "\n",
      "36 messages\n",
      "data: {\"type\": \"token\", \"content\": \"\\u2019s\"}\n",
      "\n",
      "37 messages\n",
      "data: {\"type\": \"token\", \"content\": \" salary\"}\n",
      "\n",
      "38 messages\n",
      "data: {\"type\": \"token\", \"content\": \" before\"}\n",
      "\n",
      "39 messages\n",
      "data: {\"type\": \"token\", \"content\": \" they\"}\n",
      "\n",
      "40 messages\n",
      "data: {\"type\": \"token\", \"content\": \" receive\"}\n",
      "\n",
      "41 messages\n",
      "data: {\"type\": \"token\", \"content\": \" it\"}\n",
      "\n",
      "42 messages\n",
      "data: {\"type\": \"token\", \"content\": \".\"}\n",
      "\n",
      "43 messages\n",
      "data: {\"type\": \"token\", \"content\": \" It\"}\n",
      "\n",
      "44 messages\n",
      "data: {\"type\": \"token\", \"content\": \" is\"}\n",
      "\n",
      "45 messages\n",
      "data: {\"type\": \"token\", \"content\": \" mandatory\"}\n",
      "\n",
      "46 messages\n",
      "data: {\"type\": \"token\", \"content\": \" by\"}\n",
      "\n",
      "47 messages\n",
      "data: {\"type\": \"token\", \"content\": \" HM\"}\n",
      "\n",
      "48 messages\n",
      "data: {\"type\": \"token\", \"content\": \"RC\"}\n",
      "\n",
      "49 messages\n",
      "data: {\"type\": \"token\", \"content\": \" regulations\"}\n",
      "\n",
      "50 messages\n",
      "data: {\"type\": \"token\", \"content\": \".\"}\n",
      "\n",
      "51 messages\n",
      "data: {\"type\": \"token\", \"content\": \" We\"}\n",
      "\n",
      "52 messages\n",
      "data: {\"type\": \"token\", \"content\": \" can\"}\n",
      "\n",
      "53 messages\n",
      "data: {\"type\": \"token\", \"content\": \" assist\"}\n",
      "\n",
      "54 messages\n",
      "data: {\"type\": \"token\", \"content\": \" with\"}\n",
      "\n",
      "55 messages\n",
      "data: {\"type\": \"token\", \"content\": \" calculating\"}\n",
      "\n",
      "56 messages\n",
      "data: {\"type\": \"token\", \"content\": \",\"}\n",
      "\n",
      "57 messages\n",
      "data: {\"type\": \"token\", \"content\": \" submitting\"}\n",
      "\n",
      "58 messages\n",
      "data: {\"type\": \"token\", \"content\": \",\"}\n",
      "\n",
      "59 messages\n",
      "data: {\"type\": \"token\", \"content\": \" and\"}\n",
      "\n",
      "60 messages\n",
      "data: {\"type\": \"token\", \"content\": \" managing\"}\n",
      "\n",
      "61 messages\n",
      "data: {\"type\": \"token\", \"content\": \" PAY\"}\n",
      "\n",
      "62 messages\n",
      "data: {\"type\": \"token\", \"content\": \"E\"}\n",
      "\n",
      "63 messages\n",
      "data: {\"type\": \"token\", \"content\": \" and\"}\n",
      "\n",
      "64 messages\n",
      "data: {\"type\": \"token\", \"content\": \" National\"}\n",
      "\n",
      "65 messages\n",
      "data: {\"type\": \"token\", \"content\": \" Insurance\"}\n",
      "\n",
      "66 messages\n",
      "data: {\"type\": \"token\", \"content\": \" contributions\"}\n",
      "\n",
      "67 messages\n",
      "data: {\"type\": \"token\", \"content\": \" for\"}\n",
      "\n",
      "68 messages\n",
      "data: {\"type\": \"token\", \"content\": \" your\"}\n",
      "\n",
      "69 messages\n",
      "data: {\"type\": \"token\", \"content\": \" business\"}\n",
      "\n",
      "70 messages\n",
      "data: {\"type\": \"token\", \"content\": \".\"}\n",
      "\n",
      "71 messages\n",
      "---CHECK HALLUCINATIONS---\n",
      "72 messages\n",
      "72 messages -> skip_stream\n",
      "73 messages\n",
      "73 messages -> skip_stream\n",
      "74 messages\n",
      "74 messages -> skip_stream\n",
      "75 messages\n",
      "75 messages -> skip_stream\n",
      "76 messages\n",
      "76 messages -> skip_stream\n",
      "77 messages\n",
      "77 messages -> skip_stream\n",
      "78 messages\n",
      "78 messages -> skip_stream\n",
      "79 messages\n",
      "79 messages -> skip_stream\n",
      "80 messages\n",
      "80 messages -> skip_stream\n",
      "81 messages\n",
      "81 messages -> skip_stream\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "82 messages\n",
      "82 messages -> skip_stream\n",
      "83 messages\n",
      "83 messages -> skip_stream\n",
      "84 messages\n",
      "84 messages -> skip_stream\n",
      "85 messages\n",
      "85 messages -> skip_stream\n",
      "86 messages\n",
      "86 messages -> skip_stream\n",
      "87 messages\n",
      "87 messages -> skip_stream\n",
      "88 messages\n",
      "88 messages -> skip_stream\n",
      "89 messages\n",
      "89 messages -> skip_stream\n",
      "90 messages\n",
      "90 messages -> skip_stream\n",
      "91 messages\n",
      "91 messages -> skip_stream\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "92 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "---FINALIZING THE RESPONSE---\n",
      "93 messages\n",
      "93 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "94 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "94 common block -> isinstance(message, tuple)\n",
      "94 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"PAYE (Pay As You Earn) is a system where income tax is deducted from an employee\\u2019s salary before they receive it. It is mandatory by HMRC regulations. We can assist with calculating, submitting, and managing PAYE and National Insurance contributions for your business.\", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"ad30652d-54f2-44ee-aea2-a1c6bc949c3f\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "data: [DONE]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, AIMessageChunk, AnyMessage, HumanMessage, ToolMessage\n",
    "\n",
    "import json\n",
    "from typing import Any\n",
    "from uuid import UUID, uuid4\n",
    "config = {\"configurable\": {\"thread_id\": f\"{str(uuid4())}\", \"user_id\": f\"{str(uuid4())}\", \"vec_client\":vec_client}}\n",
    "run_id    = uuid4()\n",
    "\n",
    "events = []\n",
    "\n",
    "# User input to create a profile memory\n",
    "m = 'paye?'\n",
    "input_messages = [HumanMessage(content=m)]\n",
    "user_input: UserInput = UserInput(message=m)\n",
    "#run_id = \"nkljwkd\"\n",
    "\n",
    "i = 0\n",
    "try:\n",
    "    # Process streamed events from the graph and yield messages over the SSE stream.\n",
    "    async for stream_event in self_corrective_rag.astream(\n",
    "        {\"messages\": \"paye?\"},\n",
    "        config,\n",
    "        stream_mode=[\"updates\", \"messages\", \"custom\"],\n",
    "    ):\n",
    "        i += 1\n",
    "        if not isinstance(stream_event, tuple):\n",
    "            continue\n",
    "\n",
    "        stream_mode, event = stream_event\n",
    "        events.append(event)\n",
    "#        print(type(stream_mode))\n",
    "        new_messages = []\n",
    "\n",
    "        if stream_mode == \"updates\":\n",
    "            print(i, \"updates\")\n",
    "            for node, updates in event.items():\n",
    "                # A simple approach to handle agent interrupts.\n",
    "                # In a more sophisticated implementation, we could add\n",
    "                # some structured ChatMessage type to return the interrupt value.\n",
    "                if node == \"__interrupt__\":\n",
    "                    \n",
    "                    print(i, \"updates -> __interrupt__\")\n",
    "                    \n",
    "                    for interrupt in updates:\n",
    "                        print(i, \"updates -> __interrupt__ -> interrupt in updates\")\n",
    "                        new_messages.append(AIMessage(content=interrupt.value))\n",
    "                    continue\n",
    "\n",
    "                updates = updates or {}\n",
    "                print(\"update_messages = updates.get(messages, [])\")\n",
    "                update_messages = updates.get(\"messages\", [])\n",
    "\n",
    "                # special cases for using langgraph-supervisor library\n",
    "                if node == \"supervisor\":\n",
    "                    print(i, \"updates -> supervisor\")\n",
    "                    # Get only the last AIMessage since supervisor includes all previous messages\n",
    "                    ai_messages = [msg for msg in update_messages if isinstance(msg, AIMessage)]\n",
    "                    if ai_messages:\n",
    "                        print(i, \"updates -> supervisor -> aimessage\")\n",
    "                        update_messages = [ai_messages[-1]]\n",
    "\n",
    "                if node in (\"research_expert\", \"math_expert\"):\n",
    "                    print(i, \"updates -> [research_expert, math_expert]\")\n",
    "                    # By default the sub-agent output is returned as an AIMessage.\n",
    "                    # Convert it to a ToolMessage so it displays in the UI as a tool response.\n",
    "                    msg = ToolMessage(\n",
    "                        content=update_messages[0].content,\n",
    "                        name=node,\n",
    "                        tool_call_id=\"\",\n",
    "                    )\n",
    "                    update_messages = [msg]\n",
    "\n",
    "                new_messages.extend(update_messages)\n",
    "\n",
    "                # if node == 'document_search':\n",
    "                #     current_docs = [updates['documents'][i].model_dump_json() + \"\\n \\n\" for i in range(len(updates['documents']))]\n",
    "                #     current_docs = \"\".join(current_docs)\n",
    "                #     new_messages.append(AIMessage(content=current_docs))\n",
    "                #     continue\n",
    "\n",
    "        if stream_mode == \"custom\":\n",
    "            print(i, \"custom\")\n",
    "            new_messages = [event]\n",
    "\n",
    "        # LangGraph streaming may emit tuples: (field_name, field_value)\n",
    "        # e.g. ('content', <str>), ('tool_calls', [ToolCall,...]), ('additional_kwargs', {...}), etc.\n",
    "        # We accumulate only supported fields into `parts` and skip unsupported metadata.\n",
    "        # More info at: https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/\n",
    "        processed_messages = []\n",
    "        current_message: dict[str, Any] = {}\n",
    "\n",
    "        for message in new_messages:\n",
    "            print(i, \"common block -> isinstance(message, tuple)\")\n",
    "            if isinstance(message, tuple):\n",
    "                key, value = message\n",
    "                # Store parts in temporary dict\n",
    "                current_message[key] = value\n",
    "            else:\n",
    "                # Add complete message if we have one in progress\n",
    "                if current_message:\n",
    "                    print(i, \"common block -> else: current_message\")\n",
    "                    processed_messages.append(_create_ai_message(current_message))\n",
    "                    current_message = {}\n",
    "                processed_messages.append(message)\n",
    "\n",
    "        # Add any remaining message parts\n",
    "        if current_message:\n",
    "            print(i, \"common block -> if: current_message\")\n",
    "            processed_messages.append(_create_ai_message(current_message))\n",
    "\n",
    "        for message in processed_messages:\n",
    "            print(i, \"common block -> [message in processed_messages]\")\n",
    "            try:\n",
    "                chat_message = langchain_to_chat_message(message)\n",
    "                chat_message.run_id = str(run_id)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'error', 'content': 'Unexpected error', 'error': str(e)})}\\n\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # LangGraph re-sends the input message, which feels weird, so drop it\n",
    "            if chat_message.type == \"human\" and chat_message.content == user_input.message:\n",
    "                print(i, \"common block -> [if chat_message.type == human and chat_message.content == user_input.message]\")\n",
    "                continue\n",
    "\n",
    "            print(\n",
    "                f\"data: {json.dumps({'type': 'message', 'content': chat_message.model_dump()})}\\n\"\n",
    "            )\n",
    "\n",
    "        if stream_mode == \"messages\":\n",
    "            print(i, \"messages\")\n",
    "            if not True:  # user_input.stream_tokens (default=True). see `schema.schema` -> `StreamInput`\n",
    "                continue\n",
    "\n",
    "            msg, metadata = event\n",
    "\n",
    "            if \"skip_stream\" in metadata.get(\"tags\", []):\n",
    "                print(i, \"messages -> skip_stream\")\n",
    "                continue\n",
    "\n",
    "            # For some reason, astream(\"messages\") causes non-LLM nodes to send extra messages.\n",
    "            # Drop them.\n",
    "            if not isinstance(msg, AIMessageChunk):\n",
    "                print(i, \"messages -> [if not isinstance(msg, AIMessageChunk)]\")\n",
    "                continue\n",
    "\n",
    "            content = remove_tool_calls(msg.content)\n",
    "            if content:\n",
    "                # Actually print the token stream (previously this was constructed but not printed)\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'token', 'content': convert_message_content_to_string(content)})}\\n\"\n",
    "                )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"data: {json.dumps({'type': 'error', 'content': 'Internal server error', 'error': str(e)})}\\n\"\n",
    "    )\n",
    "finally:\n",
    "    print(\"data: [DONE]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30a02174-e610-4749-b7bf-6b5be0d08bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "1 messages\n",
      "1 messages -> skip_stream\n",
      "2 messages\n",
      "2 messages -> skip_stream\n",
      "3 messages\n",
      "3 messages -> skip_stream\n",
      "4 messages\n",
      "4 messages -> skip_stream\n",
      "5 messages\n",
      "5 messages -> skip_stream\n",
      "6 messages\n",
      "6 messages -> skip_stream\n",
      "7 messages\n",
      "7 messages -> skip_stream\n",
      "8 messages\n",
      "8 messages -> skip_stream\n",
      "9 messages\n",
      "9 messages -> skip_stream\n",
      "10 messages\n",
      "10 messages -> skip_stream\n",
      "---DECISION: QUERY/QUESTION <IS NOT RELATED> TO ACCOUNTING---\n",
      "11 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "12 custom\n",
      "12 common block -> isinstance(message, tuple)\n",
      "12 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"error\", \"content\": \"Unexpected error\", \"error\": \"Unsupported message type: str\"}\n",
      "\n",
      "13 custom\n",
      "13 common block -> isinstance(message, tuple)\n",
      "13 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"error\", \"content\": \"Unexpected error\", \"error\": \"Unsupported message type: str\"}\n",
      "\n",
      "14 custom\n",
      "14 common block -> isinstance(message, tuple)\n",
      "14 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"error\", \"content\": \"Unexpected error\", \"error\": \"Unsupported message type: str\"}\n",
      "\n",
      "15 custom\n",
      "15 common block -> isinstance(message, tuple)\n",
      "15 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"error\", \"content\": \"Unexpected error\", \"error\": \"Unsupported message type: str\"}\n",
      "\n",
      "16 custom\n",
      "16 common block -> isinstance(message, tuple)\n",
      "16 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"error\", \"content\": \"Unexpected error\", \"error\": \"Unsupported message type: str\"}\n",
      "\n",
      "17 custom\n",
      "17 common block -> isinstance(message, tuple)\n",
      "17 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"error\", \"content\": \"Unexpected error\", \"error\": \"Unsupported message type: str\"}\n",
      "\n",
      "18 custom\n",
      "18 common block -> isinstance(message, tuple)\n",
      "18 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"error\", \"content\": \"Unexpected error\", \"error\": \"Unsupported message type: str\"}\n",
      "\n",
      "19 custom\n",
      "19 common block -> isinstance(message, tuple)\n",
      "19 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"error\", \"content\": \"Unexpected error\", \"error\": \"Unsupported message type: str\"}\n",
      "\n",
      "20 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "---FINALIZING THE RESPONSE---\n",
      "21 messages\n",
      "21 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "22 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "22 common block -> isinstance(message, tuple)\n",
      "22 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"Sorry, I cannot help you in this matter.\", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"41f42e47-18be-4651-aac6-b5b43fc3e7d4\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "data: [DONE]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, AIMessageChunk, AnyMessage, HumanMessage, ToolMessage\n",
    "\n",
    "import json\n",
    "from typing import Any\n",
    "from uuid import UUID, uuid4\n",
    "config = {\"configurable\": {\"thread_id\": f\"{str(uuid4())}\", \"user_id\": f\"{str(uuid4())}\", \"vec_client\":vec_client}}\n",
    "run_id    = uuid4()\n",
    "\n",
    "events = []\n",
    "\n",
    "# User input to create a profile memory\n",
    "m = 'boobs?'\n",
    "input_messages = [HumanMessage(content=m)]\n",
    "user_input: UserInput = UserInput(message=m)\n",
    "#run_id = \"nkljwkd\"\n",
    "\n",
    "i = 0\n",
    "try:\n",
    "    # Process streamed events from the graph and yield messages over the SSE stream.\n",
    "    async for stream_event in self_corrective_rag.astream(\n",
    "        {\"messages\": m},\n",
    "        config,\n",
    "        stream_mode=[\"updates\", \"messages\", \"custom\"],\n",
    "    ):\n",
    "        i += 1\n",
    "        if not isinstance(stream_event, tuple):\n",
    "            continue\n",
    "\n",
    "        stream_mode, event = stream_event\n",
    "        events.append(event)\n",
    "#        print(type(stream_mode))\n",
    "        new_messages = []\n",
    "\n",
    "        if stream_mode == \"updates\":\n",
    "            print(i, \"updates\")\n",
    "            for node, updates in event.items():\n",
    "                # A simple approach to handle agent interrupts.\n",
    "                # In a more sophisticated implementation, we could add\n",
    "                # some structured ChatMessage type to return the interrupt value.\n",
    "                if node == \"__interrupt__\":\n",
    "                    \n",
    "                    print(i, \"updates -> __interrupt__\")\n",
    "                    \n",
    "                    for interrupt in updates:\n",
    "                        print(i, \"updates -> __interrupt__ -> interrupt in updates\")\n",
    "                        new_messages.append(AIMessage(content=interrupt.value))\n",
    "                    continue\n",
    "\n",
    "                updates = updates or {}\n",
    "                print(\"update_messages = updates.get(messages, [])\")\n",
    "                update_messages = updates.get(\"messages\", [])\n",
    "\n",
    "                # special cases for using langgraph-supervisor library\n",
    "                if node == \"supervisor\":\n",
    "                    print(i, \"updates -> supervisor\")\n",
    "                    # Get only the last AIMessage since supervisor includes all previous messages\n",
    "                    ai_messages = [msg for msg in update_messages if isinstance(msg, AIMessage)]\n",
    "                    if ai_messages:\n",
    "                        print(i, \"updates -> supervisor -> aimessage\")\n",
    "                        update_messages = [ai_messages[-1]]\n",
    "\n",
    "                if node in (\"research_expert\", \"math_expert\"):\n",
    "                    print(i, \"updates -> [research_expert, math_expert]\")\n",
    "                    # By default the sub-agent output is returned as an AIMessage.\n",
    "                    # Convert it to a ToolMessage so it displays in the UI as a tool response.\n",
    "                    msg = ToolMessage(\n",
    "                        content=update_messages[0].content,\n",
    "                        name=node,\n",
    "                        tool_call_id=\"\",\n",
    "                    )\n",
    "                    update_messages = [msg]\n",
    "\n",
    "                new_messages.extend(update_messages)\n",
    "\n",
    "                # if node == 'document_search':\n",
    "                #     current_docs = [updates['documents'][i].model_dump_json() + \"\\n \\n\" for i in range(len(updates['documents']))]\n",
    "                #     current_docs = \"\".join(current_docs)\n",
    "                #     new_messages.append(AIMessage(content=current_docs))\n",
    "                #     continue\n",
    "\n",
    "        if stream_mode == \"custom\":\n",
    "            print(i, \"custom\")\n",
    "            new_messages = [event]\n",
    "\n",
    "        # LangGraph streaming may emit tuples: (field_name, field_value)\n",
    "        # e.g. ('content', <str>), ('tool_calls', [ToolCall,...]), ('additional_kwargs', {...}), etc.\n",
    "        # We accumulate only supported fields into `parts` and skip unsupported metadata.\n",
    "        # More info at: https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/\n",
    "        processed_messages = []\n",
    "        current_message: dict[str, Any] = {}\n",
    "\n",
    "        for message in new_messages:\n",
    "            print(i, \"common block -> isinstance(message, tuple)\")\n",
    "            if isinstance(message, tuple):\n",
    "                key, value = message\n",
    "                # Store parts in temporary dict\n",
    "                current_message[key] = value\n",
    "            else:\n",
    "                # Add complete message if we have one in progress\n",
    "                if current_message:\n",
    "                    print(i, \"common block -> else: current_message\")\n",
    "                    processed_messages.append(_create_ai_message(current_message))\n",
    "                    current_message = {}\n",
    "                processed_messages.append(message)\n",
    "\n",
    "        # Add any remaining message parts\n",
    "        if current_message:\n",
    "            print(i, \"common block -> if: current_message\")\n",
    "            processed_messages.append(_create_ai_message(current_message))\n",
    "\n",
    "        for message in processed_messages:\n",
    "            print(i, \"common block -> [message in processed_messages]\")\n",
    "            try:\n",
    "                chat_message = langchain_to_chat_message(message)\n",
    "                chat_message.run_id = str(run_id)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'error', 'content': 'Unexpected error', 'error': str(e)})}\\n\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # LangGraph re-sends the input message, which feels weird, so drop it\n",
    "            if chat_message.type == \"human\" and chat_message.content == user_input.message:\n",
    "                print(i, \"common block -> [if chat_message.type == human and chat_message.content == user_input.message]\")\n",
    "                continue\n",
    "\n",
    "            print(\n",
    "                f\"data: {json.dumps({'type': 'message', 'content': chat_message.model_dump()})}\\n\"\n",
    "            )\n",
    "\n",
    "        if stream_mode == \"messages\":\n",
    "            print(i, \"messages\")\n",
    "            if not True:  # user_input.stream_tokens (default=True). see `schema.schema` -> `StreamInput`\n",
    "                continue\n",
    "\n",
    "            msg, metadata = event\n",
    "\n",
    "            if \"skip_stream\" in metadata.get(\"tags\", []):\n",
    "                print(i, \"messages -> skip_stream\")\n",
    "                continue\n",
    "\n",
    "            # For some reason, astream(\"messages\") causes non-LLM nodes to send extra messages.\n",
    "            # Drop them.\n",
    "            if not isinstance(msg, AIMessageChunk):\n",
    "                print(i, \"messages -> [if not isinstance(msg, AIMessageChunk)]\")\n",
    "                continue\n",
    "\n",
    "            content = remove_tool_calls(msg.content)\n",
    "            if content:\n",
    "                # Actually print the token stream (previously this was constructed but not printed)\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'token', 'content': convert_message_content_to_string(content)})}\\n\"\n",
    "                )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"data: {json.dumps({'type': 'error', 'content': 'Internal server error', 'error': str(e)})}\\n\"\n",
    "    )\n",
    "finally:\n",
    "    print(\"data: [DONE]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5b335c-4623-4d2c-b8c9-5211e576679b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f6df2-bdf6-4db8-b409-9c714dded8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f7d214b-547b-44b9-b057-067bf0dfaa66",
   "metadata": {},
   "source": [
    "# updating custom message handling logiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f68e9d6-17c3-4658-b331-390d53532bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import StreamWriter\n",
    "\n",
    "PRESET = \"Hello from LangGraph 🎉 This was predefined.\"\n",
    "\n",
    "class State(TypedDict):\n",
    "    pass\n",
    "\n",
    "from langgraph.types import StreamWriter\n",
    "async def say_predefined(_: State, writer: StreamWriter):  # writer auto-injected\n",
    "    for word in PRESET.split():\n",
    "        writer(word + ' ')\n",
    "    return {}\n",
    "\n",
    "graph = (\n",
    "    StateGraph(State)\n",
    "    .add_node(\"say_predefined\", say_predefined)\n",
    "    .add_edge(START, \"say_predefined\")\n",
    "    .add_edge(\"say_predefined\", END)\n",
    ").compile()\n",
    "\n",
    "# async def main():\n",
    "#     async for chunk in graph.astream({}, stream_mode=\"custom\"):\n",
    "#         print(chunk, end=\"\", flush=True)\n",
    "#     print()\n",
    "\n",
    "# asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb83cc9-de41-46f8-9322-0444fb43ee05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab9e3688-657b-472d-8e21-05172ece5281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 custom\n",
      "1 common block -> isinstance(message, tuple)\n",
      "1 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"Hello \", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"a362c570-83e5-471d-8085-77b599563004\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "2 custom\n",
      "2 common block -> isinstance(message, tuple)\n",
      "2 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"from \", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"a362c570-83e5-471d-8085-77b599563004\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "3 custom\n",
      "3 common block -> isinstance(message, tuple)\n",
      "3 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"LangGraph \", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"a362c570-83e5-471d-8085-77b599563004\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "4 custom\n",
      "4 common block -> isinstance(message, tuple)\n",
      "4 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"🎉 \", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"a362c570-83e5-471d-8085-77b599563004\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "5 custom\n",
      "5 common block -> isinstance(message, tuple)\n",
      "5 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"This \", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"a362c570-83e5-471d-8085-77b599563004\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "6 custom\n",
      "6 common block -> isinstance(message, tuple)\n",
      "6 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"was \", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"a362c570-83e5-471d-8085-77b599563004\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "7 custom\n",
      "7 common block -> isinstance(message, tuple)\n",
      "7 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"predefined. \", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"a362c570-83e5-471d-8085-77b599563004\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "8 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "data: [DONE]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, AIMessageChunk, AnyMessage, HumanMessage, ToolMessage\n",
    "\n",
    "import json\n",
    "from typing import Any\n",
    "from uuid import UUID, uuid4\n",
    "config = {\"configurable\": {\"thread_id\": f\"{str(uuid4())}\", \"user_id\": f\"{str(uuid4())}\", \"vec_client\":vec_client}}\n",
    "run_id    = uuid4()\n",
    "\n",
    "events = []\n",
    "\n",
    "# User input to create a profile memory\n",
    "m = 'paye?'\n",
    "input_messages = [HumanMessage(content=m)]\n",
    "user_input: UserInput = UserInput(message=m)\n",
    "#run_id = \"nkljwkd\"\n",
    "\n",
    "i = 0\n",
    "try:\n",
    "    # Process streamed events from the graph and yield messages over the SSE stream.\n",
    "    async for stream_event in graph.astream(\n",
    "        {\"messages\": \"paye?\"},\n",
    "        config,\n",
    "        stream_mode=[\"updates\", \"messages\", \"custom\"],\n",
    "    ):\n",
    "        i += 1\n",
    "        if not isinstance(stream_event, tuple):\n",
    "            continue\n",
    "\n",
    "        stream_mode, event = stream_event\n",
    "        events.append(event)\n",
    "#        print(type(stream_mode))\n",
    "        new_messages = []\n",
    "\n",
    "        if stream_mode == \"updates\":\n",
    "            print(i, \"updates\")\n",
    "            for node, updates in event.items():\n",
    "                # A simple approach to handle agent interrupts.\n",
    "                # In a more sophisticated implementation, we could add\n",
    "                # some structured ChatMessage type to return the interrupt value.\n",
    "                if node == \"__interrupt__\":\n",
    "                    \n",
    "                    print(i, \"updates -> __interrupt__\")\n",
    "                    \n",
    "                    for interrupt in updates:\n",
    "                        print(i, \"updates -> __interrupt__ -> interrupt in updates\")\n",
    "                        new_messages.append(AIMessage(content=interrupt.value))\n",
    "                    continue\n",
    "\n",
    "                updates = updates or {}\n",
    "                print(\"update_messages = updates.get(messages, [])\")\n",
    "                update_messages = updates.get(\"messages\", [])\n",
    "\n",
    "                # special cases for using langgraph-supervisor library\n",
    "                if node == \"supervisor\":\n",
    "                    print(i, \"updates -> supervisor\")\n",
    "                    # Get only the last AIMessage since supervisor includes all previous messages\n",
    "                    ai_messages = [msg for msg in update_messages if isinstance(msg, AIMessage)]\n",
    "                    if ai_messages:\n",
    "                        print(i, \"updates -> supervisor -> aimessage\")\n",
    "                        update_messages = [ai_messages[-1]]\n",
    "\n",
    "                if node in (\"research_expert\", \"math_expert\"):\n",
    "                    print(i, \"updates -> [research_expert, math_expert]\")\n",
    "                    # By default the sub-agent output is returned as an AIMessage.\n",
    "                    # Convert it to a ToolMessage so it displays in the UI as a tool response.\n",
    "                    msg = ToolMessage(\n",
    "                        content=update_messages[0].content,\n",
    "                        name=node,\n",
    "                        tool_call_id=\"\",\n",
    "                    )\n",
    "                    update_messages = [msg]\n",
    "\n",
    "                new_messages.extend(update_messages)\n",
    "\n",
    "                # if node == 'document_search':\n",
    "                #     current_docs = [updates['documents'][i].model_dump_json() + \"\\n \\n\" for i in range(len(updates['documents']))]\n",
    "                #     current_docs = \"\".join(current_docs)\n",
    "                #     new_messages.append(AIMessage(content=current_docs))\n",
    "                #     continue\n",
    "\n",
    "        if stream_mode == \"custom\":\n",
    "            print(i, \"custom\")\n",
    "            new_messages = [event]\n",
    "\n",
    "        # LangGraph streaming may emit tuples: (field_name, field_value)\n",
    "        # e.g. ('content', <str>), ('tool_calls', [ToolCall,...]), ('additional_kwargs', {...}), etc.\n",
    "        # We accumulate only supported fields into `parts` and skip unsupported metadata.\n",
    "        # More info at: https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/\n",
    "        processed_messages = []\n",
    "        current_message: dict[str, Any] = {}\n",
    "\n",
    "        for message in new_messages:\n",
    "            print(i, \"common block -> isinstance(message, tuple)\")\n",
    "            if isinstance(message, tuple):\n",
    "                key, value = message\n",
    "                # print(\"key, value = message\", key, value)\n",
    "                # Store parts in temporary dict\n",
    "                current_message[key] = value\n",
    "            else:\n",
    "                # Add complete message if we have one in progress\n",
    "                if current_message:\n",
    "                    print(i, \"common block -> else: current_message\")\n",
    "                    processed_messages.append(_create_ai_message(current_message))\n",
    "                    current_message = {}\n",
    "                processed_messages.append(message)\n",
    "\n",
    "        # Add any remaining message parts\n",
    "        if current_message:\n",
    "            print(i, \"common block -> if: current_message\")\n",
    "            processed_messages.append(_create_ai_message(current_message))\n",
    "\n",
    "        for message in processed_messages:\n",
    "            print(i, \"common block -> [message in processed_messages]\")\n",
    "            try:\n",
    "                if isinstance(message, str):\n",
    "                    chat_message        = ChatMessage(type=\"ai\", content=message)\n",
    "                    chat_message.run_id = str(run_id)\n",
    "                else:\n",
    "                    chat_message = langchain_to_chat_message(message)\n",
    "                    chat_message.run_id = str(run_id)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'error', 'content': 'Unexpected error', 'error': str(e)})}\\n\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # LangGraph re-sends the input message, which feels weird, so drop it\n",
    "            if chat_message.type == \"human\" and chat_message.content == user_input.message:\n",
    "                print(i, \"common block -> [if chat_message.type == human and chat_message.content == user_input.message]\")\n",
    "                continue\n",
    "\n",
    "                \n",
    "            payload = {\"type\": \"message\", \"content\": chat_message.model_dump()}\n",
    "            # if you're printing to stdout (dev)\n",
    "            print(f\"data: {json.dumps(payload, ensure_ascii=False)}\\n\")\n",
    "\n",
    "\n",
    "        if stream_mode == \"messages\":\n",
    "            print(i, \"messages\")\n",
    "            if not True:  # user_input.stream_tokens (default=True). see `schema.schema` -> `StreamInput`\n",
    "                continue\n",
    "\n",
    "            msg, metadata = event\n",
    "\n",
    "            if \"skip_stream\" in metadata.get(\"tags\", []):\n",
    "                print(i, \"messages -> skip_stream\")\n",
    "                continue\n",
    "\n",
    "            # For some reason, astream(\"messages\") causes non-LLM nodes to send extra messages.\n",
    "            # Drop them.\n",
    "            if not isinstance(msg, AIMessageChunk):\n",
    "                print(i, \"messages -> [if not isinstance(msg, AIMessageChunk)]\")\n",
    "                continue\n",
    "\n",
    "            content = remove_tool_calls(msg.content)\n",
    "            if content:\n",
    "                # Actually print the token stream (previously this was constructed but not printed)\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'token', 'content': convert_message_content_to_string(content)})}\\n\"\n",
    "                )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"data: {json.dumps({'type': 'error', 'content': 'Internal server error', 'error': str(e)})}\\n\"\n",
    "    )\n",
    "finally:\n",
    "    print(\"data: [DONE]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4eeb552a-d687-4e89-b3a3-f54c508d341d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(message) == type('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ec22eb-7380-4c6a-aa6f-6c812af54583",
   "metadata": {},
   "source": [
    "# adding same logic to self corrective rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44bd7169-3d8c-4a78-b7af-ae12afc8b3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "1 messages\n",
      "1 messages -> skip_stream\n",
      "2 messages\n",
      "2 messages -> skip_stream\n",
      "3 messages\n",
      "3 messages -> skip_stream\n",
      "4 messages\n",
      "4 messages -> skip_stream\n",
      "5 messages\n",
      "5 messages -> skip_stream\n",
      "6 messages\n",
      "6 messages -> skip_stream\n",
      "7 messages\n",
      "7 messages -> skip_stream\n",
      "8 messages\n",
      "8 messages -> skip_stream\n",
      "9 messages\n",
      "9 messages -> skip_stream\n",
      "10 messages\n",
      "10 messages -> skip_stream\n",
      "---DECISION: QUERY/QUESTION <IS NOT RELATED> TO ACCOUNTING---\n",
      "11 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "12 custom\n",
      "12 common block -> isinstance(message, tuple)\n",
      "12 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"Sorry, \", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"7793ddc6-871e-4b82-ba87-4061d27610b3\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "13 custom\n",
      "13 common block -> isinstance(message, tuple)\n",
      "13 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"I \", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"7793ddc6-871e-4b82-ba87-4061d27610b3\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "14 custom\n",
      "14 common block -> isinstance(message, tuple)\n",
      "14 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"cannot \", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"7793ddc6-871e-4b82-ba87-4061d27610b3\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "15 custom\n",
      "15 common block -> isinstance(message, tuple)\n",
      "15 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"help \", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"7793ddc6-871e-4b82-ba87-4061d27610b3\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "16 custom\n",
      "16 common block -> isinstance(message, tuple)\n",
      "16 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"you \", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"7793ddc6-871e-4b82-ba87-4061d27610b3\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "17 custom\n",
      "17 common block -> isinstance(message, tuple)\n",
      "17 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"in \", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"7793ddc6-871e-4b82-ba87-4061d27610b3\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "18 custom\n",
      "18 common block -> isinstance(message, tuple)\n",
      "18 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"this \", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"7793ddc6-871e-4b82-ba87-4061d27610b3\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "19 custom\n",
      "19 common block -> isinstance(message, tuple)\n",
      "19 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"matter. \", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"7793ddc6-871e-4b82-ba87-4061d27610b3\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "20 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "---FINALIZING THE RESPONSE---\n",
      "21 messages\n",
      "21 messages -> [if not isinstance(msg, AIMessageChunk)]\n",
      "22 updates\n",
      "update_messages = updates.get(messages, [])\n",
      "22 common block -> isinstance(message, tuple)\n",
      "22 common block -> [message in processed_messages]\n",
      "data: {\"type\": \"message\", \"content\": {\"type\": \"ai\", \"content\": \"Sorry, I cannot help you in this matter.\", \"tool_calls\": [], \"tool_call_id\": null, \"run_id\": \"7793ddc6-871e-4b82-ba87-4061d27610b3\", \"response_metadata\": {}, \"custom_data\": {}}}\n",
      "\n",
      "data: [DONE]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, AIMessageChunk, AnyMessage, HumanMessage, ToolMessage\n",
    "\n",
    "import json\n",
    "from typing import Any\n",
    "from uuid import UUID, uuid4\n",
    "config = {\"configurable\": {\"thread_id\": f\"{str(uuid4())}\", \"user_id\": f\"{str(uuid4())}\", \"vec_client\":vec_client}}\n",
    "run_id    = uuid4()\n",
    "\n",
    "events = []\n",
    "\n",
    "# User input to create a profile memory\n",
    "m = 'boobs?'\n",
    "input_messages = [HumanMessage(content=m)]\n",
    "user_input: UserInput = UserInput(message=m)\n",
    "#run_id = \"nkljwkd\"\n",
    "\n",
    "i = 0\n",
    "try:\n",
    "    # Process streamed events from the graph and yield messages over the SSE stream.\n",
    "    async for stream_event in self_corrective_rag.astream(\n",
    "        {\"messages\": m},\n",
    "        config,\n",
    "        stream_mode=[\"updates\", \"messages\", \"custom\"],\n",
    "    ):\n",
    "        i += 1\n",
    "        if not isinstance(stream_event, tuple):\n",
    "            continue\n",
    "\n",
    "        stream_mode, event = stream_event\n",
    "        events.append(event)\n",
    "#        print(type(stream_mode))\n",
    "        new_messages = []\n",
    "\n",
    "        if stream_mode == \"updates\":\n",
    "            print(i, \"updates\")\n",
    "            for node, updates in event.items():\n",
    "                # A simple approach to handle agent interrupts.\n",
    "                # In a more sophisticated implementation, we could add\n",
    "                # some structured ChatMessage type to return the interrupt value.\n",
    "                if node == \"__interrupt__\":\n",
    "                    \n",
    "                    print(i, \"updates -> __interrupt__\")\n",
    "                    \n",
    "                    for interrupt in updates:\n",
    "                        print(i, \"updates -> __interrupt__ -> interrupt in updates\")\n",
    "                        new_messages.append(AIMessage(content=interrupt.value))\n",
    "                    continue\n",
    "\n",
    "                updates = updates or {}\n",
    "                print(\"update_messages = updates.get(messages, [])\")\n",
    "                update_messages = updates.get(\"messages\", [])\n",
    "\n",
    "                # special cases for using langgraph-supervisor library\n",
    "                if node == \"supervisor\":\n",
    "                    print(i, \"updates -> supervisor\")\n",
    "                    # Get only the last AIMessage since supervisor includes all previous messages\n",
    "                    ai_messages = [msg for msg in update_messages if isinstance(msg, AIMessage)]\n",
    "                    if ai_messages:\n",
    "                        print(i, \"updates -> supervisor -> aimessage\")\n",
    "                        update_messages = [ai_messages[-1]]\n",
    "\n",
    "                if node in (\"research_expert\", \"math_expert\"):\n",
    "                    print(i, \"updates -> [research_expert, math_expert]\")\n",
    "                    # By default the sub-agent output is returned as an AIMessage.\n",
    "                    # Convert it to a ToolMessage so it displays in the UI as a tool response.\n",
    "                    msg = ToolMessage(\n",
    "                        content=update_messages[0].content,\n",
    "                        name=node,\n",
    "                        tool_call_id=\"\",\n",
    "                    )\n",
    "                    update_messages = [msg]\n",
    "\n",
    "                new_messages.extend(update_messages)\n",
    "\n",
    "                # if node == 'document_search':\n",
    "                #     current_docs = [updates['documents'][i].model_dump_json() + \"\\n \\n\" for i in range(len(updates['documents']))]\n",
    "                #     current_docs = \"\".join(current_docs)\n",
    "                #     new_messages.append(AIMessage(content=current_docs))\n",
    "                #     continue\n",
    "\n",
    "        if stream_mode == \"custom\":\n",
    "            print(i, \"custom\")\n",
    "            new_messages = [event]\n",
    "\n",
    "        # LangGraph streaming may emit tuples: (field_name, field_value)\n",
    "        # e.g. ('content', <str>), ('tool_calls', [ToolCall,...]), ('additional_kwargs', {...}), etc.\n",
    "        # We accumulate only supported fields into `parts` and skip unsupported metadata.\n",
    "        # More info at: https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/\n",
    "        processed_messages = []\n",
    "        current_message: dict[str, Any] = {}\n",
    "\n",
    "        for message in new_messages:\n",
    "            print(i, \"common block -> isinstance(message, tuple)\")\n",
    "            if isinstance(message, tuple):\n",
    "                key, value = message\n",
    "                # print(\"key, value = message\", key, value)\n",
    "                # Store parts in temporary dict\n",
    "                current_message[key] = value\n",
    "            else:\n",
    "                # Add complete message if we have one in progress\n",
    "                if current_message:\n",
    "                    print(i, \"common block -> else: current_message\")\n",
    "                    processed_messages.append(_create_ai_message(current_message))\n",
    "                    current_message = {}\n",
    "                processed_messages.append(message)\n",
    "\n",
    "        # Add any remaining message parts\n",
    "        if current_message:\n",
    "            print(i, \"common block -> if: current_message\")\n",
    "            processed_messages.append(_create_ai_message(current_message))\n",
    "\n",
    "        for message in processed_messages:\n",
    "            print(i, \"common block -> [message in processed_messages]\")\n",
    "            try:\n",
    "                if isinstance(message, str):\n",
    "                    chat_message        = ChatMessage(type=\"ai\", content=message)\n",
    "                    chat_message.run_id = str(run_id)\n",
    "                else:\n",
    "                    chat_message = langchain_to_chat_message(message)\n",
    "                    chat_message.run_id = str(run_id)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'error', 'content': 'Unexpected error', 'error': str(e)})}\\n\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # LangGraph re-sends the input message, which feels weird, so drop it\n",
    "            if chat_message.type == \"human\" and chat_message.content == user_input.message:\n",
    "                print(i, \"common block -> [if chat_message.type == human and chat_message.content == user_input.message]\")\n",
    "                continue\n",
    "\n",
    "                \n",
    "            payload = {\"type\": \"message\", \"content\": chat_message.model_dump()}\n",
    "            # if you're printing to stdout (dev)\n",
    "            print(f\"data: {json.dumps(payload, ensure_ascii=False)}\\n\")\n",
    "\n",
    "\n",
    "        if stream_mode == \"messages\":\n",
    "            print(i, \"messages\")\n",
    "            if not True:  # user_input.stream_tokens (default=True). see `schema.schema` -> `StreamInput`\n",
    "                continue\n",
    "\n",
    "            msg, metadata = event\n",
    "\n",
    "            if \"skip_stream\" in metadata.get(\"tags\", []):\n",
    "                print(i, \"messages -> skip_stream\")\n",
    "                continue\n",
    "\n",
    "            # For some reason, astream(\"messages\") causes non-LLM nodes to send extra messages.\n",
    "            # Drop them.\n",
    "            if not isinstance(msg, AIMessageChunk):\n",
    "                print(i, \"messages -> [if not isinstance(msg, AIMessageChunk)]\")\n",
    "                continue\n",
    "\n",
    "            content = remove_tool_calls(msg.content)\n",
    "            if content:\n",
    "                # Actually print the token stream (previously this was constructed but not printed)\n",
    "                print(\n",
    "                    f\"data: {json.dumps({'type': 'token', 'content': convert_message_content_to_string(content)})}\\n\"\n",
    "                )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"data: {json.dumps({'type': 'error', 'content': 'Internal server error', 'error': str(e)})}\\n\"\n",
    "    )\n",
    "finally:\n",
    "    print(\"data: [DONE]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f77746-920f-4aeb-9aeb-410859df4aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6bb4d0-a3a6-4d51-a0c5-040c82c76ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83bc58c-4995-4955-b878-b57e81c4723b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f541bb1-31f0-4d15-be1a-bb629332aab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6556c400-e2c0-43a6-aedc-e1a29bb88c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
